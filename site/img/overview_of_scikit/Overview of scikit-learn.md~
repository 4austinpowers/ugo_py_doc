---

[TOC]

---

**Foreword**

Code snippets and excerpts from the tutorial. Python 3. From DataCamp.

---

```python
# Set the current directory
import os

os.chdir('/home/ugo/Documents/Notebooks/DataCamp, Overview of scikit-learn/')
print(os.getcwd())
```

    /home/ugo/Documents/Notebooks/DataCamp, Overview of scikit-learn


# The scikit-learn module

<img src="img/overview_of_scikit/scikit-learn.png" width="100%" hspace=0 vspace=0 >

We use different algorithms from the `sciki-learn` module as classifiers (on a binary dependent variable). Most models come from this [link](https://www.youtube.com/watch?v=T5pRlIbr6gg).

Unused algorithms:

- Regressions,
    - Ridge regression (for dealing with heteroscedasticity),
    - ElasticNet, Lasso (for dealing with heteroscedasticity),
    - Support Vector Regression (SVR), ensemble models,
- Classfication,
    - Linear SVC, ensemble SVC, kernel approximation,
- Clustering,
    - k-means, spectral clustering GMM,
    - Other k-means,
- Dimensionality reduction,
    - Principal Component Analysis (PCA),
    - Others.

# Basic level

## Hard-coded dataset


```python
# [height, weight, shoe_size]
X = [[181, 80, 44], [177, 70, 43], [160, 60, 38], [154, 54, 37], [166, 65, 40],
     [190, 90, 47], [175, 64, 39],
     [177, 70, 40], [159, 55, 37], [171, 75, 42], [181, 85, 43]]

Y = ['male', 'male', 'female', 'female', 'male', 'male', 'female', 'female',
     'female', 'male', 'male']
```

## Decision tree


```python
# import decision tree
from sklearn import tree

# train on the train set
clf = tree.DecisionTreeClassifier()

clf = clf.fit(X,Y)
```


```python
# test
prediction = clf.predict([[190, 70, 43]])
print(prediction)
```

    ['male']


## Random Forests


```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.cross_validation import train_test_split
from sklearn.metrics import confusion_matrix

# set the training parameters
clf = RandomForestClassifier(n_estimators=1000)

# train on the same train set
clf = clf.fit(X,Y)

# validate the classifier
accuracy = clf.score(X, Y)
print('Accuracy: ' + str(accuracy))
```

    Accuracy: 1.0



```python
# test
prediction = clf.predict([[190, 70, 43]])
print(prediction)
```

    ['male']


## k-Nearest Neighbours


```python
from sklearn.neighbors import KNeighborsClassifier

# set the training parameters
neigh = KNeighborsClassifier(n_neighbors=3)

# train on the same train set
neigh.fit(X,Y)
```




    KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
               metric_params=None, n_jobs=1, n_neighbors=3, p=2,
               weights='uniform')




```python
# test
prediction = neigh.predict([[190, 70, 43]])
print(prediction)
```

    ['male']


## Logistic regression


```python
from sklearn.linear_model import LogisticRegression

# set the training parameters
neigh = LogisticRegression()

# train on the same train set
neigh.fit(X, Y)
```




    LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
              intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,
              penalty='l2', random_state=None, solver='liblinear', tol=0.0001,
              verbose=0, warm_start=False)




```python
# test
prediction = neigh.predict([[190, 70, 43]])
print(prediction)
```

    ['female']


## Na√Øve Bayes


```python
from sklearn.naive_bayes import GaussianNB

# set the training parameters
gnb = GaussianNB()

# train on the same train set
gnb = gnb.fit(X, Y)
```


```python
# test
prediction = gnb.predict([[190, 70, 43]])
print(prediction)
```

    ['male']


# Intermediate level

## Imported dataset

## Decision tree


```python
import pandas as pd
from sklearn import tree
from sklearn.preprocessing import LabelEncoder
from sklearn.cross_validation import train_test_split
from sklearn.metrics import confusion_matrix

# import the adult.txt file into Python
data = pd.read_csv('data/adults.txt', sep=',')
print(data.head(3))
```

       age         workclass  final_weight  education  education_num  \
    0   39         State-gov         77516  Bachelors             13   
    1   50  Self-emp-not-inc         83311  Bachelors             13   
    2   38           Private        215646    HS-grad              9   
    
           marital_status         occupation   relationship   race   sex  \
    0       Never-married       Adm-clerical  Not-in-family  White  Male   
    1  Married-civ-spouse    Exec-managerial        Husband  White  Male   
    2            Divorced  Handlers-cleaners  Not-in-family  White  Male   
    
       capital_gain  capital_loss  hours_per_week native_country salary  
    0          2174             0              40  United-States  <=50K  
    1             0             0              13  United-States  <=50K  
    2             0             0              40  United-States  <=50K  



```python
len(data)
```




    32561




```python
data.shape
```




    (32561, 15)




```python
data.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 32561 entries, 0 to 32560
    Data columns (total 15 columns):
    age               32561 non-null int64
    workclass         32561 non-null object
    final_weight      32561 non-null int64
    education         32561 non-null object
    education_num     32561 non-null int64
    marital_status    32561 non-null object
    occupation        32561 non-null object
    relationship      32561 non-null object
    race              32561 non-null object
    sex               32561 non-null object
    capital_gain      32561 non-null int64
    capital_loss      32561 non-null int64
    hours_per_week    32561 non-null int64
    native_country    32561 non-null object
    salary            32561 non-null object
    dtypes: int64(6), object(9)
    memory usage: 3.7+ MB



```python
# convert the string labels to numeric labels
for label in ['race', 'occupation']:
    data[label] = LabelEncoder().fit_transform(data[label])
print(data.head(3))
```

       age         workclass  final_weight  education  education_num  \
    0   39         State-gov         77516  Bachelors             13   
    1   50  Self-emp-not-inc         83311  Bachelors             13   
    2   38           Private        215646    HS-grad              9   
    
           marital_status  occupation   relationship  race   sex  capital_gain  \
    0       Never-married           1  Not-in-family     4  Male          2174   
    1  Married-civ-spouse           4        Husband     4  Male             0   
    2            Divorced           6  Not-in-family     4  Male             0   
    
       capital_loss  hours_per_week native_country salary  
    0             0              40  United-States  <=50K  
    1             0              13  United-States  <=50K  
    2             0              40  United-States  <=50K  



```python
# take the fields of interest and plug them into variable X
X = data[['race', 'hours_per_week', 'occupation']]

# make sure to provide the corresponding truth value
Y = data['sex'].values.tolist()
```


```python
# split the data into a test (30%) and train set (70%)
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)

# set the training parameters, instantiate the classifier
clf = tree.DecisionTreeClassifier()

# train on the train set
clf = clf.fit(X_train, Y_train)
```


```python
# validate the classifier
accuracy = clf.score(X_test, Y_test)
print('Accuracy: ' + str(accuracy))
```

    Accuracy: 0.727198280274



```python
# test
prediction = clf.predict(X_test)
print(prediction)
```

    ['Female' 'Female' 'Male' ..., 'Male' 'Male' 'Male']



```python
# create a confusion matrix
cm = confusion_matrix(prediction, Y_test)
print(cm)
```

    [[1613 1037]
     [1628 5491]]


## Random Forests


```python
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.cross_validation import train_test_split
from sklearn.metrics import confusion_matrix

# import the adult.txt file into Python
data = pd.read_csv('data/adults.txt', sep=',')
print(data.head(3))
```

       age         workclass  final_weight  education  education_num  \
    0   39         State-gov         77516  Bachelors             13   
    1   50  Self-emp-not-inc         83311  Bachelors             13   
    2   38           Private        215646    HS-grad              9   
    
           marital_status         occupation   relationship   race   sex  \
    0       Never-married       Adm-clerical  Not-in-family  White  Male   
    1  Married-civ-spouse    Exec-managerial        Husband  White  Male   
    2            Divorced  Handlers-cleaners  Not-in-family  White  Male   
    
       capital_gain  capital_loss  hours_per_week native_country salary  
    0          2174             0              40  United-States  <=50K  
    1             0             0              13  United-States  <=50K  
    2             0             0              40  United-States  <=50K  



```python
# convert the string labels to numeric labels
for label in ['race', 'occupation']:
    data[label] = LabelEncoder().fit_transform(data[label])
print(data.head(3))
```

       age         workclass  final_weight  education  education_num  \
    0   39         State-gov         77516  Bachelors             13   
    1   50  Self-emp-not-inc         83311  Bachelors             13   
    2   38           Private        215646    HS-grad              9   
    
           marital_status  occupation   relationship  race   sex  capital_gain  \
    0       Never-married           1  Not-in-family     4  Male          2174   
    1  Married-civ-spouse           4        Husband     4  Male             0   
    2            Divorced           6  Not-in-family     4  Male             0   
    
       capital_loss  hours_per_week native_country salary  
    0             0              40  United-States  <=50K  
    1             0              13  United-States  <=50K  
    2             0              40  United-States  <=50K  



```python
# take the fields of interest and plug them into variable X
X = data[['race', 'hours_per_week', 'occupation']]

# make sure to provide the corresponding truth value
Y = data['sex'].values.tolist()
```


```python
# split the data into a test (30%) and train set (70%)
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)

# set the training parameters
clf = RandomForestClassifier(n_estimators=1000)

# train on the train set
clf = clf.fit(X_train, Y_train)
```


```python
# validate the classifier
accuracy = clf.score(X_test, Y_test)
print('Accuracy: ' + str(accuracy))
```

    Accuracy: 0.738765482649



```python
# test
prediction = clf.predict(X_test)
print(prediction)
```

    ['Male' 'Female' 'Male' ..., 'Female' 'Male' 'Female']



```python
# create a confusion matrix
cm = confusion_matrix(prediction, Y_test)
print(cm)
```

    [[1568  970]
     [1582 5649]]


## Random Forests (with the Iris dataset)

Iris dataset.


```python
from sklearn.cross_validation import cross_val_score, train_test_split
import numpy as np
from sklearn import datasets
from sklearn.ensemble import RandomForestClassifier
from sklearn import preprocessing

iris = datasets.load_iris()
```


```python
# feature scaling
min_max_scaler = preprocessing.MinMaxScaler()
X = min_max_scaler.fit_transform(iris.data)

# train on the train set
clf = RandomForestClassifier(n_estimators=200)   
```


```python
# test our classifier
scores = cross_val_score(clf, X, iris.target, cv=5)

print("Accuracy: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))
```

    Accuracy: 0.97 (+/- 0.04)


## k-Nearest Neighbours


```python
import pandas as pd
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.cross_validation import train_test_split
from sklearn.metrics import confusion_matrix

# Import the adult.txt file into Python
data = pd.read_csv('data/adults.txt', sep=',')
print(data.head(3))
```

       age         workclass  final_weight  education  education_num  \
    0   39         State-gov         77516  Bachelors             13   
    1   50  Self-emp-not-inc         83311  Bachelors             13   
    2   38           Private        215646    HS-grad              9   
    
           marital_status         occupation   relationship   race   sex  \
    0       Never-married       Adm-clerical  Not-in-family  White  Male   
    1  Married-civ-spouse    Exec-managerial        Husband  White  Male   
    2            Divorced  Handlers-cleaners  Not-in-family  White  Male   
    
       capital_gain  capital_loss  hours_per_week native_country salary  
    0          2174             0              40  United-States  <=50K  
    1             0             0              13  United-States  <=50K  
    2             0             0              40  United-States  <=50K  



```python
# convert the string labels to numeric labels
for label in ['race', 'occupation']:
    data[label] = LabelEncoder().fit_transform(data[label])
print(data.head(3))
```

       age         workclass  final_weight  education  education_num  \
    0   39         State-gov         77516  Bachelors             13   
    1   50  Self-emp-not-inc         83311  Bachelors             13   
    2   38           Private        215646    HS-grad              9   
    
           marital_status  occupation   relationship  race   sex  capital_gain  \
    0       Never-married           1  Not-in-family     4  Male          2174   
    1  Married-civ-spouse           4        Husband     4  Male             0   
    2            Divorced           6  Not-in-family     4  Male             0   
    
       capital_loss  hours_per_week native_country salary  
    0             0              40  United-States  <=50K  
    1             0              13  United-States  <=50K  
    2             0              40  United-States  <=50K  



```python
# take the fields of interest and plug them into variable X
X = data[['race', 'hours_per_week', 'occupation']]

# make sure to provide the corresponding truth value
Y = data['sex'].values.tolist()
```


```python
# split the data into a test (30%) and train set (70%)
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)

# set the training parameters, instantiate the classifier
clf = KNeighborsClassifier(n_neighbors=3)

# train on the train set
clf = clf.fit(X_train, Y_train)
```


```python
# validate the classifier
accuracy = clf.score(X_test, Y_test)
print('Accuracy: ' + str(accuracy))
```

    Accuracy: 0.68113420002



```python
# create a confusion matrix
prediction = clf.predict(X_test)
```


```python
# test
cm = confusion_matrix(prediction, Y_test)
print(cm)
```

    [[1694 1591]
     [1524 4960]]


## Logistic regression


```python
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder
from sklearn.cross_validation import train_test_split
from sklearn.metrics import confusion_matrix

# import the adult.txt file into Python
data = pd.read_csv('data/adults.txt', sep=',')
print(data.head(3))
```

       age         workclass  final_weight  education  education_num  \
    0   39         State-gov         77516  Bachelors             13   
    1   50  Self-emp-not-inc         83311  Bachelors             13   
    2   38           Private        215646    HS-grad              9   
    
           marital_status         occupation   relationship   race   sex  \
    0       Never-married       Adm-clerical  Not-in-family  White  Male   
    1  Married-civ-spouse    Exec-managerial        Husband  White  Male   
    2            Divorced  Handlers-cleaners  Not-in-family  White  Male   
    
       capital_gain  capital_loss  hours_per_week native_country salary  
    0          2174             0              40  United-States  <=50K  
    1             0             0              13  United-States  <=50K  
    2             0             0              40  United-States  <=50K  



```python
# convert the string labels to numeric labels
for label in ['race', 'occupation']:
    data[label] = LabelEncoder().fit_transform(data[label])
print(data.head(3))
```

       age         workclass  final_weight  education  education_num  \
    0   39         State-gov         77516  Bachelors             13   
    1   50  Self-emp-not-inc         83311  Bachelors             13   
    2   38           Private        215646    HS-grad              9   
    
           marital_status  occupation   relationship  race   sex  capital_gain  \
    0       Never-married           1  Not-in-family     4  Male          2174   
    1  Married-civ-spouse           4        Husband     4  Male             0   
    2            Divorced           6  Not-in-family     4  Male             0   
    
       capital_loss  hours_per_week native_country salary  
    0             0              40  United-States  <=50K  
    1             0              13  United-States  <=50K  
    2             0              40  United-States  <=50K  



```python
# take the fields of interest and plug them into variable X
X = data[['race', 'hours_per_week', 'occupation']]

# make sure to provide the corresponding truth value
Y = data['sex'].values.tolist()
```


```python
# split the data into a test (30%) and train set (70%)
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)

# set the training parameters, instantiate the classifier
clf = LogisticRegression()

# train on the train set
clf = clf.fit(X_train, Y_train)
```


```python
# validate the classifier
accuracy = clf.score(X_test, Y_test)
print('Accuracy: ' + str(accuracy))
```

    Accuracy: 0.669259903777



```python
# create a confusion matrix
prediction = clf.predict(X_test)
print(prediction)
```

    ['Male' 'Male' 'Male' ..., 'Female' 'Female' 'Male']



```python
# test
cm = confusion_matrix(prediction, Y_test)
print(cm)
```

    [[ 459  419]
     [2812 6079]]


## Na√Øve Bayes


```python
import pandas as pd
from sklearn.naive_bayes import GaussianNB
from sklearn.preprocessing import LabelEncoder
from sklearn.cross_validation import train_test_split
from sklearn.metrics import confusion_matrix

# import the adult.txt file into Python
data = pd.read_csv('data/adults.txt', sep=',')
print(data.head(3))
```

       age         workclass  final_weight  education  education_num  \
    0   39         State-gov         77516  Bachelors             13   
    1   50  Self-emp-not-inc         83311  Bachelors             13   
    2   38           Private        215646    HS-grad              9   
    
           marital_status         occupation   relationship   race   sex  \
    0       Never-married       Adm-clerical  Not-in-family  White  Male   
    1  Married-civ-spouse    Exec-managerial        Husband  White  Male   
    2            Divorced  Handlers-cleaners  Not-in-family  White  Male   
    
       capital_gain  capital_loss  hours_per_week native_country salary  
    0          2174             0              40  United-States  <=50K  
    1             0             0              13  United-States  <=50K  
    2             0             0              40  United-States  <=50K  



```python
# convert the string labels to numeric labels
for label in ['race', 'occupation']:
    data[label] = LabelEncoder().fit_transform(data[label])
print(data.head(3))
```

       age         workclass  final_weight  education  education_num  \
    0   39         State-gov         77516  Bachelors             13   
    1   50  Self-emp-not-inc         83311  Bachelors             13   
    2   38           Private        215646    HS-grad              9   
    
           marital_status  occupation   relationship  race   sex  capital_gain  \
    0       Never-married           1  Not-in-family     4  Male          2174   
    1  Married-civ-spouse           4        Husband     4  Male             0   
    2            Divorced           6  Not-in-family     4  Male             0   
    
       capital_loss  hours_per_week native_country salary  
    0             0              40  United-States  <=50K  
    1             0              13  United-States  <=50K  
    2             0              40  United-States  <=50K  



```python
# take the fields of interest and plug them into variable X
X = data[['race', 'hours_per_week', 'occupation']]

# make sure to provide the corresponding truth value
Y = data['sex'].values.tolist()
```


```python
# split the data into a test (30%) and train set (70%)
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)

# set the training parameters, instantiate the classifier
clf = GaussianNB()

# train on the train set
clf = clf.fit(X_train, Y_train)
```


```python
# validate the classifier
accuracy = clf.score(X_test, Y_test)
print('Accuracy: ' + str(accuracy))
```

    Accuracy: 0.6612754632



```python
# create a confusion matrix
prediction = clf.predict(X_test)
print(prediction)
```

    ['Male' 'Male' 'Male' ..., 'Male' 'Male' 'Female']



```python
# test
cm = confusion_matrix(prediction, Y_test)
print(cm)
```

    [[ 674  721]
     [2588 5786]]


# Intermediate level (Additional)

## Principal Component Analysis


```python
import pandas as pd
from sklearn.decomposition import PCA
from sklearn.preprocessing import LabelEncoder

# import the adult.txt file into Python
data = pd.read_csv('data/adults.txt', sep=',')
print(data.head(3))
```

       age         workclass  final_weight  education  education_num  \
    0   39         State-gov         77516  Bachelors             13   
    1   50  Self-emp-not-inc         83311  Bachelors             13   
    2   38           Private        215646    HS-grad              9   
    
           marital_status         occupation   relationship   race   sex  \
    0       Never-married       Adm-clerical  Not-in-family  White  Male   
    1  Married-civ-spouse    Exec-managerial        Husband  White  Male   
    2            Divorced  Handlers-cleaners  Not-in-family  White  Male   
    
       capital_gain  capital_loss  hours_per_week native_country salary  
    0          2174             0              40  United-States  <=50K  
    1             0             0              13  United-States  <=50K  
    2             0             0              40  United-States  <=50K  



```python
# convert the string labels to numeric labels
for label in ['race', 'occupation', 'sex']:
    data[label] = LabelEncoder().fit_transform(data[label])
print(data.head(3))
```

       age         workclass  final_weight  education  education_num  \
    0   39         State-gov         77516  Bachelors             13   
    1   50  Self-emp-not-inc         83311  Bachelors             13   
    2   38           Private        215646    HS-grad              9   
    
           marital_status  occupation   relationship  race  sex  capital_gain  \
    0       Never-married           1  Not-in-family     4    1          2174   
    1  Married-civ-spouse           4        Husband     4    1             0   
    2            Divorced           6  Not-in-family     4    1             0   
    
       capital_loss  hours_per_week native_country salary  
    0             0              40  United-States  <=50K  
    1             0              13  United-States  <=50K  
    2             0              40  United-States  <=50K  



```python
print(data.shape)
```

    (32561, 15)



```python
# print one variable
print(data.sex.head(3))
```

    0    1
    1    1
    2    1
    Name: sex, dtype: int64



```python
# % Male
sum(data.sex)/len(data)
```




    0.66920549123184181




```python
# take the fields of interest and plug them into variable X
X = data[['age', 'final_weight', 'education_num', 'occupation', 'race', 'capital_gain', 'hours_per_week']]
```


```python
# create a regular PCA model 
# tell the model to only keep two components.
pca = PCA(n_components=2)

# Fit and transform the data to the model
reduced_data_pca = pca.fit_transform(X)

# Inspect the shape
print(reduced_data_pca.shape)
```

    (32561, 2)



```python
# Print out the data (array)
print(reduced_data_pca[0:3])
```

    [[-112262.33316766   -1099.76011639]
     [-106467.39923916    1074.41772634]
     [  25867.60075685    1078.43450794]]



```python
%pylab inline
import matplotlib.pyplot as plt

x = reduced_data_pca[:, 0]
y = reduced_data_pca[:, 1]

plt.scatter(x, y)

plt.xlabel('First Principal Component')
plt.ylabel('Second Principal Component')
plt.title("PCA Scatter Plot")

plt.show()
```

    Populating the interactive namespace from numpy and matplotlib



![png](output_78_1.png)



```python
male = [data.sex == 1][0:3]
type(male)
```




    list




```python
# Is Male?
male[0][0:3]
```




    0    True
    1    True
    2    True
    Name: sex, dtype: bool




```python
female = [data.sex == 0][0:3]

# Is Female?
female[0][0:3]
```




    0    False
    1    False
    2    False
    Name: sex, dtype: bool




```python
for i in range(len(colors)):
    print(i)
```

    0
    1



```python
data.sex = data.sex.astype(int)
data.head(3)
```




<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>workclass</th>
      <th>final_weight</th>
      <th>education</th>
      <th>education_num</th>
      <th>marital_status</th>
      <th>occupation</th>
      <th>relationship</th>
      <th>race</th>
      <th>sex</th>
      <th>capital_gain</th>
      <th>capital_loss</th>
      <th>hours_per_week</th>
      <th>native_country</th>
      <th>salary</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>39</td>
      <td>State-gov</td>
      <td>77516</td>
      <td>Bachelors</td>
      <td>13</td>
      <td>Never-married</td>
      <td>1</td>
      <td>Not-in-family</td>
      <td>4</td>
      <td>1</td>
      <td>2174</td>
      <td>0</td>
      <td>40</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>1</th>
      <td>50</td>
      <td>Self-emp-not-inc</td>
      <td>83311</td>
      <td>Bachelors</td>
      <td>13</td>
      <td>Married-civ-spouse</td>
      <td>4</td>
      <td>Husband</td>
      <td>4</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>13</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>2</th>
      <td>38</td>
      <td>Private</td>
      <td>215646</td>
      <td>HS-grad</td>
      <td>9</td>
      <td>Divorced</td>
      <td>6</td>
      <td>Not-in-family</td>
      <td>4</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>40</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
  </tbody>
</table>
</div>




```python
colors = ['blue', 
          'red']

# colors = ['black','blue','purple','yellow','white','red','lime','cyan','orange','gray']

# 0 Female, blue
# 1 Male, red
for i in range(len(colors)):
    x = reduced_data_pca[:, 0]*[data.sex == i]
    y = reduced_data_pca[:, 1]*[data.sex == i]
    plt.scatter(x, y, c=colors[i]) 

# 0 Female, 1 Male
plt.legend(['Female','Male'], 
           bbox_to_anchor=(1.05, 1), 
           loc=2, 
           borderaxespad=0.)

plt.xlabel('First Principal Component')
plt.ylabel('Second Principal Component')
plt.title("PCA Scatter Plot")

plt.show()
```


![png](output_84_0.png)


## Support Vector Machines


```python
import pandas as pd
from sklearn import svm
from sklearn.preprocessing import LabelEncoder
from sklearn.cross_validation import train_test_split
from sklearn.metrics import confusion_matrix

# import the adult.txt file into Python
data = pd.read_csv('data/adults.txt', sep=',')
print(data.head(3))
```

       age         workclass  final_weight  education  education_num  \
    0   39         State-gov         77516  Bachelors             13   
    1   50  Self-emp-not-inc         83311  Bachelors             13   
    2   38           Private        215646    HS-grad              9   
    
           marital_status         occupation   relationship   race   sex  \
    0       Never-married       Adm-clerical  Not-in-family  White  Male   
    1  Married-civ-spouse    Exec-managerial        Husband  White  Male   
    2            Divorced  Handlers-cleaners  Not-in-family  White  Male   
    
       capital_gain  capital_loss  hours_per_week native_country salary  
    0          2174             0              40  United-States  <=50K  
    1             0             0              13  United-States  <=50K  
    2             0             0              40  United-States  <=50K  



```python
# convert the string labels to numeric labels
for label in ['race', 'occupation']:
    data[label] = LabelEncoder().fit_transform(data[label])
print(data.head(3))
```

       age         workclass  final_weight  education  education_num  \
    0   39         State-gov         77516  Bachelors             13   
    1   50  Self-emp-not-inc         83311  Bachelors             13   
    2   38           Private        215646    HS-grad              9   
    
           marital_status  occupation   relationship  race   sex  capital_gain  \
    0       Never-married           1  Not-in-family     4  Male          2174   
    1  Married-civ-spouse           4        Husband     4  Male             0   
    2            Divorced           6  Not-in-family     4  Male             0   
    
       capital_loss  hours_per_week native_country salary  
    0             0              40  United-States  <=50K  
    1             0              13  United-States  <=50K  
    2             0              40  United-States  <=50K  



```python
# take the fields of interest and plug them into variable X
X = data[['race', 'hours_per_week', 'occupation']]

# make sure to provide the corresponding truth value
Y = data['sex'].values.tolist()
```


```python
# split the data into a test (30%) and train set (70%)
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)

# Create the SVC model
clf = svm.SVC(gamma=0.001, C=100., kernel='linear')

# Fit the data to the SVC model
clf = clf.fit(X_train, Y_train)
```


```python
# validate the classifier
accuracy = clf.score(X_test, Y_test)
print('Accuracy: ' + str(accuracy))
```


```python
# create a confusion matrix
prediction = clf.predict(X_test)
print(prediction)
```


```python
# test
cm = confusion_matrix(prediction, Y_test)
print(cm)
```

# A little application

**Append each result in a dictionary**

```python
index = np.argmax([acc_model1, acc_model2])
classifiers = {0: 'model1', 1: 'model2}
print('Best classifier is {}'.format(classifiers[index]))
```
