



<!DOCTYPE html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
        <meta name="description" content="A Python documentation website.">
      
      
        <link rel="canonical" href="https://ugoproto.github.io/ugo_py_doc/k-NN_Linear_regression_Logit_Scaling_Centering_Noise/">
      
      
        <meta name="author" content="Ugo Sparks">
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="en">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="../img/favicon.ico">
      <meta name="generator" content="mkdocs-0.17.3, mkdocs-material-2.7.0">
    
    
      
        <title>k-NN, Linear regression, Logit, Scaling, Centering, Noise - ugo_py_doc</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/application.78aab2dc.css">
      
        <link rel="stylesheet" href="../assets/stylesheets/application-palette.6079476c.css">
      
    
    
      <script src="../assets/javascripts/modernizr.1aa3b519.js"></script>
    
    
      <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
      
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:300,400,400i,700|Ubuntu+Mono">
        <style>body,input{font-family:"Ubuntu","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Ubuntu Mono","Courier New",Courier,monospace}</style>
      
      <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
    
    
    
  </head>
  
    
    
    <body dir="ltr" data-md-color-primary="yellow" data-md-color-accent="indigo">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448"
    viewBox="0 0 416 448" id="github">
  <path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19-18.125
        8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19 18.125-8.5
        18.125 8.5 10.75 19 3.125 20.5zM320 304q0 10-3.125 20.5t-10.75
        19-18.125 8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19
        18.125-8.5 18.125 8.5 10.75 19 3.125 20.5zM360
        304q0-30-17.25-51t-46.75-21q-10.25 0-48.75 5.25-17.75 2.75-39.25
        2.75t-39.25-2.75q-38-5.25-48.75-5.25-29.5 0-46.75 21t-17.25 51q0 22 8
        38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0
        37.25-1.75t35-7.375 30.5-15 20.25-25.75 8-38.375zM416 260q0 51.75-15.25
        82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5-41.75
        1.125q-19.5 0-35.5-0.75t-36.875-3.125-38.125-7.5-34.25-12.875-30.25-20.25-21.5-28.75q-15.5-30.75-15.5-82.75
        0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25
        30.875q36.75-8.75 77.25-8.75 37 0 70 8 26.25-20.5
        46.75-30.25t47.25-9.75q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34
        99.5z" />
</svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="drawer">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="search">
    <label class="md-overlay" data-md-component="overlay" for="drawer"></label>
    
      <a href="#k-nearest-neighbours" tabindex="1" class="md-skip">
        Skip to content
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="https://ugoproto.github.io/ugo_py_doc/" title="ugo_py_doc" class="md-header-nav__button md-logo">
          
            <i class="md-icon">layers</i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            
              <span class="md-header-nav__topic">
                ugo_py_doc
              </span>
              <span class="md-header-nav__topic">
                k-NN, Linear regression, Logit, Scaling, Centering, Noise
              </span>
            
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          
            <label class="md-icon md-icon--search md-header-nav__button" for="search"></label>
            
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
          
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  


  <a href="https://github.com/ugoproto/ugo_r_doc.git/" title="Go to repository" class="md-source" data-md-source="github">
    
      <div class="md-source__icon">
        <svg viewBox="0 0 24 24" width="24" height="24">
          <use xlink:href="#github" width="24" height="24"></use>
        </svg>
      </div>
    
    <div class="md-source__repository">
      ugo_py_doc
    </div>
  </a>

          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="drawer">
    <span class="md-nav__button md-logo">
      
        <i class="md-icon">layers</i>
      
    </span>
    ugo_py_doc
  </label>
  
    <div class="md-nav__source">
      


  


  <a href="https://github.com/ugoproto/ugo_r_doc.git/" title="Go to repository" class="md-source" data-md-source="github">
    
      <div class="md-source__icon">
        <svg viewBox="0 0 24 24" width="24" height="24">
          <use xlink:href="#github" width="24" height="24"></use>
        </svg>
      </div>
    
    <div class="md-source__repository">
      ugo_py_doc
    </div>
  </a>

    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href=".." title="Home" class="md-nav__link">
      Home
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2">
    
    <label class="md-nav__link" for="nav-2">
      Basics
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        Basics
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../Py_CS/" title="Python Cheat Sheets" class="md-nav__link">
      Python Cheat Sheets
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Python_Preliminaries/" title="Python Preliminaries" class="md-nav__link">
      Python Preliminaries
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Python_Nice_to_Have/" title="Python Nice to Have" class="md-nav__link">
      Python Nice to Have
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Freeze_the_Code/" title="Freeze the Code" class="md-nav__link">
      Freeze the Code
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Decorators/" title="Decorators" class="md-nav__link">
      Decorators
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Write_Better_Python/" title="Write Better Python with PEP" class="md-nav__link">
      Write Better Python with PEP
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Regex/" title="Regular Expressions (regex)" class="md-nav__link">
      Regular Expressions (regex)
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Databases/" title="Databases" class="md-nav__link">
      Databases
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Datetime/" title="Datetime" class="md-nav__link">
      Datetime
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Gedit_Execute_Highlighted_Python_Code/" title="Gedit, Execute Highlighted Python Code" class="md-nav__link">
      Gedit, Execute Highlighted Python Code
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3" checked>
    
    <label class="md-nav__link" for="nav-3">
      Scipy Stack
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        Scipy Stack
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../Scipy_CS/" title="Scipy Stack Cheat Sheets" class="md-nav__link">
      Scipy Stack Cheat Sheets
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../JN_CS/" title="Jupyter Notebook Cheat Sheets" class="md-nav__link">
      Jupyter Notebook Cheat Sheets
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Scientific Python/" title="Scientific Python" class="md-nav__link">
      Scientific Python
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Importing Data into Python/" title="Importing Data into Python" class="md-nav__link">
      Importing Data into Python
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Python for Data Science/" title="Python for Data Science" class="md-nav__link">
      Python for Data Science
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Tidy_Data_in_Python/" title="Tidy Data in Python" class="md-nav__link">
      Tidy Data in Python
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Lists/" title="Lists" class="md-nav__link">
      Lists
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../IPython Notebook/" title="IPython Notebook, Collection" class="md-nav__link">
      IPython Notebook, Collection
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Python Numpy Arrays/" title="Python Numpy Arrays" class="md-nav__link">
      Python Numpy Arrays
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Vectors and Arrays (Linear Algebra)/" title="Vectors and Arrays (Linear Algebra)" class="md-nav__link">
      Vectors and Arrays (Linear Algebra)
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Matplotlib, Python Plotting/" title="Matplotlib, Python Plotting" class="md-nav__link">
      Matplotlib, Python Plotting
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Viewing+3D+Volumetric+Data+With+Matplotlib/" title="Viewing 3D Volumetric Data with Matplotlib" class="md-nav__link">
      Viewing 3D Volumetric Data with Matplotlib
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Seaborn, Python Statistical Data Visualization Library/" title="Seaborn, Python's Statistical Data Visualization Library" class="md-nav__link">
      Seaborn, Python's Statistical Data Visualization Library
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Pandas+DataFrames/" title="Pandas DataFrames" class="md-nav__link">
      Pandas DataFrames
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Write Idiomatic Pandas Code/" title="Write Idiomatic Pandas Code" class="md-nav__link">
      Write Idiomatic Pandas Code
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Exploratory Data Analysis/" title="Exploratory Data Analysis (EDA)" class="md-nav__link">
      Exploratory Data Analysis (EDA)
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Intro to data.world in Python/" title="Intro to data.world in Python" class="md-nav__link">
      Intro to data.world in Python
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Python+And+Excel/" title="Python and Excel" class="md-nav__link">
      Python and Excel
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Overview_of_scikit-learn/" title="Overview of scikit-learn" class="md-nav__link">
      Overview of scikit-learn
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="toc">
    
    
      <label class="md-nav__link md-nav__link--active" for="toc">
        k-NN, Linear regression, Logit, Scaling, Centering, Noise
      </label>
    
    <a href="./" title="k-NN, Linear regression, Logit, Scaling, Centering, Noise" class="md-nav__link md-nav__link--active">
      k-NN, Linear regression, Logit, Scaling, Centering, Noise
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
  
    <label class="md-nav__title" for="toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#k-nearest-neighbours" title="k-Nearest Neighbours" class="md-nav__link">
    k-Nearest Neighbours
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#measure-performance" title="Measure performance" class="md-nav__link">
    Measure performance
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train-test-split-and-performance-in-practice" title="Train-test split and performance in practice" class="md-nav__link">
    Train-test split and performance in practice
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#preprocessing-scaling-and-centering-the-data" title="Preprocessing: scaling and centering the data" class="md-nav__link">
    Preprocessing: scaling and centering the data
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#k-nn-scaling-in-practice" title="k-NN: scaling in practice" class="md-nav__link">
    k-NN: scaling in practice
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#scale-the-data" title="Scale the data" class="md-nav__link">
    Scale the data
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-the-k-nn" title="Run the k-NN" class="md-nav__link">
    Run the k-NN
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#measure-the-performance" title="Measure the performance" class="md-nav__link">
    Measure the performance
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#k-nn-recap" title="k-NN Recap" class="md-nav__link">
    k-NN Recap
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#without-scaling" title="Without scaling" class="md-nav__link">
    Without scaling
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#with-scaling" title="With scaling" class="md-nav__link">
    With scaling
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#linear-regression" title="Linear regression" class="md-nav__link">
    Linear regression
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#logistic-regression-logit" title="Logistic regression (Logit)" class="md-nav__link">
    Logistic regression (Logit)
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#with-random-numbers" title="With random numbers" class="md-nav__link">
    With random numbers
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#with-the-wine-dataset" title="With the Wine dataset" class="md-nav__link">
    With the Wine dataset
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#scale-the-data_1" title="Scale the data" class="md-nav__link">
    Scale the data
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-the-logit-and-measure-the-performance" title="Run the Logit and measure the performance" class="md-nav__link">
    Run the Logit and measure the performance
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#logit-recap" title="Logit Recap" class="md-nav__link">
    Logit Recap
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#without-scaling_1" title="Without scaling" class="md-nav__link">
    Without scaling
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#noise-and-scaling" title="Noise and scaling" class="md-nav__link">
    Noise and scaling
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#plotting-the-synthesized-data" title="Plotting the synthesized data" class="md-nav__link">
    Plotting the synthesized data
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#k-nearest-neighbours_1" title="k-Nearest Neighbours" class="md-nav__link">
    k-Nearest Neighbours
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#scale-the-data-run-the-k-nn-and-measure-the-performance" title="Scale the data, run the k-NN, and measure the performance" class="md-nav__link">
    Scale the data, run the k-NN, and measure the performance
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#add-noise-to-the-signal" title="Add noise to the signal" class="md-nav__link">
    Add noise to the signal
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-the-k-nn-and-measure-the-performance" title="Run the k-NN and measure the performance" class="md-nav__link">
    Run the k-NN and measure the performance
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#scale-the-data-add-noise-run-the-k-nn-and-measure-the-performance" title="Scale the data, add noise, run the k-NN, and measure the performance" class="md-nav__link">
    Scale the data, add noise, run the k-NN, and measure the performance
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#noise-strength-vs-accuracy-and-the-need-for-scaling" title="Noise strength vs. accuracy (and the need for scaling)" class="md-nav__link">
    Noise strength vs. accuracy (and the need for scaling)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#logit-repeat-the-k-nn-procedure" title="Logit (Repeat the k-NN procedure)" class="md-nav__link">
    Logit (Repeat the k-NN procedure)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Time_Series_Analysis/" title="Time Series Analysis" class="md-nav__link">
      Time Series Analysis
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Sentiment_Analysis_with_Twitter/" title="Sentiment Analysis with Twitter" class="md-nav__link">
      Sentiment Analysis with Twitter
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../EDA_Machine_Learning_Feature_Engineering_and_Kaggle/" title="EDA, Machine Learning, Feature Engineering, and Kaggle" class="md-nav__link">
      EDA, Machine Learning, Feature Engineering, and Kaggle
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4" type="checkbox" id="nav-4">
    
    <label class="md-nav__link" for="nav-4">
      Courses
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-4">
        Courses
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../Apprenez a programmer en Python/" title="Apprenez à programmer en Python" class="md-nav__link">
      Apprenez à programmer en Python
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Codecademy Python/" title="Codecademy Python" class="md-nav__link">
      Codecademy Python
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Learn Python the Hard Way/" title="Learn Python the Hard Way" class="md-nav__link">
      Learn Python the Hard Way
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../LPTHW, Python Code Snippets/" title="LPTHW, Python Code Snippets" class="md-nav__link">
      LPTHW, Python Code Snippets
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Introduction to Python/" title="Introduction to Python" class="md-nav__link">
      Introduction to Python
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5" type="checkbox" id="nav-5">
    
    <label class="md-nav__link" for="nav-5">
      Manuals
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-5">
        Manuals
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../Automate the Boring Stuff with Python/" title="Automate the Boring Stuff with Python" class="md-nav__link">
      Automate the Boring Stuff with Python
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Real_Python/" title="Real Python" class="md-nav__link">
      Real Python
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Managing Your Biological Data with Python/" title="Managing Your Biological Data with Python" class="md-nav__link">
      Managing Your Biological Data with Python
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Python for Education/" title="Python for Education" class="md-nav__link">
      Python for Education
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
  
    <label class="md-nav__title" for="toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#k-nearest-neighbours" title="k-Nearest Neighbours" class="md-nav__link">
    k-Nearest Neighbours
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#measure-performance" title="Measure performance" class="md-nav__link">
    Measure performance
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#train-test-split-and-performance-in-practice" title="Train-test split and performance in practice" class="md-nav__link">
    Train-test split and performance in practice
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#preprocessing-scaling-and-centering-the-data" title="Preprocessing: scaling and centering the data" class="md-nav__link">
    Preprocessing: scaling and centering the data
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#k-nn-scaling-in-practice" title="k-NN: scaling in practice" class="md-nav__link">
    k-NN: scaling in practice
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#scale-the-data" title="Scale the data" class="md-nav__link">
    Scale the data
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-the-k-nn" title="Run the k-NN" class="md-nav__link">
    Run the k-NN
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#measure-the-performance" title="Measure the performance" class="md-nav__link">
    Measure the performance
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#k-nn-recap" title="k-NN Recap" class="md-nav__link">
    k-NN Recap
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#without-scaling" title="Without scaling" class="md-nav__link">
    Without scaling
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#with-scaling" title="With scaling" class="md-nav__link">
    With scaling
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#linear-regression" title="Linear regression" class="md-nav__link">
    Linear regression
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#logistic-regression-logit" title="Logistic regression (Logit)" class="md-nav__link">
    Logistic regression (Logit)
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#with-random-numbers" title="With random numbers" class="md-nav__link">
    With random numbers
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#with-the-wine-dataset" title="With the Wine dataset" class="md-nav__link">
    With the Wine dataset
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#scale-the-data_1" title="Scale the data" class="md-nav__link">
    Scale the data
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-the-logit-and-measure-the-performance" title="Run the Logit and measure the performance" class="md-nav__link">
    Run the Logit and measure the performance
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#logit-recap" title="Logit Recap" class="md-nav__link">
    Logit Recap
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#without-scaling_1" title="Without scaling" class="md-nav__link">
    Without scaling
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#noise-and-scaling" title="Noise and scaling" class="md-nav__link">
    Noise and scaling
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#plotting-the-synthesized-data" title="Plotting the synthesized data" class="md-nav__link">
    Plotting the synthesized data
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#k-nearest-neighbours_1" title="k-Nearest Neighbours" class="md-nav__link">
    k-Nearest Neighbours
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#scale-the-data-run-the-k-nn-and-measure-the-performance" title="Scale the data, run the k-NN, and measure the performance" class="md-nav__link">
    Scale the data, run the k-NN, and measure the performance
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#add-noise-to-the-signal" title="Add noise to the signal" class="md-nav__link">
    Add noise to the signal
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#run-the-k-nn-and-measure-the-performance" title="Run the k-NN and measure the performance" class="md-nav__link">
    Run the k-NN and measure the performance
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#scale-the-data-add-noise-run-the-k-nn-and-measure-the-performance" title="Scale the data, add noise, run the k-NN, and measure the performance" class="md-nav__link">
    Scale the data, add noise, run the k-NN, and measure the performance
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#noise-strength-vs-accuracy-and-the-need-for-scaling" title="Noise strength vs. accuracy (and the need for scaling)" class="md-nav__link">
    Noise strength vs. accuracy (and the need for scaling)
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#logit-repeat-the-k-nn-procedure" title="Logit (Repeat the k-NN procedure)" class="md-nav__link">
    Logit (Repeat the k-NN procedure)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/ugoproto/ugo_r_doc.git/edit/master/docs/k-NN_Linear_regression_Logit_Scaling_Centering_Noise.md" title="Edit this page" class="md-icon md-content__icon">&#xE3C9;</a>
                
                
                  <h1>k-NN, Linear regression, Logit, Scaling, Centering, Noise</h1>
                
                <div class="toc"><span class="toctitle">CONTENT</span><ul>
<li><a href="#load-and-explore-the-wine-dataset">Load and explore the Wine dataset</a></li>
<li><a href="#k-nearest-neighbours">k-Nearest Neighbours</a><ul>
<li><a href="#measure-performance">Measure performance</a></li>
<li><a href="#train-test-split-and-performance-in-practice">Train-test split and performance in practice</a></li>
</ul>
</li>
<li><a href="#preprocessing-scaling-and-centering-the-data">Preprocessing: scaling and centering the data</a></li>
<li><a href="#k-nn-scaling-in-practice">k-NN: scaling in practice</a><ul>
<li><a href="#scale-the-data">Scale the data</a></li>
<li><a href="#run-the-k-nn">Run the k-NN</a></li>
<li><a href="#measure-the-performance">Measure the performance</a></li>
</ul>
</li>
<li><a href="#k-nn-recap">k-NN Recap</a><ul>
<li><a href="#without-scaling">Without scaling</a></li>
<li><a href="#with-scaling">With scaling</a></li>
</ul>
</li>
<li><a href="#linear-regression">Linear regression</a></li>
<li><a href="#logistic-regression-logit">Logistic regression (Logit)</a><ul>
<li><a href="#with-random-numbers">With random numbers</a></li>
<li><a href="#with-the-wine-dataset">With the Wine dataset</a></li>
<li><a href="#scale-the-data_1">Scale the data</a></li>
<li><a href="#run-the-logit-and-measure-the-performance">Run the Logit and measure the performance</a></li>
</ul>
</li>
<li><a href="#logit-recap">Logit Recap</a><ul>
<li><a href="#without-scaling_1">Without scaling</a></li>
</ul>
</li>
<li><a href="#noise-and-scaling">Noise and scaling</a><ul>
<li><a href="#plotting-the-synthesized-data">Plotting the synthesized data</a></li>
<li><a href="#k-nearest-neighbours_1">k-Nearest Neighbours</a><ul>
<li><a href="#scale-the-data-run-the-k-nn-and-measure-the-performance">Scale the data, run the k-NN, and measure the performance</a></li>
<li><a href="#add-noise-to-the-signal">Add noise to the signal</a></li>
<li><a href="#run-the-k-nn-and-measure-the-performance">Run the k-NN and measure the performance</a></li>
<li><a href="#scale-the-data-add-noise-run-the-k-nn-and-measure-the-performance">Scale the data, add noise, run the k-NN, and measure the performance</a></li>
</ul>
</li>
<li><a href="#noise-strength-vs-accuracy-and-the-need-for-scaling">Noise strength vs. accuracy (and the need for scaling)</a></li>
<li><a href="#logit-repeat-the-k-nn-procedure">Logit (Repeat the k-NN procedure)</a></li>
</ul>
</li>
</ul>
</div>
<hr />
<p><strong>Foreword</strong></p>
<p>Code snippets and excerpts from the tutorial. Python 3. From DataCamp.</p>
<hr />
<h3 id="load-and-explore-the-wine-dataset">Load and explore the Wine dataset<a class="headerlink" href="#load-and-explore-the-wine-dataset" title="Permanent link">&para;</a></h3>
<p>We use the <a href="http://archive.ics.uci.edu/ml/datasets/Wine+Quality">wine quality dataset</a> related to red and white vinho verde wine samples, from the north of Portugal.</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># import the modules</span>
<span class="o">%</span><span class="n">pylab</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>

<span class="c1"># set the style</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;ggplot&#39;</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>Populating the interactive namespace from numpy and matplotlib
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># import the data</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv &#39;</span> <span class="p">,</span> <span class="n">sep</span> <span class="o">=</span> <span class="s1">&#39;;&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fixed acidity</th>
      <th>volatile acidity</th>
      <th>citric acid</th>
      <th>residual sugar</th>
      <th>chlorides</th>
      <th>free sulfur dioxide</th>
      <th>total sulfur dioxide</th>
      <th>density</th>
      <th>pH</th>
      <th>sulphates</th>
      <th>alcohol</th>
      <th>quality</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>7.4</td>
      <td>0.70</td>
      <td>0.00</td>
      <td>1.9</td>
      <td>0.076</td>
      <td>11.0</td>
      <td>34.0</td>
      <td>0.9978</td>
      <td>3.51</td>
      <td>0.56</td>
      <td>9.4</td>
      <td>5</td>
    </tr>
    <tr>
      <th>1</th>
      <td>7.8</td>
      <td>0.88</td>
      <td>0.00</td>
      <td>2.6</td>
      <td>0.098</td>
      <td>25.0</td>
      <td>67.0</td>
      <td>0.9968</td>
      <td>3.20</td>
      <td>0.68</td>
      <td>9.8</td>
      <td>5</td>
    </tr>
    <tr>
      <th>2</th>
      <td>7.8</td>
      <td>0.76</td>
      <td>0.04</td>
      <td>2.3</td>
      <td>0.092</td>
      <td>15.0</td>
      <td>54.0</td>
      <td>0.9970</td>
      <td>3.26</td>
      <td>0.65</td>
      <td>9.8</td>
      <td>5</td>
    </tr>
  </tbody>
</table>
</div>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># drop target variable</span>
<span class="c1"># only keep the values; the DataFrame becomes a simple array (matrix)</span>
<span class="c1"># index (axis=0 / ‘index’) or columns (axis=1 / ‘columns’).</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;quality&#39;</span> <span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>

<span class="c1"># print the array</span>
<span class="k">print</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">[[  7.4     0.7     0.    ...,   3.51    0.56    9.4  ]</span>
 <span class="k">[  7.8     0.88    0.    ...,   3.2     0.68    9.8  ]</span>
 <span class="k">[  7.8     0.76    0.04  ...,   3.26    0.65    9.8  ]</span>
 <span class="na">..., </span>
 <span class="k">[  6.3     0.51    0.13  ...,   3.42    0.75   11.   ]</span>
 <span class="k">[  5.9     0.645   0.12  ...,   3.57    0.71   10.2  ]</span>
 <span class="k">[  6.      0.31    0.47  ...,   3.39    0.66   11.   ]]</span>
</pre></div>
</td></tr></table>

<p>The last column is gone from the array. Make it a list instead (or a single-row array).</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">y1</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;quality&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

<span class="c1"># print the single-row array</span>
<span class="k">print</span><span class="p">(</span><span class="n">y1</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>[5 5 5 ..., 6 5 6]
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># row, col of the DataFrame</span>
<span class="n">df</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>(1599, 12)
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># plot all the columns or variables</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">[</span><span class="mi">15</span><span class="p">,</span><span class="mi">15</span><span class="p">]);</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</td></tr></table>

<p><img alt="" src="../img/k-NN_linear_regression/output_8_0.png" /></p>
<p>Notice the range of each variable; some are wider.</p>
<p>Any algorithm, such as k-NN, which cares about the distance between data points. This motivates scaling our data.</p>
<p>Let us turn it into a two-category variable consisting of &lsquo;good&rsquo; (rating &gt; 5) &amp; &lsquo;bad&rsquo; (rating &lt;= 5) qualities.</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">y1</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>[5 5 5 ..., 6 5 6]
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># is the rating &lt;= 5 ?</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">y1</span> <span class="o">&lt;=</span> <span class="mi">5</span>
<span class="k">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>[ True  True  True ..., False  True False]
</pre></div>
</td></tr></table>

<p><code class="codehilite">True</code> is worth 1 and <code class="codehilite">False</code> is worth 0.</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># plot two histograms</span>
<span class="c1"># the original target variable</span>
<span class="c1"># and the aggregated target variable</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">5</span><span class="p">));</span>

<span class="c1"># left plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span> <span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">y1</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;original target value&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;count&#39;</span><span class="p">)</span>

<span class="c1"># right plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;aggregated target value&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</td></tr></table>

<p><img alt="" src="../img/k-NN_linear_regression/output_13_0.png" /></p>
<p>Again, on the right histogram, <code class="codehilite">True</code> = 1 and <code class="codehilite">False</code> = 0.</p>
<h3 id="k-nearest-neighbours">k-Nearest Neighbours<a class="headerlink" href="#k-nearest-neighbours" title="Permanent link">&para;</a></h3>
<h4 id="measure-performance">Measure performance<a class="headerlink" href="#measure-performance" title="Permanent link">&para;</a></h4>
<p><strong>Accuracy</strong> is the default scoring method for both</p>
<ul>
<li>k-Nearest Neighbours and</li>
<li>logistic regression.</li>
</ul>
<div>
<div class="MathJax_Preview">\text{Accuracy}=\frac{\text{Number of Correct Predictions}}{\text{Total Number of Predictions}}</div>
<script type="math/tex; mode=display">\text{Accuracy}=\frac{\text{Number of Correct Predictions}}{\text{Total Number of Predictions}}</script>
</div>
<p>Accuracy is commonly defined for binary classification problems in terms of true positives &amp; false negatives. It can also be defined in terms of a <a href="https://en.wikipedia.org/wiki/Confusion_matrix">confusion matrix</a>. </p>
<p><a href="https://machinelearningmastery.com/classification-accuracy-is-not-enough-more-performance-measures-you-can-use/">Other measures</a> of model performance are derived from the confusion matrix: <strong>precision</strong> (true positives divided by the number of true &amp; false positives) and <strong>recall</strong> (number of true positives divided by the number of true positives plus the number of false negatives). </p>
<p>The <strong><a href="https://en.wikipedia.org/wiki/F1_score">F1-score</a></strong> is the harmonic mean of the precision and the recall.</p>
<h4 id="train-test-split-and-performance-in-practice">Train-test split and performance in practice<a class="headerlink" href="#train-test-split-and-performance-in-practice" title="Permanent link">&para;</a></h4>
<p>The rule of thumb is to use approximately </p>
<ul>
<li>80% of the data for training (train set) and</li>
<li>20% for testing (test set).</li>
</ul>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> 
                                                    <span class="n">y</span><span class="p">,</span> 
                                                    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> 
                                                    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># the k-NN model</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">neighbors</span><span class="p">,</span> <span class="n">linear_model</span>

<span class="n">knn</span> <span class="o">=</span> <span class="n">neighbors</span><span class="o">.</span><span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">knn_model_1</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="s1">&#39;k-NN score for test set: </span><span class="si">%f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">knn_model_1</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;k-NN score for training set: </span><span class="si">%f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">knn_model_1</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>k-NN score for test set: 0.612500
k-NN score for training set: 0.774042
</pre></div>
</td></tr></table>

<p>The accuracy, more specifically the test accuracy, is not great.</p>
<p>Let us print out all the <em>other</em> performance measures for the test set.</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>

<span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">knn_model_1</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>             precision    recall  f1-score   support

      False       0.66      0.64      0.65       179
       True       0.56      0.57      0.57       141

avg / total       0.61      0.61      0.61       320
</pre></div>
</td></tr></table>

<p><em>Other</em> performance measures for the train set.</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">knn_model_1</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>             precision    recall  f1-score   support

      False       0.80      0.76      0.78       676
       True       0.75      0.79      0.77       603

avg / total       0.78      0.77      0.77      1279
</pre></div>
</td></tr></table>

<p>These underperformances might come from the spread in the variables. The range of each variable is different; some are wider.</p>
<h3 id="preprocessing-scaling-and-centering-the-data">Preprocessing: scaling and centering the data<a class="headerlink" href="#preprocessing-scaling-and-centering-the-data" title="Permanent link">&para;</a></h3>
<p>Preprocessing happens before running any model, such as a regression (predicting a continuous variable) or a classification (predicting a discrete variable) using one or another model (k-NN, logistic, decision tree, random forests etc.).</p>
<p>For numerical variables, it is common to either normalize or standardize the data.</p>
<p><strong>Normalization</strong>: <strong>scaling</strong> a dataset so that its minimum is 0 and its maximum 1.</p>
<div>
<div class="MathJax_Preview">x_{normalized} = \frac{x-x_{min}}{x_{max}-x_{min}}</div>
<script type="math/tex; mode=display">x_{normalized} = \frac{x-x_{min}}{x_{max}-x_{min}}</script>
</div>
<p><strong>Stardardization</strong>: <strong>centering</strong> the data around 0 and to scale with respect to the standard deviation.</p>
<div>
<div class="MathJax_Preview">x_{standardized} = \frac{x-\mu}{\sigma}</div>
<script type="math/tex; mode=display">x_{standardized} = \frac{x-\mu}{\sigma}</script>
</div>
<p>where <span><span class="MathJax_Preview">\mu</span><script type="math/tex">\mu</script></span> and <span><span class="MathJax_Preview">\sigma</span><script type="math/tex">\sigma</script></span> are the mean and standard deviation of the dataset.</p>
<p>There are other transformatoions, such as the log transformation or the Box-Cox transformation, to make the data look more Gaussian or a normally distributed.</p>
<h3 id="k-nn-scaling-in-practice">k-NN: scaling in practice<a class="headerlink" href="#k-nn-scaling-in-practice" title="Permanent link">&para;</a></h3>
<h4 id="scale-the-data">Scale the data<a class="headerlink" href="#scale-the-data" title="Permanent link">&para;</a></h4>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">[[  7.4     0.7     0.    ...,   3.51    0.56    9.4  ]</span>
 <span class="k">[  7.8     0.88    0.    ...,   3.2     0.68    9.8  ]</span>
 <span class="k">[  7.8     0.76    0.04  ...,   3.26    0.65    9.8  ]</span>
 <span class="na">..., </span>
 <span class="k">[  6.3     0.51    0.13  ...,   3.42    0.75   11.   ]</span>
 <span class="k">[  5.9     0.645   0.12  ...,   3.57    0.71   10.2  ]</span>
 <span class="k">[  6.      0.31    0.47  ...,   3.39    0.66   11.   ]]</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">scale</span>

<span class="c1"># minimum is 0 and its maximum 1</span>
<span class="n">Xs</span> <span class="o">=</span> <span class="n">scale</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">Xs</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>[[-0.52835961  0.96187667 -1.39147228 ...,  1.28864292 -0.57920652
  -0.96024611]
 [-0.29854743  1.96744245 -1.39147228 ..., -0.7199333   0.1289504
  -0.58477711]
 [-0.29854743  1.29706527 -1.18607043 ..., -0.33117661 -0.04808883
  -0.58477711]
 ..., 
 [-1.1603431  -0.09955388 -0.72391627 ...,  0.70550789  0.54204194
   0.54162988]
 [-1.39015528  0.65462046 -0.77526673 ...,  1.6773996   0.30598963
  -0.20930812]
 [-1.33270223 -1.21684919  1.02199944 ...,  0.51112954  0.01092425
   0.54162988]]
</pre></div>
</td></tr></table>

<h4 id="run-the-k-nn">Run the k-NN<a class="headerlink" href="#run-the-k-nn" title="Permanent link">&para;</a></h4>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7
8
9</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="c1"># split</span>
<span class="c1"># 80% of the data for training (train set)</span>
<span class="c1"># 20% for testing (test set)</span>
<span class="n">Xs_train</span><span class="p">,</span> <span class="n">Xs_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">Xs</span><span class="p">,</span>
                                                      <span class="n">y</span><span class="p">,</span>
                                                      <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
                                                      <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Run</span>
<span class="n">knn_model_2</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xs_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<h4 id="measure-the-performance">Measure the performance<a class="headerlink" href="#measure-the-performance" title="Permanent link">&para;</a></h4>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="s1">&#39;k-NN score for test set: </span><span class="si">%f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">knn_model_2</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">Xs_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;k-NN score for training set: </span><span class="si">%f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">knn_model_2</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">Xs_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>k-NN score for test set: 0.712500
k-NN score for training set: 0.814699
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">knn_model_2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xs_test</span><span class="p">)</span>

<span class="c1"># Test set</span>
<span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>             precision    recall  f1-score   support

      False       0.72      0.79      0.75       179
       True       0.70      0.62      0.65       141

avg / total       0.71      0.71      0.71       320
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">knn_model_2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xs_train</span><span class="p">)</span>

<span class="c1"># Train set</span>
<span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>             precision    recall  f1-score   support

      False       0.80      0.86      0.83       676
       True       0.83      0.77      0.80       603

avg / total       0.82      0.81      0.81      1279
</pre></div>
</td></tr></table>

<p>Normalization-scaling improves the performance compare to the previous <code class="codehilite"><span class="n">classification_report</span></code>.</p>
<h3 id="k-nn-recap">k-NN Recap<a class="headerlink" href="#k-nn-recap" title="Permanent link">&para;</a></h3>
<h4 id="without-scaling">Without scaling<a class="headerlink" href="#without-scaling" title="Permanent link">&para;</a></h4>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Set sc = False </span>
<span class="c1"># Do not scale the features </span>
<span class="n">sc</span> <span class="o">=</span> <span class="bp">False</span>
<span class="c1"># Set the number of k in k-NN</span>
<span class="n">nk</span> <span class="o">=</span> <span class="mi">5</span>

<span class="c1"># Load data </span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv &#39;</span> <span class="p">,</span> <span class="n">sep</span> <span class="o">=</span> <span class="s1">&#39;;&#39;</span><span class="p">)</span> 
<span class="c1"># Drop target variable </span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;quality&#39;</span> <span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>

<span class="c1"># Scale, if desired </span>
<span class="k">if</span> <span class="n">sc</span> <span class="o">==</span> <span class="bp">True</span><span class="p">:</span> 
  <span class="n">X</span> <span class="o">=</span> <span class="n">scale</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> 

<span class="c1"># Target value </span>
<span class="n">y1</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;quality&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span> <span class="c1"># original target variable </span>
<span class="c1"># New target variable: is the rating &lt;= 5?</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">y1</span> <span class="o">&lt;=</span> <span class="mi">5</span> 

<span class="c1"># Split (80/20) the data into a test set and a train set</span>
<span class="c1"># X_train, X_test, y_train, y_test </span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span>
                                                    <span class="n">y</span><span class="p">,</span>
                                                    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
                                                    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span> 

<span class="c1"># Train the k-NN model</span>
<span class="n">knn</span> <span class="o">=</span> <span class="n">neighbors</span><span class="o">.</span><span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="n">nk</span><span class="p">)</span>
<span class="n">knn_model</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Print performance on the test set </span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;k-NN accuracy for test set: </span><span class="si">%f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">knn_model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
<span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">knn_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span> 
<span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>k-NN accuracy for test set: 0.612500
             precision    recall  f1-score   support

      False       0.66      0.64      0.65       179
       True       0.56      0.57      0.57       141

avg / total       0.61      0.61      0.61       320
</pre></div>
</td></tr></table>

<h4 id="with-scaling">With scaling<a class="headerlink" href="#with-scaling" title="Permanent link">&para;</a></h4>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Set sc = True </span>
<span class="c1"># to scale the features </span>
<span class="n">sc</span> <span class="o">=</span> <span class="bp">True</span>
<span class="c1"># Set the number of k in k-NN</span>
<span class="n">nk</span> <span class="o">=</span> <span class="mi">5</span>

<span class="c1"># Load data </span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv &#39;</span> <span class="p">,</span> <span class="n">sep</span> <span class="o">=</span> <span class="s1">&#39;;&#39;</span><span class="p">)</span> 
<span class="c1"># Drop target variable </span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;quality&#39;</span> <span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>

<span class="c1"># Scale, if desired </span>
<span class="k">if</span> <span class="n">sc</span> <span class="o">==</span> <span class="bp">True</span><span class="p">:</span> 
  <span class="n">X</span> <span class="o">=</span> <span class="n">scale</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> 

<span class="c1"># Target value </span>
<span class="n">y1</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;quality&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span> <span class="c1"># original target variable </span>
<span class="c1"># New target variable: is the rating &lt;= 5?</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">y1</span> <span class="o">&lt;=</span> <span class="mi">5</span> 

<span class="c1"># Split (80/20) the data into a test set and a train set</span>
<span class="c1"># X_train, X_test, y_train, y_test </span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span>
                                                    <span class="n">y</span><span class="p">,</span>
                                                    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
                                                    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span> 

<span class="c1"># Train the k-NN model</span>
<span class="n">knn</span> <span class="o">=</span> <span class="n">neighbors</span><span class="o">.</span><span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="n">nk</span><span class="p">)</span>
<span class="n">knn_model</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Print performance on the test set </span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;k-NN accuracy for test set: </span><span class="si">%f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">knn_model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
<span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">knn_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span> 
<span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>k-NN accuracy for test set: 0.712500
             precision    recall  f1-score   support

      False       0.72      0.79      0.75       179
       True       0.70      0.62      0.65       141

avg / total       0.71      0.71      0.71       320
</pre></div>
</td></tr></table>

<h3 id="linear-regression">Linear regression<a class="headerlink" href="#linear-regression" title="Permanent link">&para;</a></h3>
<p>Before addressing an alternative to k-NN, the logistic regression or Logit, let us briefly review the linear regresion with a different dataset.</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Import necessary packages</span>
<span class="o">%</span><span class="n">pylab</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>

<span class="c1"># set the style</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;ggplot&#39;</span><span class="p">)</span>

<span class="c1"># Import nmore packages</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>Populating the interactive namespace from numpy and matplotlib
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Load the data</span>
<span class="c1"># The data is part of the scikit-learn module</span>
<span class="n">boston</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_boston</span><span class="p">()</span>
<span class="n">yb</span> <span class="o">=</span> <span class="n">boston</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">Xb</span> <span class="o">=</span> <span class="n">boston</span><span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">][:,</span><span class="mi">5</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">yb</span><span class="p">[:</span><span class="mi">10</span><span class="p">])</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">[[ 24. ]</span>
 <span class="k">[ 21.6]</span>
 <span class="k">[ 34.7]</span>
 <span class="k">[ 33.4]</span>
 <span class="k">[ 36.2]</span>
 <span class="k">[ 28.7]</span>
 <span class="k">[ 22.9]</span>
 <span class="k">[ 27.1]</span>
 <span class="k">[ 16.5]</span>
 <span class="k">[ 18.9]]</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">Xb</span><span class="p">[:</span><span class="mi">10</span><span class="p">])</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">[[ 6.575]</span>
 <span class="k">[ 6.421]</span>
 <span class="k">[ 7.185]</span>
 <span class="k">[ 6.998]</span>
 <span class="k">[ 7.147]</span>
 <span class="k">[ 6.43 ]</span>
 <span class="k">[ 6.012]</span>
 <span class="k">[ 6.172]</span>
 <span class="k">[ 5.631]</span>
 <span class="k">[ 6.004]]</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Plot data</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">Xb</span><span class="p">,</span><span class="n">yb</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;value of house /1000 ($)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;number of rooms&#39;</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>&lt;matplotlib.text.Text at 0x7f3681ae90b8&gt;
</pre></div>
</td></tr></table>

<p><img alt="" src="../img/k-NN_linear_regression/output_40_1.png" /></p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Create linear regression object</span>
<span class="n">regr</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">LinearRegression</span><span class="p">()</span>

<span class="c1"># Train the model using the training sets</span>
<span class="n">regr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span> <span class="n">Xb</span><span class="p">,</span> <span class="n">yb</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Plot outputs</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">Xb</span><span class="p">,</span> <span class="n">yb</span><span class="p">,</span>  <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">Xb</span><span class="p">,</span> <span class="n">regr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xb</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span>
         <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</td></tr></table>

<p><img alt="" src="../img/k-NN_linear_regression/output_42_0.png" /></p>
<h3 id="logistic-regression-logit">Logistic regression (Logit)<a class="headerlink" href="#logistic-regression-logit" title="Permanent link">&para;</a></h3>
<h4 id="with-random-numbers">With random numbers<a class="headerlink" href="#with-random-numbers" title="Permanent link">&para;</a></h4>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Synthesize data</span>
<span class="n">X1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
<span class="n">y1</span> <span class="o">=</span> <span class="p">(</span><span class="n">X1</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
<span class="n">X1</span><span class="p">[</span><span class="n">X1</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span> <span class="o">*=</span> <span class="mi">4</span>
<span class="n">X1</span> <span class="o">+=</span> <span class="o">.</span><span class="mi">3</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">150</span><span class="p">)</span>
<span class="n">X1</span> <span class="o">=</span> <span class="n">X1</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Run the classifier</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">LogisticRegression</span><span class="p">()</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">y1</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class=&#39;ovr&#39;, n_jobs=1,
          penalty=&#39;l2&#39;, random_state=None, solver=&#39;liblinear&#39;, tol=0.0001,
          verbose=0, warm_start=False)
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">X1</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>array([[-0.74466839],
       [ 0.47335714],
       [-1.94951938],
       [ 0.12078443],
       [-1.62121705],
       [-2.23684396],
       [ 7.66984914],
       [-0.31941781],
       [-1.07205326],
       [ 0.85413978]])
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Order X1</span>
<span class="n">X1_ordered</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">X1</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

<span class="n">X1_ordered</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>[array([-3.29826361]),
 array([-2.76292445]),
 array([-2.23684396]),
 array([-1.96629089]),
 array([-1.94951938]),
 array([-1.87501025]),
 array([-1.83321548]),
 array([-1.73611093]),
 array([-1.62121705]),
 array([-1.61885181])]
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Plot the result</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X1</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">y1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">20</span> <span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X1_ordered</span><span class="p">,</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X1_ordered</span><span class="p">)[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span> <span class="p">,</span> <span class="n">linewidth</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;target variable&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;predictor variable&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</td></tr></table>

<p><img alt="" src="../img/k-NN_linear_regression/output_48_0.png" /></p>
<h4 id="with-the-wine-dataset">With the Wine dataset<a class="headerlink" href="#with-the-wine-dataset" title="Permanent link">&para;</a></h4>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Load data</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv &#39;</span> <span class="p">,</span> <span class="n">sep</span> <span class="o">=</span> <span class="s1">&#39;;&#39;</span><span class="p">)</span>

<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<div>
<style>
    .dataframe thead tr:only-child th {
        text-align: right;
    }

    .dataframe thead th {
        text-align: left;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fixed acidity</th>
      <th>volatile acidity</th>
      <th>citric acid</th>
      <th>residual sugar</th>
      <th>chlorides</th>
      <th>free sulfur dioxide</th>
      <th>total sulfur dioxide</th>
      <th>density</th>
      <th>pH</th>
      <th>sulphates</th>
      <th>alcohol</th>
      <th>quality</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>7.4</td>
      <td>0.70</td>
      <td>0.00</td>
      <td>1.9</td>
      <td>0.076</td>
      <td>11.0</td>
      <td>34.0</td>
      <td>0.9978</td>
      <td>3.51</td>
      <td>0.56</td>
      <td>9.4</td>
      <td>5</td>
    </tr>
    <tr>
      <th>1</th>
      <td>7.8</td>
      <td>0.88</td>
      <td>0.00</td>
      <td>2.6</td>
      <td>0.098</td>
      <td>25.0</td>
      <td>67.0</td>
      <td>0.9968</td>
      <td>3.20</td>
      <td>0.68</td>
      <td>9.8</td>
      <td>5</td>
    </tr>
    <tr>
      <th>2</th>
      <td>7.8</td>
      <td>0.76</td>
      <td>0.04</td>
      <td>2.3</td>
      <td>0.092</td>
      <td>15.0</td>
      <td>54.0</td>
      <td>0.9970</td>
      <td>3.26</td>
      <td>0.65</td>
      <td>9.8</td>
      <td>5</td>
    </tr>
  </tbody>
</table>
</div>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Drop target variable</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;quality&#39;</span> <span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>

<span class="c1"># Print the array</span>
<span class="k">print</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">[[  7.4     0.7     0.    ...,   3.51    0.56    9.4  ]</span>
 <span class="k">[  7.8     0.88    0.    ...,   3.2     0.68    9.8  ]</span>
 <span class="k">[  7.8     0.76    0.04  ...,   3.26    0.65    9.8  ]</span>
 <span class="na">..., </span>
 <span class="k">[  6.3     0.51    0.13  ...,   3.42    0.75   11.   ]</span>
 <span class="k">[  5.9     0.645   0.12  ...,   3.57    0.71   10.2  ]</span>
 <span class="k">[  6.      0.31    0.47  ...,   3.39    0.66   11.   ]]</span>
</pre></div>
</td></tr></table>

<p>The last column is gone.</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">y1</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;quality&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

<span class="c1"># Print the single-row array</span>
<span class="k">print</span><span class="p">(</span><span class="n">y1</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>[5 5 5 ..., 6 5 6]
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>(1599, 12)
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># plot the other columns or variables</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">[</span><span class="mi">15</span><span class="p">,</span><span class="mi">15</span><span class="p">]);</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span> <span class="c1"># facultative in Jypyter</span>
</pre></div>
</td></tr></table>

<p><img alt="" src="../img/k-NN_linear_regression/output_55_0.png" /></p>
<p>Let us turn it into a two-category variable consisting of &lsquo;good&rsquo; (rating &gt; 5) &amp; &lsquo;bad&rsquo; (rating &lt;= 5) qualities.</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># is the rating &lt;= 5 ?</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">y1</span> <span class="o">&lt;=</span> <span class="mi">5</span>
<span class="k">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>[ True  True  True ..., False  True False]
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7
8
9</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="c1"># split</span>
<span class="c1"># 80% of the data for training (train set)</span>
<span class="c1"># 20% for testing (test set)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span>
                                                    <span class="n">y</span><span class="p">,</span>
                                                    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
                                                    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span>

<span class="c1"># Initial logistic regression model</span>
<span class="n">lr</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">LogisticRegression</span><span class="p">()</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Fit the model</span>
<span class="n">lr</span> <span class="o">=</span> <span class="n">lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">lr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="c1"># Evaluate the train set</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Logistic Regression score for train set: </span><span class="si">%f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">lr</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>Logistic Regression score for train set: 0.752932
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>             precision    recall  f1-score   support

      False       0.77      0.75      0.76       676
       True       0.73      0.75      0.74       603

avg / total       0.75      0.75      0.75      1279
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>

<span class="c1"># Use the test set</span>
<span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">lr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Evaluate the test set</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Logistic Regression score for test set: </span><span class="si">%f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">lr</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>Logistic Regression score for test set: 0.740625
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>             precision    recall  f1-score   support

      False       0.78      0.74      0.76       179
       True       0.69      0.74      0.71       141

avg / total       0.74      0.74      0.74       320
</pre></div>
</td></tr></table>

<p><strong>Note</strong>: the logistic regression performs better than k-NN without scaling.</p>
<h4 id="scale-the-data_1">Scale the data<a class="headerlink" href="#scale-the-data_1" title="Permanent link">&para;</a></h4>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">[[  7.4     0.7     0.    ...,   3.51    0.56    9.4  ]</span>
 <span class="k">[  7.8     0.88    0.    ...,   3.2     0.68    9.8  ]</span>
 <span class="k">[  7.8     0.76    0.04  ...,   3.26    0.65    9.8  ]</span>
 <span class="na">..., </span>
 <span class="k">[  6.3     0.51    0.13  ...,   3.42    0.75   11.   ]</span>
 <span class="k">[  5.9     0.645   0.12  ...,   3.57    0.71   10.2  ]</span>
 <span class="k">[  6.      0.31    0.47  ...,   3.39    0.66   11.   ]]</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">scale</span>

<span class="n">Xs</span> <span class="o">=</span> <span class="n">scale</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">Xs</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>[[-0.52835961  0.96187667 -1.39147228 ...,  1.28864292 -0.57920652
  -0.96024611]
 [-0.29854743  1.96744245 -1.39147228 ..., -0.7199333   0.1289504
  -0.58477711]
 [-0.29854743  1.29706527 -1.18607043 ..., -0.33117661 -0.04808883
  -0.58477711]
 ..., 
 [-1.1603431  -0.09955388 -0.72391627 ...,  0.70550789  0.54204194
   0.54162988]
 [-1.39015528  0.65462046 -0.77526673 ...,  1.6773996   0.30598963
  -0.20930812]
 [-1.33270223 -1.21684919  1.02199944 ...,  0.51112954  0.01092425
   0.54162988]]
</pre></div>
</td></tr></table>

<h4 id="run-the-logit-and-measure-the-performance">Run the Logit and measure the performance<a class="headerlink" href="#run-the-logit-and-measure-the-performance" title="Permanent link">&para;</a></h4>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="c1"># Split 80/20</span>
<span class="n">Xs_train</span><span class="p">,</span> <span class="n">Xs_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">Xs</span><span class="p">,</span>
                                                      <span class="n">y</span><span class="p">,</span>
                                                      <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
                                                      <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Run the logistic regression model</span>
<span class="n">lr_2</span> <span class="o">=</span> <span class="n">lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xs_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Fit the model</span>
<span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">lr_2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xs_train</span><span class="p">)</span>

<span class="c1"># Evaluate the train set</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Logistic Regression score for train set: </span><span class="si">%f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">lr_2</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">Xs_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>Logistic Regression score for train set: 0.752150
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>             precision    recall  f1-score   support

      False       0.77      0.76      0.76       676
       True       0.73      0.75      0.74       603

avg / total       0.75      0.75      0.75      1279
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Use the test set</span>
<span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">lr_2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xs_test</span><span class="p">)</span>

<span class="c1"># Evaluate the test set</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Logistic Regression score for test set: </span><span class="si">%f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">lr_2</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">Xs_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>Logistic Regression score for test set: 0.740625
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>             precision    recall  f1-score   support

      False       0.79      0.74      0.76       179
       True       0.69      0.74      0.72       141

avg / total       0.74      0.74      0.74       320
</pre></div>
</td></tr></table>

<p>This is very interesting! The performance of logistic regression did not improve with data scaling.</p>
<p>Predictor variables with large ranges that do not effect the target variable, a regression algorithm will make the corresponding coefficients small so that they do not effect predictions so much.</p>
<h3 id="logit-recap">Logit Recap<a class="headerlink" href="#logit-recap" title="Permanent link">&para;</a></h3>
<h4 id="without-scaling_1">Without scaling<a class="headerlink" href="#without-scaling_1" title="Permanent link">&para;</a></h4>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Set sc = False</span>
<span class="c1"># do not scale the features </span>
<span class="n">sc</span> <span class="o">=</span> <span class="bp">False</span> 

<span class="c1"># Load the data </span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv &#39;</span> <span class="p">,</span> <span class="n">sep</span> <span class="o">=</span> <span class="s1">&#39;;&#39;</span><span class="p">)</span> 
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;quality&#39;</span> <span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">values</span> <span class="c1"># drop target variable </span>

<span class="c1"># Scale, if desired </span>
<span class="k">if</span> <span class="n">sc</span> <span class="o">==</span> <span class="bp">True</span><span class="p">:</span> 
  <span class="n">X</span> <span class="o">=</span> <span class="n">scale</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> 

<span class="c1"># Target value </span>
<span class="n">y1</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;quality&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span> <span class="c1"># original target variable </span>
<span class="n">y</span> <span class="o">=</span> <span class="n">y1</span> <span class="o">&lt;=</span> <span class="mi">5</span>  <span class="c1"># new target variable: is the rating &lt;= 5? </span>

<span class="c1"># Split (80/20) the data into a test set and a train</span>
<span class="c1"># X_train, X_test, y_train, y_test</span>
<span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span> 

<span class="c1"># Train logistic regression model </span>
<span class="n">lr</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">LogisticRegression</span><span class="p">()</span> 
<span class="n">lr</span> <span class="o">=</span> <span class="n">lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span> 

<span class="c1"># Print performance on the test set</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Logistic Regression score for training set: </span><span class="si">%f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">lr</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span> 
<span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">lr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span> 
<span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>Logistic Regression score for training set: 0.752932
             precision    recall  f1-score   support

      False       0.78      0.74      0.76       179
       True       0.69      0.74      0.71       141

avg / total       0.74      0.74      0.74       320
</pre></div>
</td></tr></table>

<h3 id="noise-and-scaling">Noise and scaling<a class="headerlink" href="#noise-and-scaling" title="Permanent link">&para;</a></h3>
<p>The noisier the symthesized data, the more important scaling will be.</p>
<p>Measurements can be in meters and and miles, with small or large ranges. If we scale the data, they end up being the same.</p>
<p>scikit-learn’s <code class="codehilite">make_blobs</code> function to generate 2000 data points that are in 4 clusters (each data point has 2 predictor variables and 1 target variable).</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="o">%</span><span class="n">pylab</span> <span class="n">inline</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>Populating the interactive namespace from numpy and matplotlib
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7
8</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Generate some clustered data (blobs!)</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets.samples_generator</span> <span class="kn">import</span> <span class="n">make_blobs</span>

<span class="n">n_samples</span><span class="o">=</span><span class="mi">2000</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">centers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">[[-0.46530384  1.73299482]</span>
 <span class="k">[-0.33963733  3.84220272]</span>
 <span class="k">[ 2.25309569  0.99541446]</span>
 <span class="na">..., </span>
 <span class="k">[ 1.03616476  4.09126428]</span>
 <span class="k">[-0.5901088   3.68821314]</span>
 <span class="k">[ 2.30405277  4.20250584]]</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>[2 0 1 ..., 0 2 0]
</pre></div>
</td></tr></table>

<h4 id="plotting-the-synthesized-data">Plotting the synthesized data<a class="headerlink" href="#plotting-the-synthesized-data" title="Permanent link">&para;</a></h4>
<p>Each axis is a predictor variable and the colour is a key to the target variable</p>
<p>All possible target variables are equally represented. In this case (or even if they are approximately equally represented), we say that the class y is balanced.</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>

<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;ggplot&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">5</span><span class="p">));</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span> <span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span> <span class="p">,</span> <span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span>  <span class="n">c</span> <span class="o">=</span> <span class="n">y</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.7</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</td></tr></table>

<p><img alt="" src="../img/k-NN_linear_regression/output_81_0.png" /></p>
<p>Plot histograms of the features.</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>

<span class="c1"># Convert to a DataFrame</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Plot it</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>array([[&lt;matplotlib.axes._subplots.AxesSubplot object at 0x7f366d3dbba8&gt;,
        &lt;matplotlib.axes._subplots.AxesSubplot object at 0x7f366d30ca58&gt;]], dtype=object)
</pre></div>
</td></tr></table>

<p><img alt="" src="../img/k-NN_linear_regression/output_83_1.png" /></p>
<p>Split into test &amp; train sets, and plot both sets (train set &gt; test set; 80/20).</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span>
                                                    <span class="n">y</span><span class="p">,</span>
                                                    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
                                                    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7
8
9</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">5</span><span class="p">));</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span> <span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;training set&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span> <span class="p">,</span> <span class="n">X_train</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span>  <span class="n">c</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.7</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_test</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span> <span class="p">,</span> <span class="n">X_test</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span>  <span class="n">c</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.7</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;test set&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</td></tr></table>

<p><img alt="" src="../img/k-NN_linear_regression/output_86_0.png" /></p>
<h4 id="k-nearest-neighbours_1">k-Nearest Neighbours<a class="headerlink" href="#k-nearest-neighbours_1" title="Permanent link">&para;</a></h4>
<p>Let’s instantiate a k-Nearest Neighbours classifier and train it on our train set.</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">neighbors</span><span class="p">,</span> <span class="n">linear_model</span>

<span class="n">knn</span> <span class="o">=</span> <span class="n">neighbors</span><span class="o">.</span><span class="n">KNeighborsClassifier</span><span class="p">()</span>
<span class="n">knn_model</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<p>Fit the <code class="codehilite">knn_model</code> to the test set and compute the accuracy.</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">knn_model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>0.93500000000000005
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="s1">&#39;k-NN score for test set: </span><span class="si">%f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">knn_model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>k-NN score for test set: 0.935000
</pre></div>
</td></tr></table>

<p>Check out a variety of other metrics.</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>

<span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">knn_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7
8</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>             precision    recall  f1-score   support

          0       0.87      0.90      0.88       106
          1       0.98      0.93      0.95       102
          2       0.90      0.92      0.91       100
          3       1.00      1.00      1.00        92

avg / total       0.94      0.94      0.94       400
</pre></div>
</td></tr></table>

<p>Re-fit <code class="codehilite">knn_model</code> to the train set and compute the accuracy.</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="s1">&#39;k-NN score for train set: </span><span class="si">%f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">knn_model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>k-NN score for train set: 0.941875
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>

<span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">knn_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7
8</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>             precision    recall  f1-score   support

          0       0.88      0.90      0.89       394
          1       0.97      0.96      0.96       398
          2       0.94      0.93      0.93       400
          3       0.99      0.98      0.98       408

avg / total       0.94      0.94      0.94      1600
</pre></div>
</td></tr></table>

<h5 id="scale-the-data-run-the-k-nn-and-measure-the-performance">Scale the data, run the k-NN, and measure the performance<a class="headerlink" href="#scale-the-data-run-the-k-nn-and-measure-the-performance" title="Permanent link">&para;</a></h5>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">[[-0.46530384  1.73299482]</span>
 <span class="k">[-0.33963733  3.84220272]</span>
 <span class="k">[ 2.25309569  0.99541446]</span>
 <span class="na">..., </span>
 <span class="k">[ 1.03616476  4.09126428]</span>
 <span class="k">[-0.5901088   3.68821314]</span>
 <span class="k">[ 2.30405277  4.20250584]]</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">scale</span>

<span class="n">Xs</span> <span class="o">=</span> <span class="n">scale</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">Xs</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">[[-0.26508542 -0.82638395]</span>
 <span class="k">[-0.19594894 -0.0519305 ]</span>
 <span class="k">[ 1.23046484 -1.09720678]</span>
 <span class="na">..., </span>
 <span class="k">[ 0.5609601   0.03951927]</span>
 <span class="k">[-0.33374791 -0.10847199]</span>
 <span class="k">[ 1.25849931  0.08036466]]</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">Xs_train</span><span class="p">,</span> <span class="n">Xs_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">Xs</span><span class="p">,</span>
                                                      <span class="n">y</span><span class="p">,</span>
                                                      <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
                                                      <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">5</span><span class="p">));</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span> <span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">Xs_train</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span> <span class="p">,</span> <span class="n">Xs_train</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span>  <span class="n">c</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.7</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;scaled training set&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">Xs_test</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span> <span class="p">,</span> <span class="n">Xs_test</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span>  <span class="n">c</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.7</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;scaled test set&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</td></tr></table>

<p><img alt="" src="../img/k-NN_linear_regression/output_101_0.png" /></p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">knn_model_s</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xs_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s1">&#39;k-NN score for test set: </span><span class="si">%f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">knn_model_s</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">Xs_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>k-NN score for test set: 0.935000
</pre></div>
</td></tr></table>

<p>It doesn’t perform any better with scaling.</p>
<p>This is most likely because both features were already around the same range.</p>
<h5 id="add-noise-to-the-signal">Add noise to the signal<a class="headerlink" href="#add-noise-to-the-signal" title="Permanent link">&para;</a></h5>
<p>Adding a third variable of Gaussian noise with mean 0 and variable standard deviation <span><span class="MathJax_Preview">\sigma</span><script type="math/tex">\sigma</script></span>. We call <span><span class="MathJax_Preview">\sigma</span><script type="math/tex">\sigma</script></span> the strength of the noise and we see that the stronger the noise, the worse the performance of k-Nearest Neighbours.</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7
8</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Strength of noise term</span>
<span class="n">ns</span> <span class="o">=</span> <span class="mi">10</span><span class="o">**</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>

<span class="c1"># Add noise column to predictor variables</span>
<span class="n">newcol</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">([</span><span class="n">ns</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)])</span>
<span class="n">Xn</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">newcol</span><span class="p">),</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">Xn</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">[[ -4.65303843e-01   1.73299482e+00  -9.41949646e+01]</span>
 <span class="k">[ -3.39637332e-01   3.84220272e+00  -1.00446506e+03]</span>
 <span class="k">[  2.25309569e+00   9.95414462e-01   2.95697211e+02]</span>
 <span class="na">..., </span>
 <span class="k">[  1.03616476e+00   4.09126428e+00  -1.16020635e+02]</span>
 <span class="k">[ -5.90108797e-01   3.68821314e+00   5.60244701e+02]</span>
 <span class="k">[  2.30405277e+00   4.20250584e+00  -8.97600798e+02]]</span>
</pre></div>
</td></tr></table>

<p>Plot the 3D data.</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">mpl_toolkits.mplot3d</span> <span class="kn">import</span> <span class="n">Axes3D</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s1">&#39;3d&#39;</span> <span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">Xn</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">Xn</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">Xn</span><span class="p">[:,</span><span class="mi">2</span><span class="p">],</span> <span class="n">c</span> <span class="o">=</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>&lt;mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x7f366d409cf8&gt;
</pre></div>
</td></tr></table>

<p><img alt="" src="../img/k-NN_linear_regression/output_106_1.png" /></p>
<h5 id="run-the-k-nn-and-measure-the-performance">Run the k-NN and measure the performance<a class="headerlink" href="#run-the-k-nn-and-measure-the-performance" title="Permanent link">&para;</a></h5>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Split into train-test sets</span>
<span class="n">Xn_train</span><span class="p">,</span> <span class="n">Xn_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">Xn</span><span class="p">,</span>
                                                      <span class="n">y</span><span class="p">,</span> 
                                                      <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> 
                                                      <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Run the model</span>
<span class="n">knn</span> <span class="o">=</span> <span class="n">neighbors</span><span class="o">.</span><span class="n">KNeighborsClassifier</span><span class="p">()</span>
<span class="n">knn_model</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xn_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Evaluate</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;k-NN score for test set: </span><span class="si">%f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">knn_model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">Xn_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>k-NN score for test set: 0.337500
</pre></div>
</td></tr></table>

<p>Horrible!</p>
<h5 id="scale-the-data-add-noise-run-the-k-nn-and-measure-the-performance">Scale the data, add noise, run the k-NN, and measure the performance<a class="headerlink" href="#scale-the-data-add-noise-run-the-k-nn-and-measure-the-performance" title="Permanent link">&para;</a></h5>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Scale</span>
<span class="n">Xns</span> <span class="o">=</span> <span class="n">scale</span><span class="p">(</span><span class="n">Xn</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">Xns</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">[[-0.26508542 -0.82638395 -0.07164275]</span>
 <span class="k">[-0.19594894 -0.0519305  -0.98584539]</span>
 <span class="k">[ 1.23046484 -1.09720678  0.31993383]</span>
 <span class="na">..., </span>
 <span class="k">[ 0.5609601   0.03951927 -0.09356271]</span>
 <span class="k">[-0.33374791 -0.10847199  0.58562421]</span>
 <span class="k">[ 1.25849931  0.08036466 -0.87851945]]</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Apply noise</span>
<span class="n">s</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="o">.</span><span class="mi">2</span><span class="o">*</span><span class="n">n_samples</span><span class="p">)</span>
<span class="n">Xns_train</span> <span class="o">=</span> <span class="n">Xns</span><span class="p">[</span><span class="n">s</span><span class="p">:]</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">s</span><span class="p">:]</span>
<span class="n">Xns_test</span> <span class="o">=</span> <span class="n">Xns</span><span class="p">[:</span><span class="n">s</span><span class="p">]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span><span class="n">s</span><span class="p">]</span>

<span class="c1"># Run the model</span>
<span class="n">knn</span> <span class="o">=</span> <span class="n">neighbors</span><span class="o">.</span><span class="n">KNeighborsClassifier</span><span class="p">()</span>
<span class="n">knn_models</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xns_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Evaluate</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;k-NN score for test set: </span><span class="si">%f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">knn_models</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">Xns_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>k-NN score for test set: 0.917500
</pre></div>
</td></tr></table>

<p>After scaling the data, the model performs nearly as well as were there no noise introduced.</p>
<h4 id="noise-strength-vs-accuracy-and-the-need-for-scaling">Noise strength vs. accuracy (and the need for scaling)<a class="headerlink" href="#noise-strength-vs-accuracy-and-the-need-for-scaling" title="Permanent link">&para;</a></h4>
<p>How the noise strength can effect model accuracy?</p>
<p>Create a function to split the data and run the model. </p>
<p>Use the function in a loop.</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">accu</span><span class="p">(</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span>
                                                        <span class="n">y</span><span class="p">,</span>
                                                        <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
                                                        <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

    <span class="n">knn</span> <span class="o">=</span> <span class="n">neighbors</span><span class="o">.</span><span class="n">KNeighborsClassifier</span><span class="p">()</span>
    <span class="n">knn_model</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="k">return</span><span class="p">(</span><span class="n">knn_model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Set the variables</span>
<span class="n">noise</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="o">**</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">6</span><span class="p">)]</span>
<span class="n">A1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">noise</span><span class="p">))</span>
<span class="n">A2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">noise</span><span class="p">))</span>
<span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">noise</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>[1, 10, 100, 1000, 10000, 100000]
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">A1</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">A2</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">[ 0.  0.  0.  0.  0.  0.]</span>
<span class="k">[ 0.  0.  0.  0.  0.  0.]</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7
8</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Run the loop</span>
<span class="k">for</span> <span class="n">ns</span> <span class="ow">in</span> <span class="n">noise</span><span class="p">:</span>
    <span class="n">newcol</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">([</span><span class="n">ns</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)])</span>
    <span class="n">Xn</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">newcol</span><span class="p">),</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">Xns</span> <span class="o">=</span> <span class="n">scale</span><span class="p">(</span><span class="n">Xn</span><span class="p">)</span>
    <span class="n">A1</span><span class="p">[</span><span class="n">count</span><span class="p">]</span> <span class="o">=</span> <span class="n">accu</span><span class="p">(</span> <span class="n">Xn</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">A2</span><span class="p">[</span><span class="n">count</span><span class="p">]</span> <span class="o">=</span> <span class="n">accu</span><span class="p">(</span> <span class="n">Xns</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7
8
9</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Plot the results</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span> <span class="n">noise</span><span class="p">,</span> <span class="n">A1</span> <span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span> <span class="n">noise</span><span class="p">,</span> <span class="n">A1</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;unscaled&#39;</span><span class="p">,</span> <span class="n">linewidth</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span> <span class="n">noise</span><span class="p">,</span> <span class="n">A2</span> <span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span> <span class="n">noise</span><span class="p">,</span> <span class="n">A2</span> <span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;scaled&#39;</span><span class="p">,</span> <span class="n">linewidth</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Noise strength&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">3</span><span class="p">);</span>
</pre></div>
</td></tr></table>

<p><img alt="" src="../img/k-NN_linear_regression/output_120_0.png" /></p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">A1</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">A2</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">[ 0.9225  0.9175  0.8025  0.3275  0.22    0.2525]</span>
<span class="k">[ 0.91    0.9175  0.9325  0.9075  0.9325  0.92  ]</span>
</pre></div>
</td></tr></table>

<p>The more noise there is in the nuisance variable, the more important it is to scale the data for the k-NN model.</p>
<blockquote>
<p>More noise, more scaling.</p>
</blockquote>
<h4 id="logit-repeat-the-k-nn-procedure">Logit (Repeat the k-NN procedure)<a class="headerlink" href="#logit-repeat-the-k-nn-procedure" title="Permanent link">&para;</a></h4>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Change the exponent of 10 to alter the amount of noise</span>
<span class="n">ns</span> <span class="o">=</span> <span class="mi">10</span><span class="o">**</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span> <span class="c1"># Strength of noise term</span>

<span class="c1"># Set sc = True if we want to scale the features</span>
<span class="n">sc</span> <span class="o">=</span> <span class="bp">True</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Import packages</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">neighbors</span><span class="p">,</span> <span class="n">linear_model</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">scale</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets.samples_generator</span> <span class="kn">import</span> <span class="n">make_blobs</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Generate some data</span>
<span class="n">n_samples</span><span class="o">=</span><span class="mi">2000</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> 
                  <span class="n">centers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> 
                  <span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                  <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Add noise column to predictor variables</span>
<span class="n">newcol</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">([</span><span class="n">ns</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)])</span>
<span class="n">Xn</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">newcol</span><span class="p">),</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Scale if desired</span>
<span class="k">if</span> <span class="n">sc</span> <span class="o">==</span> <span class="bp">True</span><span class="p">:</span>
    <span class="n">Xn</span> <span class="o">=</span> <span class="n">scale</span><span class="p">(</span><span class="n">Xn</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Train model and test after splitting</span>
<span class="n">Xn_train</span><span class="p">,</span> <span class="n">Xn_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">Xn</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">lr</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">LogisticRegression</span><span class="p">()</span>
<span class="n">lr_model</span> <span class="o">=</span> <span class="n">lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xn_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;logistic regression score for test set: </span><span class="si">%f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">lr_model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">Xn_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>logistic regression score for test set: 0.942500
</pre></div>
</td></tr></table>
                
                  
                
              
              
                
              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../Overview_of_scikit-learn/" title="Overview of scikit-learn" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Overview of scikit-learn
              </span>
            </div>
          </a>
        
        
          <a href="../Time_Series_Analysis/" title="Time Series Analysis" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Time Series Analysis
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            © Ugo Sparks
          </div>
        
        powered by
        <a href="http://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
        
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/application.8eb9be28.js"></script>
      
      <script>app.initialize({version:"0.17.3",url:{base:".."}})</script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
    
      
        <script>!function(e,a,t,n,o,c,i){e.GoogleAnalyticsObject=o,e.ga=e.ga||function(){(e.ga.q=e.ga.q||[]).push(arguments)},e.ga.l=1*new Date,c=a.createElement(t),i=a.getElementsByTagName(t)[0],c.async=1,c.src="https://www.google-analytics.com/analytics.js",i.parentNode.insertBefore(c,i)}(window,document,"script",0,"ga"),ga("create","UA-93008985-2","auto"),ga("set","anonymizeIp",!0),ga("send","pageview");var links=document.getElementsByTagName("a");if(Array.prototype.map.call(links,function(e){e.host!=document.location.host&&e.addEventListener("click",function(){var a=e.getAttribute("data-md-action")||"follow";ga("send","event","outbound",a,e.href)})}),document.forms.search){var query=document.forms.search.query;query.addEventListener("blur",function(){if(this.value){var e=document.location.pathname;ga("send","pageview",e+"?q="+this.value)}})}</script>
      
    
  </body>
</html>