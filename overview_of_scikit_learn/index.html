
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="A Python documentation website.">
      
      
      
      
      <link rel="icon" href="../img/favicon.ico">
      <meta name="generator" content="mkdocs-1.2.3, mkdocs-material-7.3.0">
    
    
      
        <title>Overview of scikit-learn - ugo_py_doc</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.8b42a75e.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.3f5d1f46.min.css">
        
          
          
          <meta name="theme-color" content="#ffc105">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:300,400,400i,700%7CUbuntu+Mono&display=fallback">
        <style>:root{--md-text-font-family:"Ubuntu";--md-code-font-family:"Ubuntu Mono"}</style>
      
    
    
    
      <link rel="stylesheet" href="../extra.css">
    
    
      


    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="amber" data-md-color-accent="indigo">
  
    
    <script>function __prefix(e){return new URL("..",location).pathname+"."+e}function __get(e,t=localStorage){return JSON.parse(t.getItem(__prefix(e)))}</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#three-types-of-machine-learning-algorithms" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="ugo_py_doc" class="md-header__button md-logo" aria-label="ugo_py_doc" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m12 16 7.36-5.73L21 9l-9-7-9 7 1.63 1.27M12 18.54l-7.38-5.73L3 14.07l9 7 9-7-1.63-1.27L12 18.54z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            ugo_py_doc
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Overview of scikit-learn
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        
<a href="https://github.com/ugoproto/ugo_py_doc.git/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    ugo_py_doc
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="ugo_py_doc" class="md-nav__button md-logo" aria-label="ugo_py_doc" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m12 16 7.36-5.73L21 9l-9-7-9 7 1.63 1.27M12 18.54l-7.38-5.73L3 14.07l9 7 9-7-1.63-1.27L12 18.54z"/></svg>

    </a>
    ugo_py_doc
  </label>
  
    <div class="md-nav__source">
      
<a href="https://github.com/ugoproto/ugo_py_doc.git/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    ugo_py_doc
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_2">
          Basics
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Basics" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          Basics
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../py_cs/" class="md-nav__link">
        Python Cheat Sheets
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../databases/" class="md-nav__link">
        Databases
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../datetime/" class="md-nav__link">
        Datetime
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../decorators/" class="md-nav__link">
        Decorators
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../exceptions/" class="md-nav__link">
        Exceptions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../freeze_the_code/" class="md-nav__link">
        Freeze the Code
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../gedit_execute_highlighted_python_code/" class="md-nav__link">
        Gedit, Execute Highlighted Code
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../python_nice_to_have/" class="md-nav__link">
        Python Nice to Have
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          Scipy Stack
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Scipy Stack" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Scipy Stack
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../jn_cs/" class="md-nav__link">
        Jupyter Notebook Cheat Sheets
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../scipy_cs/" class="md-nav__link">
        Scipy Stack Cheat Sheets
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../eda_machine_learning_feature_engineering_and_kaggle/" class="md-nav__link">
        EDA, Machine Learning, Feature Engineering, and Kaggle
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../exploratory_data_analysis/" class="md-nav__link">
        Exploratory Data Analysis (EDA)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../feature_selection_in_python/" class="md-nav__link">
        Feature Selection
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../geospatial_data_in_python/" class="md-nav__link">
        Geospatial Data
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../importing_data_into_python/" class="md-nav__link">
        Importing Data
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../introduction_to_customer_segmentation_in_python/" class="md-nav__link">
        Introduction to Customer Segmentation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../intro_to_data_world_in_python/" class="md-nav__link">
        Introduction to data.world
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Overview of scikit-learn
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Overview of scikit-learn
      </a>
      
        
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#three-types-of-machine-learning-algorithms" class="md-nav__link">
    Three types of Machine Learning Algorithms
  </a>
  
    <nav class="md-nav" aria-label="Three types of Machine Learning Algorithms">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#supervised-learning" class="md-nav__link">
    Supervised Learning
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#unsupervised-learning" class="md-nav__link">
    Unsupervised Learning
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reinforcement-learning" class="md-nav__link">
    Reinforcement Learning
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-scikit-learn-module" class="md-nav__link">
    The scikit-learn Module
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#basic-supervised-learning" class="md-nav__link">
    Basic Supervised Learning
  </a>
  
    <nav class="md-nav" aria-label="Basic Supervised Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#with-a-hard-coded-dataset" class="md-nav__link">
    With a Hard-Coded Dataset
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#linear-regression" class="md-nav__link">
    Linear Regression
  </a>
  
    <nav class="md-nav" aria-label="Linear Regression">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#r-code" class="md-nav__link">
    R Code
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#python-code" class="md-nav__link">
    Python Code
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#linear-regression-with-statsmodels" class="md-nav__link">
    Linear Regression with StatsModels
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#logistic-regression" class="md-nav__link">
    Logistic Regression
  </a>
  
    <nav class="md-nav" aria-label="Logistic Regression">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-r-code" class="md-nav__link">
    The R code
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-python-code" class="md-nav__link">
    The Python Code
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision-tree" class="md-nav__link">
    Decision tree
  </a>
  
    <nav class="md-nav" aria-label="Decision tree">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-r-code_1" class="md-nav__link">
    The R Code
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-python-code_1" class="md-nav__link">
    The Python Code
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#random-forests" class="md-nav__link">
    Random Forests
  </a>
  
    <nav class="md-nav" aria-label="Random Forests">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-r-code_2" class="md-nav__link">
    The R Code
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-python-code_2" class="md-nav__link">
    The Python Code
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#k-nearest-neighbours" class="md-nav__link">
    k-Nearest Neighbours
  </a>
  
    <nav class="md-nav" aria-label="k-Nearest Neighbours">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-r-code_3" class="md-nav__link">
    The R Code
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rescaling" class="md-nav__link">
    Rescaling
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-python-code_3" class="md-nav__link">
    The Python Code
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#naive-bayes" class="md-nav__link">
    Naïve Bayes
  </a>
  
    <nav class="md-nav" aria-label="Naïve Bayes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-r-code_4" class="md-nav__link">
    The R Code
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-python-code_4" class="md-nav__link">
    The Python Code
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#support-vector-machine" class="md-nav__link">
    Support Vector Machine
  </a>
  
    <nav class="md-nav" aria-label="Support Vector Machine">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-r-code_5" class="md-nav__link">
    The R Code
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-python-code_5" class="md-nav__link">
    The Python Code
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#split-a-dataset" class="md-nav__link">
    Split a dataset
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#intermediate-supervised-learning" class="md-nav__link">
    Intermediate Supervised Learning
  </a>
  
    <nav class="md-nav" aria-label="Intermediate Supervised Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#logistic-regression_1" class="md-nav__link">
    Logistic regression
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision-tree_1" class="md-nav__link">
    Decision tree
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#random-forests_1" class="md-nav__link">
    Random Forests
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#k-nearest-neighbours_1" class="md-nav__link">
    k-Nearest Neighbours
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#naive-bayes_1" class="md-nav__link">
    Naïve Bayes
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#support-vector-machine_1" class="md-nav__link">
    Support Vector Machine
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#unsupervised-learning_1" class="md-nav__link">
    Unsupervised Learning
  </a>
  
    <nav class="md-nav" aria-label="Unsupervised Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#k-means" class="md-nav__link">
    k-Means
  </a>
  
    <nav class="md-nav" aria-label="k-Means">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-r-code_6" class="md-nav__link">
    The R Code
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-python-code_6" class="md-nav__link">
    The Python Code
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dimension-reduction" class="md-nav__link">
    Dimension Reduction
  </a>
  
    <nav class="md-nav" aria-label="Dimension Reduction">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#principal-component-analysis" class="md-nav__link">
    Principal Component Analysis
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../python_and_excel/" class="md-nav__link">
        Python and Excel
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../scaling_centering_noise_with_knn_linear_regression_logit/" class="md-nav__link">
        Scaling, Centering, Noise with kNN, Linear Regression, Logit
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../sentiment_analysis_with_twitter/" class="md-nav__link">
        Sentiment Analysis with Twitter
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../time_series_analysis/" class="md-nav__link">
        Time Series Analysis
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../vectors_and_arrays_linear_algebra/" class="md-nav__link">
        Vectors and Arrays (Linear Algebra)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../viewing_3d_volumetric_data_with_matplotlib/" class="md-nav__link">
        Viewing 3D Volumetric Data with Matplotlib
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../write_idiomatic_pandas_code/" class="md-nav__link">
        Write Idiomatic Pandas Code
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" type="checkbox" id="__nav_4" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4">
          Courses
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Courses" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          Courses
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../apprenez_a_programmer_en_python/" class="md-nav__link">
        Apprenez à programmer en Python
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../automate_the_boring_stuff_with_python/" class="md-nav__link">
        Automate the Boring Stuff with Python
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../codecademy_python/" class="md-nav__link">
        Codecademy Python
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../learn_python_the_hard_way/" class="md-nav__link">
        Learn Python the Hard Way
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../lpthw_python_code_snippets/" class="md-nav__link">
        LPTHW, Python Code Snippets
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5" type="checkbox" id="__nav_5" >
      
      
      
      
        <label class="md-nav__link" for="__nav_5">
          Manuals
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Manuals" data-md-level="1">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          Manuals
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../managing_your_biological_data_with_python/" class="md-nav__link">
        Managing Your Biological Data with Python
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../python_for_education/" class="md-nav__link">
        Python for Education
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#three-types-of-machine-learning-algorithms" class="md-nav__link">
    Three types of Machine Learning Algorithms
  </a>
  
    <nav class="md-nav" aria-label="Three types of Machine Learning Algorithms">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#supervised-learning" class="md-nav__link">
    Supervised Learning
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#unsupervised-learning" class="md-nav__link">
    Unsupervised Learning
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reinforcement-learning" class="md-nav__link">
    Reinforcement Learning
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-scikit-learn-module" class="md-nav__link">
    The scikit-learn Module
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#basic-supervised-learning" class="md-nav__link">
    Basic Supervised Learning
  </a>
  
    <nav class="md-nav" aria-label="Basic Supervised Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#with-a-hard-coded-dataset" class="md-nav__link">
    With a Hard-Coded Dataset
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#linear-regression" class="md-nav__link">
    Linear Regression
  </a>
  
    <nav class="md-nav" aria-label="Linear Regression">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#r-code" class="md-nav__link">
    R Code
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#python-code" class="md-nav__link">
    Python Code
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#linear-regression-with-statsmodels" class="md-nav__link">
    Linear Regression with StatsModels
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#logistic-regression" class="md-nav__link">
    Logistic Regression
  </a>
  
    <nav class="md-nav" aria-label="Logistic Regression">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-r-code" class="md-nav__link">
    The R code
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-python-code" class="md-nav__link">
    The Python Code
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision-tree" class="md-nav__link">
    Decision tree
  </a>
  
    <nav class="md-nav" aria-label="Decision tree">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-r-code_1" class="md-nav__link">
    The R Code
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-python-code_1" class="md-nav__link">
    The Python Code
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#random-forests" class="md-nav__link">
    Random Forests
  </a>
  
    <nav class="md-nav" aria-label="Random Forests">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-r-code_2" class="md-nav__link">
    The R Code
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-python-code_2" class="md-nav__link">
    The Python Code
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#k-nearest-neighbours" class="md-nav__link">
    k-Nearest Neighbours
  </a>
  
    <nav class="md-nav" aria-label="k-Nearest Neighbours">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-r-code_3" class="md-nav__link">
    The R Code
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rescaling" class="md-nav__link">
    Rescaling
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-python-code_3" class="md-nav__link">
    The Python Code
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#naive-bayes" class="md-nav__link">
    Naïve Bayes
  </a>
  
    <nav class="md-nav" aria-label="Naïve Bayes">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-r-code_4" class="md-nav__link">
    The R Code
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-python-code_4" class="md-nav__link">
    The Python Code
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#support-vector-machine" class="md-nav__link">
    Support Vector Machine
  </a>
  
    <nav class="md-nav" aria-label="Support Vector Machine">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-r-code_5" class="md-nav__link">
    The R Code
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-python-code_5" class="md-nav__link">
    The Python Code
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#split-a-dataset" class="md-nav__link">
    Split a dataset
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#intermediate-supervised-learning" class="md-nav__link">
    Intermediate Supervised Learning
  </a>
  
    <nav class="md-nav" aria-label="Intermediate Supervised Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#logistic-regression_1" class="md-nav__link">
    Logistic regression
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision-tree_1" class="md-nav__link">
    Decision tree
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#random-forests_1" class="md-nav__link">
    Random Forests
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#k-nearest-neighbours_1" class="md-nav__link">
    k-Nearest Neighbours
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#naive-bayes_1" class="md-nav__link">
    Naïve Bayes
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#support-vector-machine_1" class="md-nav__link">
    Support Vector Machine
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#unsupervised-learning_1" class="md-nav__link">
    Unsupervised Learning
  </a>
  
    <nav class="md-nav" aria-label="Unsupervised Learning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#k-means" class="md-nav__link">
    k-Means
  </a>
  
    <nav class="md-nav" aria-label="k-Means">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-r-code_6" class="md-nav__link">
    The R Code
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-python-code_6" class="md-nav__link">
    The Python Code
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dimension-reduction" class="md-nav__link">
    Dimension Reduction
  </a>
  
    <nav class="md-nav" aria-label="Dimension Reduction">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#principal-component-analysis" class="md-nav__link">
    Principal Component Analysis
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/ugoproto/ugo_py_doc.git/edit/master/docs/overview_of_scikit_learn.md" title="Edit this page" class="md-content__button md-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg>
                  </a>
                
                
                  <h1>Overview of scikit-learn</h1>
                
                <h2 id="three-types-of-machine-learning-algorithms">Three types of Machine Learning Algorithms<a class="headerlink" href="#three-types-of-machine-learning-algorithms" title="Permanent link">&para;</a></h2>
<h3 id="supervised-learning">Supervised Learning<a class="headerlink" href="#supervised-learning" title="Permanent link">&para;</a></h3>
<p>The algorithm consist of a target/outcome variable (or dependent variable) which is to be predicted from a given set of predictors (independent variables). Using these set of variables, we generate a function that map inputs to desired outputs. The training process continues until the model achieves a desired level of accuracy on the training data.</p>
<p>Examples of Supervised Learning: Regression, Decision Tree, Random Forest, kNN, Logistic Regression, etc.</p>
<h3 id="unsupervised-learning">Unsupervised Learning<a class="headerlink" href="#unsupervised-learning" title="Permanent link">&para;</a></h3>
<p>In this algorithm, we do not have any target or outcome variable to predict/estimate. It is used for clustering population in different groups, which is widely used for segmenting customers in different groups for specific intervention.</p>
<p>Examples of Unsupervised Learning: Apriori, k-means.</p>
<h3 id="reinforcement-learning">Reinforcement Learning<a class="headerlink" href="#reinforcement-learning" title="Permanent link">&para;</a></h3>
<p>Using this algorithm, the machine is trained to make specific decisions. It works this way: the machine is exposed to an environment where it trains itself continually using trial and error. This machine learns from past experience and tries to capture the best possible knowledge to make accurate business decisions.</p>
<p>Example of Reinforcement Learning: Markov Decision Process.</p>
<h2 id="the-scikit-learn-module">The scikit-learn Module<a class="headerlink" href="#the-scikit-learn-module" title="Permanent link">&para;</a></h2>
<p><img alt="" src="../img/overview_of_scikit/scikit-learn.png" /></p>
<h2 id="basic-supervised-learning">Basic Supervised Learning<a class="headerlink" href="#basic-supervised-learning" title="Permanent link">&para;</a></h2>
<h3 id="with-a-hard-coded-dataset">With a Hard-Coded Dataset<a class="headerlink" href="#with-a-hard-coded-dataset" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="c1"># [height, weight, shoe_size]</span>
<span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">181</span><span class="p">,</span> <span class="mi">80</span><span class="p">,</span> <span class="mi">44</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">177</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="mi">43</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">160</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">38</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">154</span><span class="p">,</span> <span class="mi">54</span><span class="p">,</span> <span class="mi">37</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">166</span><span class="p">,</span> <span class="mi">65</span><span class="p">,</span> <span class="mi">40</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">190</span><span class="p">,</span> <span class="mi">90</span><span class="p">,</span> <span class="mi">47</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">175</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">39</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">177</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="mi">40</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">159</span><span class="p">,</span> <span class="mi">55</span><span class="p">,</span> <span class="mi">37</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">171</span><span class="p">,</span> <span class="mi">75</span><span class="p">,</span> <span class="mi">42</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">181</span><span class="p">,</span> <span class="mi">85</span><span class="p">,</span> <span class="mi">43</span><span class="p">]]</span>

<span class="n">Y</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;male&#39;</span><span class="p">,</span> <span class="s1">&#39;male&#39;</span><span class="p">,</span> <span class="s1">&#39;female&#39;</span><span class="p">,</span> <span class="s1">&#39;female&#39;</span><span class="p">,</span> <span class="s1">&#39;male&#39;</span><span class="p">,</span> <span class="s1">&#39;male&#39;</span><span class="p">,</span> <span class="s1">&#39;female&#39;</span><span class="p">,</span> <span class="s1">&#39;female&#39;</span><span class="p">,</span> <span class="s1">&#39;female&#39;</span><span class="p">,</span> <span class="s1">&#39;male&#39;</span><span class="p">,</span> <span class="s1">&#39;male&#39;</span><span class="p">]</span>

<span class="c1"># Convert the strings into booleans</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">Y</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="s1">&#39;male&#39;</span><span class="p">:</span>
        <span class="n">y_train</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">y_train</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">y_train</span>
</code></pre></div>
<h3 id="linear-regression">Linear Regression<a class="headerlink" href="#linear-regression" title="Permanent link">&para;</a></h3>
<p>We establish a relationship between independent and dependent variables by fitting the best line. This best fit line is known as the regression line: <span><span class="MathJax_Preview">Y = \alpha X + \beta</span><script type="math/tex">Y = \alpha X + \beta</script></span>.</p>
<p>There are different steps to improve the model:</p>
<ul>
<li>Using Multiple Linear regressions;</li>
<li>Including interaction terms;</li>
<li>Removing features;</li>
<li>Regularization techniques;</li>
<li>Using a non-linear model (polynomial and other curvilinear regressions).</li>
</ul>
<p>The code examples below are illustrations of the process. To handle a binary dependent variable (Y), we would rather work with classification models (including logistic regressions).</p>
<h4 id="r-code">R Code<a class="headerlink" href="#r-code" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="c1"># Load train and test datasets</span>
<span class="c1"># Identify the feature and response variable(s)</span>
<span class="c1"># Values must be numeric and numpy arrays</span>
<span class="n">x_train</span> <span class="o">&lt;-</span> <span class="n">input_variables_values_training_datasets</span>
<span class="n">y_train</span> <span class="o">&lt;-</span> <span class="n">target_variables_values_training_datasets</span>
<span class="n">x_test</span> <span class="o">&lt;-</span> <span class="n">input_variables_values_test_datasets</span>
<span class="n">x</span> <span class="o">&lt;-</span> <span class="nf">cbind</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Train the model using the training sets and</span>
<span class="c1"># Check the score</span>
<span class="n">linear</span> <span class="o">&lt;-</span> <span class="nf">lm</span><span class="p">(</span><span class="n">y_train</span> <span class="o">~</span> <span class="n">.</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">)</span>
<span class="nf">summary</span><span class="p">(</span><span class="n">linear</span><span class="p">)</span>

<span class="c1"># Predict the output</span>
<span class="n">predicted</span> <span class="o">&lt;-</span> <span class="nf">predict</span><span class="p">(</span><span class="n">linear</span><span class="p">,</span> <span class="n">x_test</span><span class="p">)</span> 
</code></pre></div>
<h4 id="python-code">Python Code<a class="headerlink" href="#python-code" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="c1"># Import the libraries</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="c1"># Load the Train and Test Datasets</span>
<span class="c1"># Identify feature and response variable(s) and</span>
<span class="c1"># Values must be numeric and numpy arrays</span>
<span class="c1">#x_train = input_variables_values_training_datasets</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">X</span>
<span class="c1">#y_train = target_variables_values_training_datasets</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span>
<span class="c1">#x_test = input_variables_values_test_datasets</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">190</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="mi">43</span><span class="p">],</span> <span class="p">[</span><span class="mi">160</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">38</span><span class="p">]]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="c1"># y_true</span>

<span class="c1"># Create the linear regression object</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">LinearRegression</span><span class="p">()</span>

<span class="c1"># Train the model</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code>LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,
         normalize=False)
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># Compute accuracy</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code><span class="mf">0.7754597107685945</span>
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># Equation intercept and coefficient</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Intercept (alpha): </span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Coefficient (betas): </span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code>Intercept (alpha): 
 -2.5061026710063232
Coefficient (betas): 
 [-0.03917782  0.00991846  0.22230002]
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># Predict the output</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="n">y_pred</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code>array([0.30330465, 0.26795454])
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># Compute accuracy</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code>-0.11436808286011502
</code></pre></div>
</td></tr></table>
<h3 id="linear-regression-with-statsmodels">Linear Regression with StatsModels<a class="headerlink" href="#linear-regression-with-statsmodels" title="Permanent link">&para;</a></h3>
<p><a href="http://www.statsmodels.org/stable/index.html">For more</a>.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Import the library</span>
<span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">sm</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># Load the Train and Test Datasets</span>
<span class="c1"># Identify feature and response variable(s) and</span>
<span class="c1"># Values must be numeric and numpy arrays</span>
<span class="c1">#x_train = input_variables_values_training_datasets</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">X</span>
<span class="c1">#y_train = target_variables_values_training_datasets</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span>
<span class="c1">#x_test = input_variables_values_test_datasets</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">190</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="mi">43</span><span class="p">],</span> <span class="p">[</span><span class="mi">160</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">38</span><span class="p">]]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="c1"># y_true</span>

<span class="c1"># Create a DataFrame</span>
<span class="n">df1</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;height&#39;</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">,</span> <span class="s1">&#39;shoe_size&#39;</span><span class="p">])</span>
<span class="n">df2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;gender&#39;</span><span class="p">])</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df1</span><span class="p">,</span> <span class="n">df2</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</code></pre></div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>height</th>
      <th>weight</th>
      <th>shoe_size</th>
      <th>gender</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>181</td>
      <td>80</td>
      <td>44</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>177</td>
      <td>70</td>
      <td>43</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>160</td>
      <td>60</td>
      <td>38</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>

<div class="highlight"><pre><span></span><code><span class="c1"># State the OLS model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span> <span class="o">=</span> <span class="s1">&#39;gender ~ height + weight + shoe_size&#39;</span><span class="p">,</span>
               <span class="n">data</span> <span class="o">=</span> <span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="c1"># Print the coefficients</span>
<span class="n">model</span><span class="o">.</span><span class="n">params</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code>Intercept   -2.506103
height      -0.039178
weight       0.009918
shoe_size    0.222300
dtype: float64
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># Print the stats</span>
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code><span class="o">/</span><span class="nv">home</span><span class="o">/</span><span class="nv">ugo</span><span class="o">/</span><span class="nv">miniconda3</span><span class="o">/</span><span class="nv">lib</span><span class="o">/</span><span class="nv">python3</span>.<span class="mi">6</span><span class="o">/</span><span class="nv">site</span><span class="o">-</span><span class="nv">packages</span><span class="o">/</span><span class="nv">scipy</span><span class="o">/</span><span class="nv">stats</span><span class="o">/</span><span class="nv">stats</span>.<span class="nv">py</span>:<span class="mi">1394</span>: <span class="nv">UserWarning</span>: <span class="nv">kurtosistest</span> <span class="nv">only</span> <span class="nv">valid</span> <span class="k">for</span> <span class="nv">n</span><span class="o">&gt;=</span><span class="mi">20</span> ... <span class="nv">continuing</span> <span class="nv">anyway</span>, <span class="nv">n</span><span class="o">=</span><span class="mi">11</span>
  <span class="s2">&quot;</span><span class="s">anyway, n=%i</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="nv">int</span><span class="ss">(</span><span class="nv">n</span><span class="ss">))</span>
</code></pre></div>
</td></tr></table>
<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>         <td>gender</td>      <th>  R-squared:         </th> <td>   0.775</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.679</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   8.058</td>
</tr>
<tr>
  <th>Date:</th>             <td>Wed, 21 Nov 2018</td> <th>  Prob (F-statistic):</th>  <td>0.0113</td> 
</tr>
<tr>
  <th>Time:</th>                 <td>13:16:06</td>     <th>  Log-Likelihood:    </th> <td> 0.27729</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>    11</td>      <th>  AIC:               </th> <td>   7.445</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>     7</td>      <th>  BIC:               </th> <td>   9.037</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   
</tr>
</table>
<table class="simpletable">
<tr>
      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th> <td>   -2.5061</td> <td>    2.924</td> <td>   -0.857</td> <td> 0.420</td> <td>   -9.420</td> <td>    4.407</td>
</tr>
<tr>
  <th>height</th>    <td>   -0.0392</td> <td>    0.022</td> <td>   -1.777</td> <td> 0.119</td> <td>   -0.091</td> <td>    0.013</td>
</tr>
<tr>
  <th>weight</th>    <td>    0.0099</td> <td>    0.028</td> <td>    0.352</td> <td> 0.735</td> <td>   -0.057</td> <td>    0.077</td>
</tr>
<tr>
  <th>shoe_size</th> <td>    0.2223</td> <td>    0.097</td> <td>    2.287</td> <td> 0.056</td> <td>   -0.008</td> <td>    0.452</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td> 0.165</td> <th>  Durbin-Watson:     </th> <td>   2.858</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.921</td> <th>  Jarque-Bera (JB):  </th> <td>   0.201</td>
</tr>
<tr>
  <th>Skew:</th>          <td> 0.201</td> <th>  Prob(JB):          </th> <td>   0.904</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 2.473</td> <th>  Cond. No.          </th> <td>6.25e+03</td>
</tr>
</table>
<p>Warnings:[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.[2] The condition number is large, 6.25e+03. This might indicate that there arestrong multicollinearity or other numerical problems.</p>
<h3 id="logistic-regression">Logistic Regression<a class="headerlink" href="#logistic-regression" title="Permanent link">&para;</a></h3>
<p>We estimate discrete values (binary values like 0/1, yes/no, true/false). It predicts the probability of occurrence of an event by fitting data to a logit function. Since, it predicts the probability, its output values lies between 0 and 1.</p>
<p>Note: we can work with strings in <code>Y</code>.</p>
<h4 id="the-r-code">The R code<a class="headerlink" href="#the-r-code" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="c1"># Load train and test datasets</span>
<span class="c1"># Identify the feature and response variable(s)</span>
<span class="c1"># Values must be numeric and numpy arrays</span>
<span class="n">x_train</span> <span class="o">&lt;-</span> <span class="n">input_variables_values_training_datasets</span>
<span class="n">y_train</span> <span class="o">&lt;-</span> <span class="n">target_variables_values_training_datasets</span>
<span class="n">x_test</span> <span class="o">&lt;-</span> <span class="n">input_variables_values_test_datasets</span>
<span class="n">x</span> <span class="o">&lt;-</span> <span class="nf">cbind</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Train the model using the training sets and</span>
<span class="c1"># Check the score</span>
<span class="n">logistic</span> <span class="o">&lt;-</span> <span class="nf">glm</span><span class="p">(</span><span class="n">y_train</span> <span class="o">~</span> <span class="n">.</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">family</span><span class="o">=</span><span class="s">&#39;binomial&#39;</span><span class="p">)</span>
<span class="nf">summary</span><span class="p">(</span><span class="n">logistic</span><span class="p">)</span>

<span class="c1"># Predict the output</span>
<span class="n">predicted</span> <span class="o">&lt;-</span> <span class="nf">predict</span><span class="p">(</span><span class="n">logistic</span><span class="p">,</span> <span class="n">x_test</span><span class="p">)</span>
</code></pre></div>
<h4 id="the-python-code">The Python Code<a class="headerlink" href="#the-python-code" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="c1"># Import the libraries</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="c1"># Load the Train and Test Datasets</span>
<span class="c1"># Identify feature and response variable(s) and</span>
<span class="c1"># Values must be numeric and numpy arrays</span>
<span class="c1">#x_train = input_variables_values_training_datasets</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">X</span>
<span class="c1">#y_train = target_variables_values_training_datasets</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span>
<span class="c1">#x_test = input_variables_values_test_datasets</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">190</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="mi">43</span><span class="p">],</span> <span class="p">[</span><span class="mi">160</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">38</span><span class="p">]]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="c1"># y_true</span>

<span class="c1"># Assume we have, X (predictor) and Y (target) for</span>
<span class="c1"># training data set and x_test(predictor) of</span>
<span class="c1"># test_dataset</span>
<span class="c1"># Create the logistic regression object</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">C</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
                           <span class="n">class_weight</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                           <span class="n">dual</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                           <span class="n">fit_intercept</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                           <span class="n">intercept_scaling</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> 
                           <span class="n">max_iter</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> 
                           <span class="n">multi_class</span> <span class="o">=</span> <span class="s1">&#39;ovr&#39;</span><span class="p">,</span>
                           <span class="n">n_jobs</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
                           <span class="n">penalty</span> <span class="o">=</span> <span class="s1">&#39;l2&#39;</span><span class="p">,</span>
                           <span class="n">random_state</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                           <span class="n">solver</span> <span class="o">=</span> <span class="s1">&#39;liblinear&#39;</span><span class="p">,</span>
                           <span class="n">tol</span> <span class="o">=</span> <span class="mf">0.0001</span><span class="p">,</span>
                           <span class="n">verbose</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> 
                           <span class="n">warm_start</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>

<span class="c1"># Train the model</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code>LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class=&#39;ovr&#39;, n_jobs=1,
          penalty=&#39;l2&#39;, random_state=None, solver=&#39;liblinear&#39;, tol=0.0001,
          verbose=0, warm_start=False)
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># Compute accuracy</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code><span class="mf">1.0</span>
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># Equation intercept and coefficient</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Coefficient: </span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Intercept: </span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code>Coefficient: 
 [[-0.43920419  0.62276186  0.8290359 ]]
Intercept: 
 [-0.00585817]
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># Predict the output</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="n">y_pred</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code>array([0, 0])
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># Compute accuracy</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code><span class="mf">0.5</span>
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># Print the metrics</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)))</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code><span class="k">[[1 0]</span>
 <span class="k">[1 0]]</span>
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)))</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code>              precision    recall  f1-score   support

           0       0.50      1.00      0.67         1
           1       0.00      0.00      0.00         1

   micro avg       0.50      0.50      0.50         2
   macro avg       0.25      0.50      0.33         2
weighted avg       0.25      0.50      0.33         2



/home/ugo/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  &#39;precision&#39;, &#39;predicted&#39;, average, warn_for)
</code></pre></div>
</td></tr></table>
<h3 id="decision-tree">Decision tree<a class="headerlink" href="#decision-tree" title="Permanent link">&para;</a></h3>
<p>It is a type of supervised learning algorithm that is mostly used for classification problems. Surprisingly, it works for both categorical and continuous dependent variables. In this algorithm, we split the population into two or more homogeneous sets. This is done based on most significant attributes/independent variables to make as distinct groups as possible.</p>
<p><a href="https://www.analyticsvidhya.com/blog/2016/04/complete-tutorial-tree-based-modeling-scratch-in-python/">Decision Tree Simplified</a>.</p>
<p>Note: we can work with strings in <code>Y</code>.</p>
<h4 id="the-r-code_1">The R Code<a class="headerlink" href="#the-r-code_1" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="nf">library</span><span class="p">(</span><span class="n">rpart</span><span class="p">)</span>

<span class="c1"># Load train and test datasets</span>
<span class="c1"># Identify the feature and response variable(s)</span>
<span class="c1"># Values must be numeric and numpy arrays</span>
<span class="n">x_train</span> <span class="o">&lt;-</span> <span class="n">input_variables_values_training_datasets</span>
<span class="n">y_train</span> <span class="o">&lt;-</span> <span class="n">target_variables_values_training_datasets</span>
<span class="n">x_test</span> <span class="o">&lt;-</span> <span class="n">input_variables_values_test_datasets</span>
<span class="n">x</span> <span class="o">&lt;-</span> <span class="nf">cbind</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Grow the tree </span>
<span class="n">fit</span> <span class="o">&lt;-</span> <span class="nf">rpart</span><span class="p">(</span><span class="n">y_train</span> <span class="o">~</span> <span class="n">.</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span> <span class="s">&quot;class&quot;</span><span class="p">)</span>
<span class="nf">summary</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>

<span class="c1"># Predict the output </span>
<span class="n">predicted</span> <span class="o">&lt;-</span> <span class="nf">predict</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span> <span class="n">x_test</span><span class="p">)</span>
</code></pre></div>
<h4 id="the-python-code_1">The Python Code<a class="headerlink" href="#the-python-code_1" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="c1"># Import the libraries</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">tree</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="c1"># Load the Train and Test Datasets</span>
<span class="c1"># Identify feature and response variable(s) and</span>
<span class="c1"># Values must be numeric and numpy arrays</span>
<span class="c1">#x_train = input_variables_values_training_datasets</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">X</span>
<span class="c1">#y_train = target_variables_values_training_datasets</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span>
<span class="c1">#x_test = input_variables_values_test_datasets</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">190</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="mi">43</span><span class="p">],</span> <span class="p">[</span><span class="mi">160</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">38</span><span class="p">]]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="c1"># y_true</span>

<span class="c1"># Assumed you have, X (predictor) and Y (target) for</span>
<span class="c1"># training data set and x_test(predictor) of</span>
<span class="c1"># test_dataset</span>
<span class="c1"># Create the tree object </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">criterion</span> <span class="o">=</span> <span class="s1">&#39;gini&#39;</span><span class="p">)</span>

<span class="c1"># For classification, we can change the algorithm</span>
<span class="c1"># as &#39;gini&#39; or &#39;entropy&#39; (information gain)</span>
<span class="c1"># by default it is &#39;gini&#39;</span>

<span class="c1"># For regression</span>
<span class="c1">#model = tree.DecisionTreeRegressor()</span>

<span class="c1"># Train the model</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code>DecisionTreeClassifier(class_weight=None, criterion=&#39;gini&#39;, max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter=&#39;best&#39;)
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># Compute accuracy</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code><span class="mf">1.0</span>
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># Predict the output</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="n">y_pred</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code>array([1, 0])
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># Compute accuracy</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code><span class="mf">1.0</span>
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># Print the metrics</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)))</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code><span class="k">[[1 0]</span>
 <span class="k">[0 1]]</span>
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)))</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span>
<span class="normal">8</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code>              precision    recall  f1-score   support

           0       1.00      1.00      1.00         1
           1       1.00      1.00      1.00         1

   micro avg       1.00      1.00      1.00         2
   macro avg       1.00      1.00      1.00         2
weighted avg       1.00      1.00      1.00         2
</code></pre></div>
</td></tr></table>
<h3 id="random-forests">Random Forests<a class="headerlink" href="#random-forests" title="Permanent link">&para;</a></h3>
<p>Random Forest is a term for an ensemble of decision trees. In Random Forest, we have collection of decision trees (so known as “Forest”). To classify a new object based on attributes, each tree gives a classification and we say the tree “votes” for that class. The forest chooses the classification having the most votes (over all the trees in the forest).</p>
<p>Each tree is planted and grown as follows:</p>
<ol>
<li>If the number of cases in the training set is N, then a sample of N cases is taken at random but with replacement. This sample will be the training set for growing the tree.</li>
<li>If there are M input variables, a number m &lt; M is specified such that at each node, m variables are selected at random out of the M and the best split on these m is used to split the node. The value of m is held constant during the forest growing.</li>
<li>Each tree is grown to the largest extent possible. There is no pruning.</li>
</ol>
<p>For more:<br />
- <a href="https://www.analyticsvidhya.com/blog/2014/06/introduction-random-forest-simplified/">Introduction to Random forest – Simplified</a><br />
- <a href="https://www.analyticsvidhya.com/blog/2014/06/comparing-cart-random-forest-1/">Comparing a CART model to Random Forest (Part 1)</a><br />
- <a href="https://www.analyticsvidhya.com/blog/2014/06/comparing-random-forest-simple-cart-model/">Comparing a Random Forest to a CART model (Part 2)</a><br />
- <a href="https://www.analyticsvidhya.com/blog/2015/06/tuning-random-forest-model/">Tuning the parameters of your Random Forest model</a></p>
<p>Note: we can work with strings in <code>Y</code>.</p>
<h4 id="the-r-code_2">The R Code<a class="headerlink" href="#the-r-code_2" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="nf">library</span><span class="p">(</span><span class="n">randomForest</span><span class="p">)</span>

<span class="c1"># Load train and test datasets</span>
<span class="c1"># Identify the feature and response variable(s)</span>
<span class="c1"># Values must be numeric and numpy arrays</span>
<span class="n">x_train</span> <span class="o">&lt;-</span> <span class="n">input_variables_values_training_datasets</span>
<span class="n">y_train</span> <span class="o">&lt;-</span> <span class="n">target_variables_values_training_datasets</span>
<span class="n">x_test</span> <span class="o">&lt;-</span> <span class="n">input_variables_values_test_datasets</span>
<span class="n">x</span> <span class="o">&lt;-</span> <span class="nf">cbind</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Fitting the model</span>
<span class="n">fit</span> <span class="o">&lt;-</span> <span class="nf">randomForest</span><span class="p">(</span><span class="n">y_train</span> <span class="o">~</span> <span class="n">.</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">ntree</span> <span class="o">=</span> <span class="m">500</span><span class="p">)</span>
<span class="nf">summary</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>

<span class="c1"># Predict the output </span>
<span class="n">predicted</span> <span class="o">&lt;-</span> <span class="nf">predict</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span> <span class="n">x_test</span><span class="p">)</span>
</code></pre></div>
<h4 id="the-python-code_2">The Python Code<a class="headerlink" href="#the-python-code_2" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="c1"># Import the libraries</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="c1"># Load the Train and Test Datasets</span>
<span class="c1"># Identify feature and response variable(s) and</span>
<span class="c1"># Values must be numeric and numpy arrays</span>
<span class="c1">#x_train = input_variables_values_training_datasets</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">X</span>
<span class="c1">#y_train = target_variables_values_training_datasets</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span>
<span class="c1">#x_test = input_variables_values_test_datasets</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">190</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="mi">43</span><span class="p">],</span> <span class="p">[</span><span class="mi">160</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">38</span><span class="p">]]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="c1"># y_true</span>

<span class="c1"># Assume we have, X (predictor) and Y (target) for</span>
<span class="c1"># training data set and x_test(predictor) of</span>
<span class="c1"># test_dataset</span>
<span class="c1"># Create the Random Forest object</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">)</span>

<span class="c1"># Train the model</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code>RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
            max_depth=None, max_features=&#39;auto&#39;, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=None,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># Compute accuracy</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code><span class="mf">1.0</span>
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># Predict the output</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="n">y_pred</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code>array([1, 0])
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># Compute accuracy</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code><span class="mf">1.0</span>
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># Print the metrics</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)))</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code><span class="k">[[1 0]</span>
 <span class="k">[0 1]]</span>
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)))</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span>
<span class="normal">8</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code>              precision    recall  f1-score   support

           0       1.00      1.00      1.00         1
           1       1.00      1.00      1.00         1

   micro avg       1.00      1.00      1.00         2
   macro avg       1.00      1.00      1.00         2
weighted avg       1.00      1.00      1.00         2
</code></pre></div>
</td></tr></table>
<h3 id="k-nearest-neighbours">k-Nearest Neighbours<a class="headerlink" href="#k-nearest-neighbours" title="Permanent link">&para;</a></h3>
<p>kNN can be used for both classification and regression problems. However, it is more widely used in classification problems in the industry. k-NN is a simple algorithm that stores all available cases and classifies new cases by a majority vote of its k neighbors. The case being assigned to the class is most common amongst its kNN measured by a distance function.</p>
<p>These distance functions can be:</p>
<ul>
<li>Euclidean, </li>
<li>Manhattan, </li>
<li>Minkowski, and </li>
<li>Hamming. </li>
</ul>
<p>First three functions are used for continuous function and fourth one (Hamming) for categorical variables. If <code>k = 1</code>, then the case is simply assigned to the class of its nearest neighbor. At times, choosing k turns out to be a challenge while performing kNN modeling.</p>
<p>Things to consider before selecting kNN:</p>
<ul>
<li>kNN is computationally expensive;</li>
<li>Variables should be <strong>normalized</strong>/standardized/rescaled or else higher range variables can bias it;</li>
<li>Works on pre-processing stage more before going for kNN like outlier, noise removal.</li>
</ul>
<p>Note: we can work with strings in <code>Y</code>.</p>
<h4 id="the-r-code_3">The R Code<a class="headerlink" href="#the-r-code_3" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="nf">library</span><span class="p">(</span><span class="n">knn</span><span class="p">)</span>

<span class="c1"># Load train and test datasets</span>
<span class="c1"># Identify the feature and response variable(s)</span>
<span class="c1"># Values must be numeric and numpy arrays</span>
<span class="n">x_train</span> <span class="o">&lt;-</span> <span class="n">input_variables_values_training_datasets</span>
<span class="n">y_train</span> <span class="o">&lt;-</span> <span class="n">target_variables_values_training_datasets</span>
<span class="n">x_test</span> <span class="o">&lt;-</span> <span class="n">input_variables_values_test_datasets</span>
<span class="n">x</span> <span class="o">&lt;-</span> <span class="nf">cbind</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Fitting the model</span>
<span class="n">fit</span> <span class="o">&lt;-</span> <span class="nf">knn</span><span class="p">(</span><span class="n">y_train</span> <span class="o">~</span> <span class="n">.</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="m">5</span><span class="p">)</span>
<span class="nf">summary</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>

<span class="c1"># Predict the output </span>
<span class="n">predicted</span> <span class="o">&lt;-</span> <span class="nf">predict</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span> <span class="n">x_test</span><span class="p">)</span>
</code></pre></div>
<h4 id="rescaling">Rescaling<a class="headerlink" href="#rescaling" title="Permanent link">&para;</a></h4>
<p>Normalization: <span><span class="MathJax_Preview">x = \frac{ x - x_{min} }{ x_{max} - x_{min} }</span><script type="math/tex">x = \frac{ x - x_{min} }{ x_{max} - x_{min} }</script></span>, transforms features by scaling each feature to a given range.</p>
<p>Standardization: <span><span class="MathJax_Preview">x = \frac{x - \mu}{\sigma}</span><script type="math/tex">x = \frac{x - \mu}{\sigma}</script></span>, centers to the mean and component wise scale to unit variance.</p>
<p>Consult the documentation for more.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Standardize</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">scale</span>

<span class="c1"># Scale the independent variables</span>
<span class="n">X_s</span> <span class="o">=</span> <span class="n">scale</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_s</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>


<span class="c1"># Normalize</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>

<span class="c1"># Scale the independent variables</span>
<span class="n">min_max_scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="n">X_s</span> <span class="o">=</span> <span class="n">min_max_scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">minmax_scale</span>
<span class="n">X_s</span> <span class="o">=</span> <span class="n">minmax_scale</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</code></pre></div>
<h4 id="the-python-code_3">The Python Code<a class="headerlink" href="#the-python-code_3" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="c1"># Import the libraries</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="c1"># Load the Train and Test Datasets</span>
<span class="c1"># Identify feature and response variable(s) and</span>
<span class="c1"># Values must be numeric and numpy arrays</span>
<span class="c1">#x_train = input_variables_values_training_datasets</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">X</span>
<span class="c1">#y_train = target_variables_values_training_datasets</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span>
<span class="c1">#x_test = input_variables_values_test_datasets</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">190</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="mi">43</span><span class="p">],</span> <span class="p">[</span><span class="mi">160</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">38</span><span class="p">]]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="c1"># y_true</span>

<span class="c1"># Assume we have, X (predictor) and Y (target) for</span>
<span class="c1"># training data set and x_test(predictor) of</span>
<span class="c1"># test_dataset</span>
<span class="c1"># Create the KNeighbors classifier object model </span>
<span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="mi">6</span><span class="p">,</span>
                     <span class="n">algorithm</span> <span class="o">=</span> <span class="s1">&#39;auto&#39;</span><span class="p">,</span>
                     <span class="n">leaf_size</span> <span class="o">=</span> <span class="mi">30</span><span class="p">,</span>
                     <span class="n">metric</span> <span class="o">=</span> <span class="s1">&#39;minkowski&#39;</span><span class="p">,</span>
                     <span class="n">metric_params</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                     <span class="n">n_jobs</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
                     <span class="n">p</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
                     <span class="n">weights</span> <span class="o">=</span> <span class="s1">&#39;uniform&#39;</span><span class="p">)</span> <span class="c1"># default value for n_neighbors is 5</span>

<span class="c1"># Train the model</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code>RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
            max_depth=None, max_features=&#39;auto&#39;, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=None,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># Compute accuracy</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code><span class="mf">1.0</span>
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># Predict the output</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="n">y_pred</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code>array([1, 0])
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># Compute accuracy</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code><span class="mf">1.0</span>
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># Print the metrics</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)))</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code><span class="k">[[1 0]</span>
 <span class="k">[0 1]]</span>
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)))</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span>
<span class="normal">8</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code>              precision    recall  f1-score   support

           0       1.00      1.00      1.00         1
           1       1.00      1.00      1.00         1

   micro avg       1.00      1.00      1.00         2
   macro avg       1.00      1.00      1.00         2
weighted avg       1.00      1.00      1.00         2
</code></pre></div>
</td></tr></table>
<h3 id="naive-bayes">Naïve Bayes<a class="headerlink" href="#naive-bayes" title="Permanent link">&para;</a></h3>
<p>It is a classification technique based on Bayes’ theorem with an assumption of independence between predictors. In simple terms, a Naive Bayes classifier assumes that the presence of a particular feature in a class is unrelated to the presence of any other feature. For example, a fruit may be considered to be an apple if it is red, round, and about 3 inches in diameter. Even if these features depend on each other or upon the existence of the other features, a naive Bayes classifier would consider all of these properties to independently contribute to the probability that this fruit is an apple.</p>
<p>Naive Bayesian model is easy to build and particularly useful for very large data sets. Along with simplicity, Naive Bayes is known to outperform even highly sophisticated classification methods.</p>
<p><a href="https://scikit-learn.org/stable/modules/naive_bayes.html">Documentation</a>.</p>
<p>Note: we can work with strings in <code>Y</code>.</p>
<h4 id="the-r-code_4">The R Code<a class="headerlink" href="#the-r-code_4" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="nf">library</span><span class="p">(</span><span class="n">e1071</span><span class="p">)</span>

<span class="c1"># Load train and test datasets</span>
<span class="c1"># Identify the feature and response variable(s)</span>
<span class="c1"># Values must be numeric and numpy arrays</span>
<span class="n">x_train</span> <span class="o">&lt;-</span> <span class="n">input_variables_values_training_datasets</span>
<span class="n">y_train</span> <span class="o">&lt;-</span> <span class="n">target_variables_values_training_datasets</span>
<span class="n">x_test</span> <span class="o">&lt;-</span> <span class="n">input_variables_values_test_datasets</span>
<span class="n">x</span> <span class="o">&lt;-</span> <span class="nf">cbind</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Fitting the model</span>
<span class="n">fit</span> <span class="o">&lt;-</span> <span class="nf">naiveBayes</span><span class="p">(</span><span class="n">y_train</span> <span class="o">~</span> <span class="n">.</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">)</span>
<span class="nf">summary</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>

<span class="c1"># Predict the output </span>
<span class="n">predicted</span> <span class="o">&lt;-</span> <span class="nf">predict</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span> <span class="n">x_test</span><span class="p">)</span>
<span class="n">predicted</span>
</code></pre></div>
<h4 id="the-python-code_4">The Python Code<a class="headerlink" href="#the-python-code_4" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="c1"># Import the libraries</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="c1"># Load the Train and Test Datasets</span>
<span class="c1"># Identify feature and response variable(s) and</span>
<span class="c1"># Values must be numeric and numpy arrays</span>
<span class="c1">#x_train = input_variables_values_training_datasets</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">X</span>
<span class="c1">#y_train = target_variables_values_training_datasets</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span>
<span class="c1">#x_test = input_variables_values_test_datasets</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">190</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="mi">43</span><span class="p">],</span> <span class="p">[</span><span class="mi">160</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">38</span><span class="p">]]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="c1"># y_true</span>

<span class="c1"># Assume you have, X (predictor) and Y (target) for</span>
<span class="c1"># training data set and x_test(predictor) of</span>
<span class="c1"># test_dataset</span>
<span class="c1"># Create SVM classification object</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span> 

<span class="c1"># There is other distribution for</span>
<span class="c1"># multinomial classes like Bernoulli Naive Bayes</span>

<span class="c1"># Train the model</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code><span class="n">GaussianNB</span><span class="p">(</span><span class="n">priors</span><span class="o">=</span><span class="n">None</span><span class="p">,</span> <span class="n">var_smoothing</span><span class="o">=</span><span class="mf">1e-09</span><span class="p">)</span>
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># Compute accuracy</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code><span class="mf">0.8181818181818182</span>
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># Predict the output</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="n">y_pred</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code>array([1, 0])
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># Compute accuracy</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code><span class="mf">1.0</span>
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># Print the metrics</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)))</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code><span class="k">[[1 0]</span>
 <span class="k">[0 1]]</span>
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)))</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span>
<span class="normal">8</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code>              precision    recall  f1-score   support

           0       1.00      1.00      1.00         1
           1       1.00      1.00      1.00         1

   micro avg       1.00      1.00      1.00         2
   macro avg       1.00      1.00      1.00         2
weighted avg       1.00      1.00      1.00         2
</code></pre></div>
</td></tr></table>
<h3 id="support-vector-machine">Support Vector Machine<a class="headerlink" href="#support-vector-machine" title="Permanent link">&para;</a></h3>
<p>SVM is a classification method. In this algorithm, we plot each data item as a point in n-dimensional space (where n is number of features you have) with the value of each feature being the value of a particular coordinate.</p>
<p><a href="https://www.analyticsvidhya.com/blog/2014/10/support-vector-machine-simplified/">For more</a>.</p>
<p>Note: we can work with strings in <code>Y</code>.</p>
<h4 id="the-r-code_5">The R Code<a class="headerlink" href="#the-r-code_5" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="nf">library</span><span class="p">(</span><span class="n">e1071</span><span class="p">)</span>

<span class="c1"># Load train and test datasets</span>
<span class="c1"># Identify the feature and response variable(s)</span>
<span class="c1"># Values must be numeric and numpy arrays</span>
<span class="n">x_train</span> <span class="o">&lt;-</span> <span class="n">input_variables_values_training_datasets</span>
<span class="n">y_train</span> <span class="o">&lt;-</span> <span class="n">target_variables_values_training_datasets</span>
<span class="n">x_test</span> <span class="o">&lt;-</span> <span class="n">input_variables_values_test_datasets</span>
<span class="n">x</span> <span class="o">&lt;-</span> <span class="nf">cbind</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Fitting the model</span>
<span class="n">fit</span> <span class="o">&lt;-</span> <span class="nf">svm</span><span class="p">(</span><span class="n">y_train</span> <span class="o">~</span> <span class="n">.</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">)</span>
<span class="nf">summary</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>

<span class="c1"># Predict the output </span>
<span class="n">predicted</span> <span class="o">&lt;-</span> <span class="nf">predict</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span> <span class="n">x_test</span><span class="p">)</span>
</code></pre></div>
<h4 id="the-python-code_5">The Python Code<a class="headerlink" href="#the-python-code_5" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="c1"># Import the libraries</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">svm</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="c1"># Load the Train and Test Datasets</span>
<span class="c1"># Identify feature and response variable(s) and</span>
<span class="c1"># Values must be numeric and numpy arrays</span>
<span class="c1">#x_train = input_variables_values_training_datasets</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">X</span>
<span class="c1">#y_train = target_variables_values_training_datasets</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span>
<span class="c1">#x_test = input_variables_values_test_datasets</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">190</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="mi">43</span><span class="p">],</span> <span class="p">[</span><span class="mi">160</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">38</span><span class="p">]]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="c1"># y_true</span>

<span class="c1"># Assume we have, X (predictor) and Y (target) for</span>
<span class="c1"># training data set and x_test(predictor) of</span>
<span class="c1"># test_dataset</span>
<span class="c1"># Create the SVM classification object </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">gamma</span> <span class="o">=</span> <span class="s1">&#39;auto&#39;</span><span class="p">)</span> 

<span class="c1"># There is various option associated with it,</span>
<span class="c1"># this is simple for classification</span>

<span class="c1"># Train the model</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code>SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=&#39;ovr&#39;, degree=3, gamma=&#39;auto&#39;, kernel=&#39;rbf&#39;,
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># Compute accuracy</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code><span class="mf">1.0</span>
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># Predict the output</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="n">y_pred</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code>array([1, 0])
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># Compute accuracy</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code><span class="mf">1.0</span>
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># Print the metrics</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)))</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code><span class="k">[[1 0]</span>
 <span class="k">[0 1]]</span>
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)))</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span>
<span class="normal">8</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code>              precision    recall  f1-score   support

           0       1.00      1.00      1.00         1
           1       1.00      1.00      1.00         1

   micro avg       1.00      1.00      1.00         2
   macro avg       1.00      1.00      1.00         2
weighted avg       1.00      1.00      1.00         2
</code></pre></div>
</td></tr></table>
<h2 id="split-a-dataset">Split a dataset<a class="headerlink" href="#split-a-dataset" title="Permanent link">&para;</a></h2>
<p>We can automate the split.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Import the libraries</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="c1"># Split the dataset</span>
<span class="c1"># 80% for training (train set)</span>
<span class="c1"># 20% for testing (test set)</span>
<span class="n">Xs_train</span><span class="p">,</span> <span class="n">Xs_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span>
                                                      <span class="n">Y</span><span class="p">,</span>
                                                      <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span>
                                                      <span class="n">random_state</span> <span class="o">=</span> <span class="mi">42</span><span class="p">)</span>
</code></pre></div>
<h2 id="intermediate-supervised-learning">Intermediate Supervised Learning<a class="headerlink" href="#intermediate-supervised-learning" title="Permanent link">&para;</a></h2>
<h3 id="logistic-regression_1">Logistic regression<a class="headerlink" href="#logistic-regression_1" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="c1"># Import the libraries</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>

<span class="c1"># Import the data</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/adults.txt&#39;</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">)</span>

<span class="c1"># Convert the string labels to numeric labels</span>
<span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;race&#39;</span><span class="p">,</span> <span class="s1">&#39;occupation&#39;</span><span class="p">]:</span>
    <span class="n">data</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">label</span><span class="p">])</span>
<span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</code></pre></div>
<p><br/><br/><br/><br/><br/><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>workclass</th>
      <th>final_weight</th>
      <th>education</th>
      <th>education_num</th>
      <th>marital_status</th>
      <th>occupation</th>
      <th>relationship</th>
      <th>race</th>
      <th>sex</th>
      <th>capital_gain</th>
      <th>capital_loss</th>
      <th>hours_per_week</th>
      <th>native_country</th>
      <th>salary</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>39</td>
      <td>State-gov</td>
      <td>77516</td>
      <td>Bachelors</td>
      <td>13</td>
      <td>Never-married</td>
      <td>1</td>
      <td>Not-in-family</td>
      <td>4</td>
      <td>Male</td>
      <td>2174</td>
      <td>0</td>
      <td>40</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>1</th>
      <td>50</td>
      <td>Self-emp-not-inc</td>
      <td>83311</td>
      <td>Bachelors</td>
      <td>13</td>
      <td>Married-civ-spouse</td>
      <td>4</td>
      <td>Husband</td>
      <td>4</td>
      <td>Male</td>
      <td>0</td>
      <td>0</td>
      <td>13</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>2</th>
      <td>38</td>
      <td>Private</td>
      <td>215646</td>
      <td>HS-grad</td>
      <td>9</td>
      <td>Divorced</td>
      <td>6</td>
      <td>Not-in-family</td>
      <td>4</td>
      <td>Male</td>
      <td>0</td>
      <td>0</td>
      <td>40</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
  </tbody>
</table>
</div>
</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Take the fields of interest and</span>
<span class="c1"># plug them into variable X</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="p">[[</span><span class="s1">&#39;race&#39;</span><span class="p">,</span> <span class="s1">&#39;hours_per_week&#39;</span><span class="p">,</span> <span class="s1">&#39;occupation&#39;</span><span class="p">]]</span>

<span class="c1"># Provide the corresponding values</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;sex&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="c1"># Import the libraries</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="c1"># Split the data into a test (30%) and train set (70%)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">Y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="c1"># Instantiate the classifier</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>

<span class="c1"># Train the model</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>

<span class="c1"># Compute accuracy</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Accuracy: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">accuracy</span><span class="p">))</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code>/home/ugo/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)


Accuracy: 0.6801105537926093
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># Predict the output</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">prediction</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code><span class="k">[&#39;Male&#39; &#39;Male&#39; &#39;Male&#39; ... &#39;Male&#39; &#39;Male&#39; &#39;Male&#39;]</span>





<span class="na">array([&#39;Male&#39;, &#39;Male&#39;, &#39;Male&#39;, ..., &#39;Male&#39;, &#39;Male&#39;, &#39;Male&#39;], dtype</span><span class="o">=</span><span class="s">&#39;&lt;U6&#39;)</span>
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># Print the confusion matrix and report</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">))</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code><span class="k">[[ 498  446]</span>
 <span class="k">[2679 6146]]</span>
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">))</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span>
<span class="normal">8</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code>              precision    recall  f1-score   support

      Female       0.16      0.53      0.24       944
        Male       0.93      0.70      0.80      8825

   micro avg       0.68      0.68      0.68      9769
   macro avg       0.54      0.61      0.52      9769
weighted avg       0.86      0.68      0.74      9769
</code></pre></div>
</td></tr></table>
<h3 id="decision-tree_1">Decision tree<a class="headerlink" href="#decision-tree_1" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="c1"># Import the libraries</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">tree</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="c1"># Instantiate the classifier</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeClassifier</span><span class="p">()</span>

<span class="c1"># Train the model</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>

<span class="c1"># Compute accuracy</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Accuracy: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">accuracy</span><span class="p">))</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code><span class="n">Accuracy</span><span class="o">:</span> <span class="mf">0.7340567100010237</span>
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># Predict the output</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">prediction</span>

<span class="c1"># Print the confusion matrix and report</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">))</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code><span class="k">[[1592 1013]</span>
 <span class="k">[1585 5579]]</span>
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">))</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span>
<span class="normal">8</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code>              precision    recall  f1-score   support

      Female       0.50      0.61      0.55      2603
        Male       0.85      0.78      0.81      7166

   micro avg       0.73      0.73      0.73      9769
   macro avg       0.67      0.69      0.68      9769
weighted avg       0.75      0.73      0.74      9769
</code></pre></div>
</td></tr></table>
<h3 id="random-forests_1">Random Forests<a class="headerlink" href="#random-forests_1" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="c1"># Import the libraries</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>


<span class="c1"># Instantiate the classifier</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">)</span>

<span class="c1"># Train the model</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>

<span class="c1"># Compute accuracy</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Accuracy: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">accuracy</span><span class="p">))</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code><span class="n">Accuracy</span><span class="o">:</span> <span class="mf">0.73303306377316</span>
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># Predict the output</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">prediction</span>

<span class="c1"># Print the confusion matrix and report</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">))</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code><span class="k">[[1497  928]</span>
 <span class="k">[1680 5664]]</span>
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">))</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span>
<span class="normal">8</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code>              precision    recall  f1-score   support

      Female       0.47      0.62      0.53      2425
        Male       0.86      0.77      0.81      7344

   micro avg       0.73      0.73      0.73      9769
   macro avg       0.67      0.69      0.67      9769
weighted avg       0.76      0.73      0.74      9769
</code></pre></div>
</td></tr></table>
<h3 id="k-nearest-neighbours_1">k-Nearest Neighbours<a class="headerlink" href="#k-nearest-neighbours_1" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="c1"># Import the libraries</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="c1"># Instantiate the classifier</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>

<span class="c1"># Train the model</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>

<span class="c1"># Compute accuracy</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Accuracy: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">accuracy</span><span class="p">))</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code><span class="n">Accuracy</span><span class="o">:</span> <span class="mf">0.6849216910635685</span>
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># Predict the output</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">prediction</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code>array([&#39;Female&#39;, &#39;Female&#39;, &#39;Male&#39;, ..., &#39;Female&#39;, &#39;Male&#39;, &#39;Male&#39;],
      dtype=&#39;&lt;U6&#39;)
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># Print the confusion matrix and report</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">))</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code><span class="k">[[1745 1646]</span>
 <span class="k">[1432 4946]]</span>
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">))</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span>
<span class="normal">8</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code>              precision    recall  f1-score   support

      Female       0.55      0.51      0.53      3391
        Male       0.75      0.78      0.76      6378

   micro avg       0.68      0.68      0.68      9769
   macro avg       0.65      0.65      0.65      9769
weighted avg       0.68      0.68      0.68      9769
</code></pre></div>
</td></tr></table>
<h3 id="naive-bayes_1">Naïve Bayes<a class="headerlink" href="#naive-bayes_1" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="c1"># Import the libraries</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="c1"># Instantiate the classifier</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>

<span class="c1"># Train the model</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>

<span class="c1"># Compute accuracy</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Accuracy: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">accuracy</span><span class="p">))</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code><span class="n">Accuracy</span><span class="o">:</span> <span class="mf">0.6708977377418365</span>
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># Predict the output</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">prediction</span><span class="p">)</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code>[&#39;Male&#39; &#39;Female&#39; &#39;Male&#39; ... &#39;Male&#39; &#39;Male&#39; &#39;Male&#39;]
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># Print the confusion matrix and report</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">))</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code><span class="k">[[ 636  674]</span>
 <span class="k">[2541 5918]]</span>
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">))</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span>
<span class="normal">8</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code>              precision    recall  f1-score   support

      Female       0.20      0.49      0.28      1310
        Male       0.90      0.70      0.79      8459

   micro avg       0.67      0.67      0.67      9769
   macro avg       0.55      0.59      0.53      9769
weighted avg       0.80      0.67      0.72      9769
</code></pre></div>
</td></tr></table>
<h3 id="support-vector-machine_1">Support Vector Machine<a class="headerlink" href="#support-vector-machine_1" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="c1"># Import the libraries</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">svm</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="c1"># Instantiate the classifier</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">gamma</span> <span class="o">=</span> <span class="s1">&#39;auto&#39;</span><span class="p">)</span>

<span class="c1"># Train the model</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>

<span class="c1"># Compute accuracy</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Accuracy: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">accuracy</span><span class="p">))</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code><span class="n">Accuracy</span><span class="o">:</span> <span class="mf">0.7360016378339646</span>
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># Predict the output</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">prediction</span><span class="p">)</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code>[&#39;Male&#39; &#39;Female&#39; &#39;Female&#39; ... &#39;Female&#39; &#39;Male&#39; &#39;Male&#39;]
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># Print the confusion matrix and report</span>
<span class="nb">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">))</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code><span class="k">[[1519  921]</span>
 <span class="k">[1658 5671]]</span>
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">))</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span>
<span class="normal">6</span>
<span class="normal">7</span>
<span class="normal">8</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code>              precision    recall  f1-score   support

      Female       0.48      0.62      0.54      2440
        Male       0.86      0.77      0.81      7329

   micro avg       0.74      0.74      0.74      9769
   macro avg       0.67      0.70      0.68      9769
weighted avg       0.76      0.74      0.75      9769
</code></pre></div>
</td></tr></table>
<h2 id="unsupervised-learning_1">Unsupervised Learning<a class="headerlink" href="#unsupervised-learning_1" title="Permanent link">&para;</a></h2>
<h3 id="k-means">k-Means<a class="headerlink" href="#k-means" title="Permanent link">&para;</a></h3>
<p>It is an unsupervised algorithm which solves clustering problems. Assume k clusters, data points inside one cluster are homogeneous, but heterogeneous to peer groups.</p>
<p>In k-means, we have clusters and each cluster has its own centroid. Sum of square of difference between centroid and the data points within a cluster constitutes within sum of square value for that cluster. Also, when the sum of square values for all the clusters are added, it becomes total within sum of square value for the cluster solution.</p>
<p>We know that as the number of cluster increases, this value keeps on decreasing but if you plot the result you may see that the sum of squared distance decreases sharply up to some value of k, and then much more slowly after that. Here, we can find the optimum number of cluster.</p>
<h4 id="the-r-code_6">The R Code<a class="headerlink" href="#the-r-code_6" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="nf">library</span><span class="p">(</span><span class="n">cluster</span><span class="p">)</span>

<span class="c1"># Load train and test datasets</span>
<span class="c1"># Identify the feature and response variable(s)</span>
<span class="c1"># Values must be numeric and numpy arrays</span>
<span class="n">x_train</span> <span class="o">&lt;-</span> <span class="n">input_variables_values_training_datasets</span>
<span class="n">y_train</span> <span class="o">&lt;-</span> <span class="n">target_variables_values_training_datasets</span>
<span class="n">x_test</span> <span class="o">&lt;-</span> <span class="n">input_variables_values_test_datasets</span>
<span class="n">x</span> <span class="o">&lt;-</span> <span class="nf">cbind</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">fit</span> <span class="o">&lt;-</span> <span class="nf">kmeans</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="m">3</span><span class="p">)</span>
</code></pre></div>
<h4 id="the-python-code_6">The Python Code<a class="headerlink" href="#the-python-code_6" title="Permanent link">&para;</a></h4>
<div class="highlight"><pre><span></span><code><span class="c1"># Import the Libraries</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="c1"># Instantiate the classifier</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>

<span class="c1"># Train the model</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="c1"># Compute accuracy</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Accuracy: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">accuracy</span><span class="p">))</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code>Accuracy: -478732.018200623
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># Extract the parameters</span>
<span class="n">clf</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code>{&#39;algorithm&#39;: &#39;auto&#39;,
 &#39;copy_x&#39;: True,
 &#39;init&#39;: &#39;k-means++&#39;,
 &#39;max_iter&#39;: 300,
 &#39;n_clusters&#39;: 3,
 &#39;n_init&#39;: 10,
 &#39;n_jobs&#39;: None,
 &#39;precompute_distances&#39;: &#39;auto&#39;,
 &#39;random_state&#39;: 0,
 &#39;tol&#39;: 0.0001,
 &#39;verbose&#39;: 0}
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># Predict the output</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">prediction</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code>array([1, 0, 0, ..., 0, 0, 2], dtype=int32)
</code></pre></div>
</td></tr></table>
<h2 id="dimension-reduction">Dimension Reduction<a class="headerlink" href="#dimension-reduction" title="Permanent link">&para;</a></h2>
<h3 id="principal-component-analysis">Principal Component Analysis<a class="headerlink" href="#principal-component-analysis" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="c1"># Import the Libraries</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">data</span><span class="p">[</span><span class="s1">&#39;sex&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code><span class="mf">0</span>    <span class="n">Male</span>
<span class="mf">1</span>    <span class="n">Male</span>
<span class="mf">2</span>    <span class="n">Male</span>
<span class="n">Name</span><span class="p">:</span> <span class="n">sex</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="n">object</span>
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># % Male</span>
<span class="nb">sum</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;sex&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;Male&#39;</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code><span class="mf">0.6692054912318418</span>
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># Convert the string labels to numeric labels</span>
<span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;race&#39;</span><span class="p">,</span> <span class="s1">&#39;occupation&#39;</span><span class="p">,</span> <span class="s1">&#39;sex&#39;</span><span class="p">]:</span>
    <span class="n">data</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">label</span><span class="p">])</span>
<span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</code></pre></div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>workclass</th>
      <th>final_weight</th>
      <th>education</th>
      <th>education_num</th>
      <th>marital_status</th>
      <th>occupation</th>
      <th>relationship</th>
      <th>race</th>
      <th>sex</th>
      <th>capital_gain</th>
      <th>capital_loss</th>
      <th>hours_per_week</th>
      <th>native_country</th>
      <th>salary</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>39</td>
      <td>State-gov</td>
      <td>77516</td>
      <td>Bachelors</td>
      <td>13</td>
      <td>Never-married</td>
      <td>1</td>
      <td>Not-in-family</td>
      <td>4</td>
      <td>1</td>
      <td>2174</td>
      <td>0</td>
      <td>40</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>1</th>
      <td>50</td>
      <td>Self-emp-not-inc</td>
      <td>83311</td>
      <td>Bachelors</td>
      <td>13</td>
      <td>Married-civ-spouse</td>
      <td>4</td>
      <td>Husband</td>
      <td>4</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>13</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>2</th>
      <td>38</td>
      <td>Private</td>
      <td>215646</td>
      <td>HS-grad</td>
      <td>9</td>
      <td>Divorced</td>
      <td>6</td>
      <td>Not-in-family</td>
      <td>4</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>40</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
  </tbody>
</table>
</div>
<div class="highlight"><pre><span></span><code><span class="c1"># Take the fields of interest and</span>
<span class="c1"># plug them into variable X</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="p">[[</span><span class="s1">&#39;age&#39;</span><span class="p">,</span> <span class="s1">&#39;final_weight&#39;</span><span class="p">,</span> <span class="s1">&#39;education_num&#39;</span><span class="p">,</span> <span class="s1">&#39;occupation&#39;</span><span class="p">,</span> <span class="s1">&#39;race&#39;</span><span class="p">,</span> <span class="s1">&#39;capital_gain&#39;</span><span class="p">,</span> <span class="s1">&#39;hours_per_week&#39;</span><span class="p">]]</span>

<span class="c1"># Instantiate the PCA model</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span> <span class="c1"># default value of k = min(n_sample, n_features)</span>

<span class="c1"># For factor analysis</span>
<span class="c1">#fa = decomposition.FactorAnalysis()</span>

<span class="c1"># Transform the data</span>
<span class="n">reduced_data_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Inspect the shape</span>
<span class="n">reduced_data_pca</span><span class="o">.</span><span class="n">shape</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code>(32561, 2)
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># Print the transformed data</span>
<span class="n">reduced_data_pca</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code>array([[-112262.33316765,    1099.76011639],
       [-106467.39923916,   -1074.41772634],
       [  25867.60075685,   -1078.43450794]])
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># Plot the results</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">reduced_data_pca</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">reduced_data_pca</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;First Principal Component&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Second Principal Component&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;PCA Scatter Plot&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
<p><img alt="" src="../img/overview_of_scikit/output_100_0.png" /></p>
<div class="highlight"><pre><span></span><code><span class="n">male</span> <span class="o">=</span> <span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;sex&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span>
<span class="nb">type</span><span class="p">(</span><span class="n">male</span><span class="p">)</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code>list
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="c1"># Is Male?</span>
<span class="n">male</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code><span class="mf">0</span>    <span class="n">True</span>
<span class="mf">1</span>    <span class="n">True</span>
<span class="mf">2</span>    <span class="n">True</span>
<span class="n">Name</span><span class="p">:</span> <span class="n">sex</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="n">bool</span>
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="n">female</span> <span class="o">=</span> <span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;sex&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span>

<span class="c1"># Is Female?</span>
<span class="n">female</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code><span class="mf">0</span>    <span class="n">False</span>
<span class="mf">1</span>    <span class="n">False</span>
<span class="mf">2</span>    <span class="n">False</span>
<span class="n">Name</span><span class="p">:</span> <span class="n">sex</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="n">bool</span>
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> 
          <span class="s1">&#39;red&#39;</span><span class="p">]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">colors</span><span class="p">)):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
</code></pre></div>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span></pre></div></td><td class="code"><div class="codehilite"><pre><span></span><code><span class="mf">0</span>
<span class="mf">1</span>
</code></pre></div>
</td></tr></table>
<div class="highlight"><pre><span></span><code><span class="n">data</span><span class="o">.</span><span class="n">sex</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">sex</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</code></pre></div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>workclass</th>
      <th>final_weight</th>
      <th>education</th>
      <th>education_num</th>
      <th>marital_status</th>
      <th>occupation</th>
      <th>relationship</th>
      <th>race</th>
      <th>sex</th>
      <th>capital_gain</th>
      <th>capital_loss</th>
      <th>hours_per_week</th>
      <th>native_country</th>
      <th>salary</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>39</td>
      <td>State-gov</td>
      <td>77516</td>
      <td>Bachelors</td>
      <td>13</td>
      <td>Never-married</td>
      <td>1</td>
      <td>Not-in-family</td>
      <td>4</td>
      <td>1</td>
      <td>2174</td>
      <td>0</td>
      <td>40</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>1</th>
      <td>50</td>
      <td>Self-emp-not-inc</td>
      <td>83311</td>
      <td>Bachelors</td>
      <td>13</td>
      <td>Married-civ-spouse</td>
      <td>4</td>
      <td>Husband</td>
      <td>4</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>13</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>2</th>
      <td>38</td>
      <td>Private</td>
      <td>215646</td>
      <td>HS-grad</td>
      <td>9</td>
      <td>Divorced</td>
      <td>6</td>
      <td>Not-in-family</td>
      <td>4</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>40</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
  </tbody>
</table>
</div>

<div class="highlight"><pre><span></span><code><span class="c1"># 0 Female, blue</span>
<span class="c1"># 1 Male, red</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">colors</span><span class="p">)):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">reduced_data_pca</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;sex&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">i</span><span class="p">]</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">reduced_data_pca</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;sex&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">i</span><span class="p">]</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span> 

<span class="c1"># 0 Female, 1 Male</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Female&#39;</span><span class="p">,</span><span class="s1">&#39;Male&#39;</span><span class="p">],</span> 
           <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">1.05</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> 
           <span class="n">loc</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
           <span class="n">borderaxespad</span><span class="o">=</span><span class="mf">0.</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;First Principal Component&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Second Principal Component&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;PCA Scatter Plot&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div>
<p><img alt="" src="../img/overview_of_scikit/output_106_0.png" /></p>
                
              
              
                


              
            </article>
          </div>
        </div>
        
      </main>
      
        
<footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="Footer">
      
        
        <a href="../intro_to_data_world_in_python/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Introduction to data.world" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              Introduction to data.world
            </div>
          </div>
        </a>
      
      
        
        <a href="../python_and_excel/" class="md-footer__link md-footer__link--next" aria-label="Next: Python and Excel" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              Python and Excel
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        
          Made with
          <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
            Material for MkDocs
          </a>
        
        
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "..", "features": [], "translations": {"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "search": "../assets/javascripts/workers/search.f8263e09.min.js", "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.4fc53ad4.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
  </body>
</html>