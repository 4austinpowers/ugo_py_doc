



<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
        <meta name="description" content="A Python documentation website.">
      
      
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="en">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="../img/favicon.ico">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-3.2.0">
    
    
      
        <title>Overview of scikit-learn - ugo_py_doc</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/application.572ca0f0.css">
      
        <link rel="stylesheet" href="../assets/stylesheets/application-palette.22915126.css">
      
      
        
        
        <meta name="theme-color" content="#ffa000">
      
    
    
      <script src="../assets/javascripts/modernizr.8c900955.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../assets/fonts/material-icons.css">
    
    
      <link rel="stylesheet" href="../extra.css">
    
    
  </head>
  
    
    
    <body dir="ltr" data-md-color-primary="amber" data-md-color-accent="indigo">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448"
    viewBox="0 0 416 448" id="__github">
  <path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19-18.125
        8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19 18.125-8.5
        18.125 8.5 10.75 19 3.125 20.5zM320 304q0 10-3.125 20.5t-10.75
        19-18.125 8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19
        18.125-8.5 18.125 8.5 10.75 19 3.125 20.5zM360
        304q0-30-17.25-51t-46.75-21q-10.25 0-48.75 5.25-17.75 2.75-39.25
        2.75t-39.25-2.75q-38-5.25-48.75-5.25-29.5 0-46.75 21t-17.25 51q0 22 8
        38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0
        37.25-1.75t35-7.375 30.5-15 20.25-25.75 8-38.375zM416 260q0 51.75-15.25
        82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5-41.75
        1.125q-19.5 0-35.5-0.75t-36.875-3.125-38.125-7.5-34.25-12.875-30.25-20.25-21.5-28.75q-15.5-30.75-15.5-82.75
        0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25
        30.875q36.75-8.75 77.25-8.75 37 0 70 8 26.25-20.5
        46.75-30.25t47.25-9.75q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34
        99.5z" />
</svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#three-types-of-machine-learning-algorithms" tabindex="1" class="md-skip">
        Skip to content
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href=".." title="ugo_py_doc" class="md-header-nav__button md-logo">
          
            <i class="md-icon">layers</i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            
              <span class="md-header-nav__topic">
                ugo_py_doc
              </span>
              <span class="md-header-nav__topic">
                Overview of scikit-learn
              </span>
            
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          
            <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
            
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
          
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  


  <a href="https://github.com/ugoproto/ugo_py_doc.git/" title="Go to repository" class="md-source" data-md-source="github">
    
      <div class="md-source__icon">
        <svg viewBox="0 0 24 24" width="24" height="24">
          <use xlink:href="#__github" width="24" height="24"></use>
        </svg>
      </div>
    
    <div class="md-source__repository">
      ugo_py_doc
    </div>
  </a>

          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href=".." title="ugo_py_doc" class="md-nav__button md-logo">
      
        <i class="md-icon">layers</i>
      
    </a>
    ugo_py_doc
  </label>
  
    <div class="md-nav__source">
      


  


  <a href="https://github.com/ugoproto/ugo_py_doc.git/" title="Go to repository" class="md-source" data-md-source="github">
    
      <div class="md-source__icon">
        <svg viewBox="0 0 24 24" width="24" height="24">
          <use xlink:href="#__github" width="24" height="24"></use>
        </svg>
      </div>
    
    <div class="md-source__repository">
      ugo_py_doc
    </div>
  </a>

    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href=".." title="Home" class="md-nav__link">
      Home
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2">
    
    <label class="md-nav__link" for="nav-2">
      Basics
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        Basics
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../py_cs/" title="Python Cheat Sheets" class="md-nav__link">
      Python Cheat Sheets
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../databases/" title="Databases" class="md-nav__link">
      Databases
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../datetime/" title="Datetime" class="md-nav__link">
      Datetime
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../decorators/" title="Decorators" class="md-nav__link">
      Decorators
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../exceptions/" title="Exceptions" class="md-nav__link">
      Exceptions
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../freeze_the_code/" title="Freeze the Code" class="md-nav__link">
      Freeze the Code
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../gedit_execute_highlighted_python_code/" title="Gedit, Execute Highlighted Code" class="md-nav__link">
      Gedit, Execute Highlighted Code
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../python_nice_to_have/" title="Python Nice to Have" class="md-nav__link">
      Python Nice to Have
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3" checked>
    
    <label class="md-nav__link" for="nav-3">
      Scipy Stack
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        Scipy Stack
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../jn_cs/" title="Jupyter Notebook Cheat Sheets" class="md-nav__link">
      Jupyter Notebook Cheat Sheets
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../scipy_cs/" title="Scipy Stack Cheat Sheets" class="md-nav__link">
      Scipy Stack Cheat Sheets
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../eda_machine_learning_feature_engineering_and_kaggle/" title="EDA, Machine Learning, Feature Engineering, and Kaggle" class="md-nav__link">
      EDA, Machine Learning, Feature Engineering, and Kaggle
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../exploratory_data_analysis/" title="Exploratory Data Analysis (EDA)" class="md-nav__link">
      Exploratory Data Analysis (EDA)
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../feature_selection_in_python/" title="Feature Selection" class="md-nav__link">
      Feature Selection
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../geospatial_data_in_python/" title="Geospatial Data" class="md-nav__link">
      Geospatial Data
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../importing_data_into_python/" title="Importing Data" class="md-nav__link">
      Importing Data
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../introduction_to_customer_segmentation_in_python/" title="Introduction to Customer Segmentation" class="md-nav__link">
      Introduction to Customer Segmentation
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../intro_to_data_world_in_python/" title="Introduction to data.world" class="md-nav__link">
      Introduction to data.world
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        Overview of scikit-learn
      </label>
    
    <a href="./" title="Overview of scikit-learn" class="md-nav__link md-nav__link--active">
      Overview of scikit-learn
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#three-types-of-machine-learning-algorithms" title="Three types of Machine Learning Algorithms" class="md-nav__link">
    Three types of Machine Learning Algorithms
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#supervised-learning" title="Supervised Learning" class="md-nav__link">
    Supervised Learning
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#unsupervised-learning" title="Unsupervised Learning" class="md-nav__link">
    Unsupervised Learning
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reinforcement-learning" title="Reinforcement Learning" class="md-nav__link">
    Reinforcement Learning
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-scikit-learn-module" title="The scikit-learn Module" class="md-nav__link">
    The scikit-learn Module
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#basic-supervised-learning" title="Basic Supervised Learning" class="md-nav__link">
    Basic Supervised Learning
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#with-a-hard-coded-dataset" title="With a Hard-Coded Dataset" class="md-nav__link">
    With a Hard-Coded Dataset
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#linear-regression" title="Linear Regression" class="md-nav__link">
    Linear Regression
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#r-code" title="R Code" class="md-nav__link">
    R Code
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#python-code" title="Python Code" class="md-nav__link">
    Python Code
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#linear-regression-with-statsmodels" title="Linear Regression with StatsModels" class="md-nav__link">
    Linear Regression with StatsModels
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#logistic-regression" title="Logistic Regression" class="md-nav__link">
    Logistic Regression
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-r-code" title="The R code" class="md-nav__link">
    The R code
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-python-code" title="The Python Code" class="md-nav__link">
    The Python Code
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision-tree" title="Decision tree" class="md-nav__link">
    Decision tree
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-r-code_1" title="The R Code" class="md-nav__link">
    The R Code
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-python-code_1" title="The Python Code" class="md-nav__link">
    The Python Code
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#random-forests" title="Random Forests" class="md-nav__link">
    Random Forests
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-r-code_2" title="The R Code" class="md-nav__link">
    The R Code
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-python-code_2" title="The Python Code" class="md-nav__link">
    The Python Code
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#k-nearest-neighbours" title="k-Nearest Neighbours" class="md-nav__link">
    k-Nearest Neighbours
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-r-code_3" title="The R Code" class="md-nav__link">
    The R Code
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rescaling" title="Rescaling" class="md-nav__link">
    Rescaling
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-python-code_3" title="The Python Code" class="md-nav__link">
    The Python Code
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#naive-bayes" title="Naïve Bayes" class="md-nav__link">
    Naïve Bayes
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-r-code_4" title="The R Code" class="md-nav__link">
    The R Code
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-python-code_4" title="The Python Code" class="md-nav__link">
    The Python Code
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#support-vector-machine" title="Support Vector Machine" class="md-nav__link">
    Support Vector Machine
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-r-code_5" title="The R Code" class="md-nav__link">
    The R Code
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-python-code_5" title="The Python Code" class="md-nav__link">
    The Python Code
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#split-a-dataset" title="Split a dataset" class="md-nav__link">
    Split a dataset
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#intermediate-supervised-learning" title="Intermediate Supervised Learning" class="md-nav__link">
    Intermediate Supervised Learning
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#logistic-regression_1" title="Logistic regression" class="md-nav__link">
    Logistic regression
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision-tree_1" title="Decision tree" class="md-nav__link">
    Decision tree
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#random-forests_1" title="Random Forests" class="md-nav__link">
    Random Forests
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#k-nearest-neighbours_1" title="k-Nearest Neighbours" class="md-nav__link">
    k-Nearest Neighbours
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#naive-bayes_1" title="Naïve Bayes" class="md-nav__link">
    Naïve Bayes
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#support-vector-machine_1" title="Support Vector Machine" class="md-nav__link">
    Support Vector Machine
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#unsupervised-learning_1" title="Unsupervised Learning" class="md-nav__link">
    Unsupervised Learning
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#k-means" title="k-Means" class="md-nav__link">
    k-Means
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-r-code_6" title="The R Code" class="md-nav__link">
    The R Code
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-python-code_6" title="The Python Code" class="md-nav__link">
    The Python Code
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dimension-reduction" title="Dimension Reduction" class="md-nav__link">
    Dimension Reduction
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#principal-component-analysis" title="Principal Component Analysis" class="md-nav__link">
    Principal Component Analysis
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../python_and_excel/" title="Python and Excel" class="md-nav__link">
      Python and Excel
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../scaling_centering_noise_with_knn_linear_regression_logit/" title="Scaling, Centering, Noise with kNN, Linear Regression, Logit" class="md-nav__link">
      Scaling, Centering, Noise with kNN, Linear Regression, Logit
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../sentiment_analysis_with_twitter/" title="Sentiment Analysis with Twitter" class="md-nav__link">
      Sentiment Analysis with Twitter
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../time_series_analysis/" title="Time Series Analysis" class="md-nav__link">
      Time Series Analysis
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../vectors_and_arrays_linear_algebra/" title="Vectors and Arrays (Linear Algebra)" class="md-nav__link">
      Vectors and Arrays (Linear Algebra)
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../viewing_3d_volumetric_data_with_matplotlib/" title="Viewing 3D Volumetric Data with Matplotlib" class="md-nav__link">
      Viewing 3D Volumetric Data with Matplotlib
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../write_idiomatic_pandas_code/" title="Write Idiomatic Pandas Code" class="md-nav__link">
      Write Idiomatic Pandas Code
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-4" type="checkbox" id="nav-4">
    
    <label class="md-nav__link" for="nav-4">
      Courses
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-4">
        Courses
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../apprenez_a_programmer_en_python/" title="Apprenez à programmer en Python" class="md-nav__link">
      Apprenez à programmer en Python
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../automate_the_boring_stuff_with_python/" title="Automate the Boring Stuff with Python" class="md-nav__link">
      Automate the Boring Stuff with Python
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../codecademy_python/" title="Codecademy Python" class="md-nav__link">
      Codecademy Python
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../learn_python_the_hard_way/" title="Learn Python the Hard Way" class="md-nav__link">
      Learn Python the Hard Way
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../lpthw_python_code_snippets/" title="LPTHW, Python Code Snippets" class="md-nav__link">
      LPTHW, Python Code Snippets
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5" type="checkbox" id="nav-5">
    
    <label class="md-nav__link" for="nav-5">
      Manuals
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-5">
        Manuals
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../managing_your_biological_data_with_python/" title="Managing Your Biological Data with Python" class="md-nav__link">
      Managing Your Biological Data with Python
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../python_for_education/" title="Python for Education" class="md-nav__link">
      Python for Education
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#three-types-of-machine-learning-algorithms" title="Three types of Machine Learning Algorithms" class="md-nav__link">
    Three types of Machine Learning Algorithms
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#supervised-learning" title="Supervised Learning" class="md-nav__link">
    Supervised Learning
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#unsupervised-learning" title="Unsupervised Learning" class="md-nav__link">
    Unsupervised Learning
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reinforcement-learning" title="Reinforcement Learning" class="md-nav__link">
    Reinforcement Learning
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-scikit-learn-module" title="The scikit-learn Module" class="md-nav__link">
    The scikit-learn Module
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#basic-supervised-learning" title="Basic Supervised Learning" class="md-nav__link">
    Basic Supervised Learning
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#with-a-hard-coded-dataset" title="With a Hard-Coded Dataset" class="md-nav__link">
    With a Hard-Coded Dataset
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#linear-regression" title="Linear Regression" class="md-nav__link">
    Linear Regression
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#r-code" title="R Code" class="md-nav__link">
    R Code
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#python-code" title="Python Code" class="md-nav__link">
    Python Code
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#linear-regression-with-statsmodels" title="Linear Regression with StatsModels" class="md-nav__link">
    Linear Regression with StatsModels
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#logistic-regression" title="Logistic Regression" class="md-nav__link">
    Logistic Regression
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-r-code" title="The R code" class="md-nav__link">
    The R code
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-python-code" title="The Python Code" class="md-nav__link">
    The Python Code
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision-tree" title="Decision tree" class="md-nav__link">
    Decision tree
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-r-code_1" title="The R Code" class="md-nav__link">
    The R Code
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-python-code_1" title="The Python Code" class="md-nav__link">
    The Python Code
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#random-forests" title="Random Forests" class="md-nav__link">
    Random Forests
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-r-code_2" title="The R Code" class="md-nav__link">
    The R Code
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-python-code_2" title="The Python Code" class="md-nav__link">
    The Python Code
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#k-nearest-neighbours" title="k-Nearest Neighbours" class="md-nav__link">
    k-Nearest Neighbours
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-r-code_3" title="The R Code" class="md-nav__link">
    The R Code
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rescaling" title="Rescaling" class="md-nav__link">
    Rescaling
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-python-code_3" title="The Python Code" class="md-nav__link">
    The Python Code
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#naive-bayes" title="Naïve Bayes" class="md-nav__link">
    Naïve Bayes
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-r-code_4" title="The R Code" class="md-nav__link">
    The R Code
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-python-code_4" title="The Python Code" class="md-nav__link">
    The Python Code
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#support-vector-machine" title="Support Vector Machine" class="md-nav__link">
    Support Vector Machine
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-r-code_5" title="The R Code" class="md-nav__link">
    The R Code
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-python-code_5" title="The Python Code" class="md-nav__link">
    The Python Code
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#split-a-dataset" title="Split a dataset" class="md-nav__link">
    Split a dataset
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#intermediate-supervised-learning" title="Intermediate Supervised Learning" class="md-nav__link">
    Intermediate Supervised Learning
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#logistic-regression_1" title="Logistic regression" class="md-nav__link">
    Logistic regression
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision-tree_1" title="Decision tree" class="md-nav__link">
    Decision tree
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#random-forests_1" title="Random Forests" class="md-nav__link">
    Random Forests
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#k-nearest-neighbours_1" title="k-Nearest Neighbours" class="md-nav__link">
    k-Nearest Neighbours
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#naive-bayes_1" title="Naïve Bayes" class="md-nav__link">
    Naïve Bayes
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#support-vector-machine_1" title="Support Vector Machine" class="md-nav__link">
    Support Vector Machine
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#unsupervised-learning_1" title="Unsupervised Learning" class="md-nav__link">
    Unsupervised Learning
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#k-means" title="k-Means" class="md-nav__link">
    k-Means
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-r-code_6" title="The R Code" class="md-nav__link">
    The R Code
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-python-code_6" title="The Python Code" class="md-nav__link">
    The Python Code
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dimension-reduction" title="Dimension Reduction" class="md-nav__link">
    Dimension Reduction
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#principal-component-analysis" title="Principal Component Analysis" class="md-nav__link">
    Principal Component Analysis
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/ugoproto/ugo_py_doc.git/edit/master/docs/overview_of_scikit_learn.md" title="Edit this page" class="md-icon md-content__icon">&#xE3C9;</a>
                
                
                  <h1>Overview of scikit-learn</h1>
                
                <h2 id="three-types-of-machine-learning-algorithms">Three types of Machine Learning Algorithms<a class="headerlink" href="#three-types-of-machine-learning-algorithms" title="Permanent link">&para;</a></h2>
<h3 id="supervised-learning">Supervised Learning<a class="headerlink" href="#supervised-learning" title="Permanent link">&para;</a></h3>
<p>The algorithm consist of a target/outcome variable (or dependent variable) which is to be predicted from a given set of predictors (independent variables). Using these set of variables, we generate a function that map inputs to desired outputs. The training process continues until the model achieves a desired level of accuracy on the training data.</p>
<p>Examples of Supervised Learning: Regression, Decision Tree, Random Forest, kNN, Logistic Regression, etc.</p>
<h3 id="unsupervised-learning">Unsupervised Learning<a class="headerlink" href="#unsupervised-learning" title="Permanent link">&para;</a></h3>
<p>In this algorithm, we do not have any target or outcome variable to predict/estimate. It is used for clustering population in different groups, which is widely used for segmenting customers in different groups for specific intervention.</p>
<p>Examples of Unsupervised Learning: Apriori, k-means.</p>
<h3 id="reinforcement-learning">Reinforcement Learning<a class="headerlink" href="#reinforcement-learning" title="Permanent link">&para;</a></h3>
<p>Using this algorithm, the machine is trained to make specific decisions. It works this way: the machine is exposed to an environment where it trains itself continually using trial and error. This machine learns from past experience and tries to capture the best possible knowledge to make accurate business decisions.</p>
<p>Example of Reinforcement Learning: Markov Decision Process.</p>
<h2 id="the-scikit-learn-module">The scikit-learn Module<a class="headerlink" href="#the-scikit-learn-module" title="Permanent link">&para;</a></h2>
<p><img alt="" src="../img/overview_of_scikit/scikit-learn.png" /></p>
<h2 id="basic-supervised-learning">Basic Supervised Learning<a class="headerlink" href="#basic-supervised-learning" title="Permanent link">&para;</a></h2>
<h3 id="with-a-hard-coded-dataset">With a Hard-Coded Dataset<a class="headerlink" href="#with-a-hard-coded-dataset" title="Permanent link">&para;</a></h3>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># [height, weight, shoe_size]</span>
<span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">181</span><span class="p">,</span> <span class="mi">80</span><span class="p">,</span> <span class="mi">44</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">177</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="mi">43</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">160</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">38</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">154</span><span class="p">,</span> <span class="mi">54</span><span class="p">,</span> <span class="mi">37</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">166</span><span class="p">,</span> <span class="mi">65</span><span class="p">,</span> <span class="mi">40</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">190</span><span class="p">,</span> <span class="mi">90</span><span class="p">,</span> <span class="mi">47</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">175</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">39</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">177</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="mi">40</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">159</span><span class="p">,</span> <span class="mi">55</span><span class="p">,</span> <span class="mi">37</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">171</span><span class="p">,</span> <span class="mi">75</span><span class="p">,</span> <span class="mi">42</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">181</span><span class="p">,</span> <span class="mi">85</span><span class="p">,</span> <span class="mi">43</span><span class="p">]]</span>

<span class="n">Y</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;male&#39;</span><span class="p">,</span> <span class="s1">&#39;male&#39;</span><span class="p">,</span> <span class="s1">&#39;female&#39;</span><span class="p">,</span> <span class="s1">&#39;female&#39;</span><span class="p">,</span> <span class="s1">&#39;male&#39;</span><span class="p">,</span> <span class="s1">&#39;male&#39;</span><span class="p">,</span> <span class="s1">&#39;female&#39;</span><span class="p">,</span> <span class="s1">&#39;female&#39;</span><span class="p">,</span> <span class="s1">&#39;female&#39;</span><span class="p">,</span> <span class="s1">&#39;male&#39;</span><span class="p">,</span> <span class="s1">&#39;male&#39;</span><span class="p">]</span>

<span class="c1"># Convert the strings into booleans</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">Y</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="s1">&#39;male&#39;</span><span class="p">:</span>
        <span class="n">y_train</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">y_train</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">y_train</span>
</pre></div>
</td></tr></table>

<h3 id="linear-regression">Linear Regression<a class="headerlink" href="#linear-regression" title="Permanent link">&para;</a></h3>
<p>We establish a relationship between independent and dependent variables by fitting the best line. This best fit line is known as the regression line: <span><span class="MathJax_Preview">Y = \alpha X + \beta</span><script type="math/tex">Y = \alpha X + \beta</script></span>.</p>
<p>There are different steps to improve the model:</p>
<ul>
<li>Using Multiple Linear regressions;</li>
<li>Including interaction terms;</li>
<li>Removing features;</li>
<li>Regularization techniques;</li>
<li>Using a non-linear model (polynomial and other curvilinear regressions).</li>
</ul>
<p>The code examples below are illustrations of the process. To handle a binary dependent variable (Y), we would rather work with classification models (including logistic regressions).</p>
<h4 id="r-code">R Code<a class="headerlink" href="#r-code" title="Permanent link">&para;</a></h4>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Load train and test datasets</span>
<span class="c1"># Identify the feature and response variable(s)</span>
<span class="c1"># Values must be numeric and numpy arrays</span>
<span class="n">x_train</span> <span class="o">&lt;-</span> <span class="n">input_variables_values_training_datasets</span>
<span class="n">y_train</span> <span class="o">&lt;-</span> <span class="n">target_variables_values_training_datasets</span>
<span class="n">x_test</span> <span class="o">&lt;-</span> <span class="n">input_variables_values_test_datasets</span>
<span class="n">x</span> <span class="o">&lt;-</span> <span class="nf">cbind</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Train the model using the training sets and</span>
<span class="c1"># Check the score</span>
<span class="n">linear</span> <span class="o">&lt;-</span> <span class="nf">lm</span><span class="p">(</span><span class="n">y_train</span> <span class="o">~</span> <span class="n">.,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">)</span>
<span class="nf">summary</span><span class="p">(</span><span class="n">linear</span><span class="p">)</span>

<span class="c1"># Predict the output</span>
<span class="n">predicted</span> <span class="o">&lt;-</span> <span class="nf">predict</span><span class="p">(</span><span class="n">linear</span><span class="p">,</span> <span class="n">x_test</span><span class="p">)</span> 
</pre></div>
</td></tr></table>

<h4 id="python-code">Python Code<a class="headerlink" href="#python-code" title="Permanent link">&para;</a></h4>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Import the libraries</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">linear_model</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="c1"># Load the Train and Test Datasets</span>
<span class="c1"># Identify feature and response variable(s) and</span>
<span class="c1"># Values must be numeric and numpy arrays</span>
<span class="c1">#x_train = input_variables_values_training_datasets</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">X</span>
<span class="c1">#y_train = target_variables_values_training_datasets</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span>
<span class="c1">#x_test = input_variables_values_test_datasets</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">190</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="mi">43</span><span class="p">],</span> <span class="p">[</span><span class="mi">160</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">38</span><span class="p">]]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="c1"># y_true</span>

<span class="c1"># Create the linear regression object</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">LinearRegression</span><span class="p">()</span>

<span class="c1"># Train the model</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,
         normalize=False)
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Compute accuracy</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>0.7754597107685945
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Equation intercept and coefficient</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Intercept (alpha): </span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Coefficient (betas): </span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>Intercept (alpha): 
 -2.5061026710063232
Coefficient (betas): 
 [-0.03917782  0.00991846  0.22230002]
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Predict the output</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="n">y_pred</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>array([0.30330465, 0.26795454])
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Compute accuracy</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>-0.11436808286011502
</pre></div>
</td></tr></table>

<h3 id="linear-regression-with-statsmodels">Linear Regression with StatsModels<a class="headerlink" href="#linear-regression-with-statsmodels" title="Permanent link">&para;</a></h3>
<p><a href="http://www.statsmodels.org/stable/index.html">For more</a>.</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Import the library</span>
<span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="kn">as</span> <span class="nn">sm</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>

<span class="c1"># Load the Train and Test Datasets</span>
<span class="c1"># Identify feature and response variable(s) and</span>
<span class="c1"># Values must be numeric and numpy arrays</span>
<span class="c1">#x_train = input_variables_values_training_datasets</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">X</span>
<span class="c1">#y_train = target_variables_values_training_datasets</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span>
<span class="c1">#x_test = input_variables_values_test_datasets</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">190</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="mi">43</span><span class="p">],</span> <span class="p">[</span><span class="mi">160</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">38</span><span class="p">]]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="c1"># y_true</span>

<span class="c1"># Create a DataFrame</span>
<span class="n">df1</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;height&#39;</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">,</span> <span class="s1">&#39;shoe_size&#39;</span><span class="p">])</span>
<span class="n">df2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;gender&#39;</span><span class="p">])</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df1</span><span class="p">,</span> <span class="n">df2</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>height</th>
      <th>weight</th>
      <th>shoe_size</th>
      <th>gender</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>181</td>
      <td>80</td>
      <td>44</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>177</td>
      <td>70</td>
      <td>43</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>160</td>
      <td>60</td>
      <td>38</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3
4
5
6</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># State the OLS model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">formula</span> <span class="o">=</span> <span class="s1">&#39;gender ~ height + weight + shoe_size&#39;</span><span class="p">,</span>
               <span class="n">data</span> <span class="o">=</span> <span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="c1"># Print the coefficients</span>
<span class="n">model</span><span class="o">.</span><span class="n">params</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>Intercept   -2.506103
height      -0.039178
weight       0.009918
shoe_size    0.222300
dtype: float64
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Print the stats</span>
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="o">/</span><span class="nt">home</span><span class="o">/</span><span class="nt">ugo</span><span class="o">/</span><span class="nt">miniconda3</span><span class="o">/</span><span class="nt">lib</span><span class="o">/</span><span class="nt">python3</span><span class="p">.</span><span class="nc">6</span><span class="o">/</span><span class="nt">site-packages</span><span class="o">/</span><span class="nt">scipy</span><span class="o">/</span><span class="nt">stats</span><span class="o">/</span><span class="nt">stats</span><span class="p">.</span><span class="nc">py</span><span class="p">:</span><span class="nd">1394</span><span class="o">:</span> <span class="nt">UserWarning</span><span class="o">:</span> <span class="nt">kurtosistest</span> <span class="nt">only</span> <span class="nt">valid</span> <span class="nt">for</span> <span class="nt">n</span><span class="o">&amp;</span><span class="nt">gt</span><span class="o">;=</span><span class="nt">20</span> <span class="o">...</span> <span class="nt">continuing</span> <span class="nt">anyway</span><span class="o">,</span> <span class="nt">n</span><span class="o">=</span><span class="nt">11</span>
  <span class="s2">&quot;anyway, n=%i&quot;</span> <span class="o">%</span> <span class="nt">int</span><span class="o">(</span><span class="nt">n</span><span class="o">))</span>
</pre></div>
</td></tr></table>

<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>         <td>gender</td>      <th>  R-squared:         </th> <td>   0.775</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.679</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   8.058</td>
</tr>
<tr>
  <th>Date:</th>             <td>Wed, 21 Nov 2018</td> <th>  Prob (F-statistic):</th>  <td>0.0113</td> 
</tr>
<tr>
  <th>Time:</th>                 <td>13:16:06</td>     <th>  Log-Likelihood:    </th> <td> 0.27729</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>    11</td>      <th>  AIC:               </th> <td>   7.445</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>     7</td>      <th>  BIC:               </th> <td>   9.037</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   
</tr>
</table>

<table class="simpletable">
<tr>
      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th> <td>   -2.5061</td> <td>    2.924</td> <td>   -0.857</td> <td> 0.420</td> <td>   -9.420</td> <td>    4.407</td>
</tr>
<tr>
  <th>height</th>    <td>   -0.0392</td> <td>    0.022</td> <td>   -1.777</td> <td> 0.119</td> <td>   -0.091</td> <td>    0.013</td>
</tr>
<tr>
  <th>weight</th>    <td>    0.0099</td> <td>    0.028</td> <td>    0.352</td> <td> 0.735</td> <td>   -0.057</td> <td>    0.077</td>
</tr>
<tr>
  <th>shoe_size</th> <td>    0.2223</td> <td>    0.097</td> <td>    2.287</td> <td> 0.056</td> <td>   -0.008</td> <td>    0.452</td>
</tr>
</table>

<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td> 0.165</td> <th>  Durbin-Watson:     </th> <td>   2.858</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.921</td> <th>  Jarque-Bera (JB):  </th> <td>   0.201</td>
</tr>
<tr>
  <th>Skew:</th>          <td> 0.201</td> <th>  Prob(JB):          </th> <td>   0.904</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 2.473</td> <th>  Cond. No.          </th> <td>6.25e+03</td>
</tr>
</table>

<p><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 6.25e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems.</p>
<h3 id="logistic-regression">Logistic Regression<a class="headerlink" href="#logistic-regression" title="Permanent link">&para;</a></h3>
<p>We estimate discrete values (binary values like 0/1, yes/no, true/false). It predicts the probability of occurrence of an event by fitting data to a logit function. Since, it predicts the probability, its output values lies between 0 and 1.</p>
<p>Note: we can work with strings in <code class="codehilite">Y</code>.</p>
<h4 id="the-r-code">The R code<a class="headerlink" href="#the-r-code" title="Permanent link">&para;</a></h4>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Load train and test datasets</span>
<span class="c1"># Identify the feature and response variable(s)</span>
<span class="c1"># Values must be numeric and numpy arrays</span>
<span class="n">x_train</span> <span class="o">&lt;-</span> <span class="n">input_variables_values_training_datasets</span>
<span class="n">y_train</span> <span class="o">&lt;-</span> <span class="n">target_variables_values_training_datasets</span>
<span class="n">x_test</span> <span class="o">&lt;-</span> <span class="n">input_variables_values_test_datasets</span>
<span class="n">x</span> <span class="o">&lt;-</span> <span class="nf">cbind</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Train the model using the training sets and</span>
<span class="c1"># Check the score</span>
<span class="n">logistic</span> <span class="o">&lt;-</span> <span class="nf">glm</span><span class="p">(</span><span class="n">y_train</span> <span class="o">~</span> <span class="n">.,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">family</span><span class="o">=</span><span class="s">&#39;binomial&#39;</span><span class="p">)</span>
<span class="nf">summary</span><span class="p">(</span><span class="n">logistic</span><span class="p">)</span>

<span class="c1"># Predict the output</span>
<span class="n">predicted</span> <span class="o">&lt;-</span> <span class="nf">predict</span><span class="p">(</span><span class="n">logistic</span><span class="p">,</span> <span class="n">x_test</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<h4 id="the-python-code">The Python Code<a class="headerlink" href="#the-python-code" title="Permanent link">&para;</a></h4>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Import the libraries</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="c1"># Load the Train and Test Datasets</span>
<span class="c1"># Identify feature and response variable(s) and</span>
<span class="c1"># Values must be numeric and numpy arrays</span>
<span class="c1">#x_train = input_variables_values_training_datasets</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">X</span>
<span class="c1">#y_train = target_variables_values_training_datasets</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span>
<span class="c1">#x_test = input_variables_values_test_datasets</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">190</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="mi">43</span><span class="p">],</span> <span class="p">[</span><span class="mi">160</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">38</span><span class="p">]]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="c1"># y_true</span>

<span class="c1"># Assume we have, X (predictor) and Y (target) for</span>
<span class="c1"># training data set and x_test(predictor) of</span>
<span class="c1"># test_dataset</span>
<span class="c1"># Create the logistic regression object</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">C</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
                           <span class="n">class_weight</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
                           <span class="n">dual</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
                           <span class="n">fit_intercept</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span>
                           <span class="n">intercept_scaling</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> 
                           <span class="n">max_iter</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> 
                           <span class="n">multi_class</span> <span class="o">=</span> <span class="s1">&#39;ovr&#39;</span><span class="p">,</span>
                           <span class="n">n_jobs</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
                           <span class="n">penalty</span> <span class="o">=</span> <span class="s1">&#39;l2&#39;</span><span class="p">,</span>
                           <span class="n">random_state</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
                           <span class="n">solver</span> <span class="o">=</span> <span class="s1">&#39;liblinear&#39;</span><span class="p">,</span>
                           <span class="n">tol</span> <span class="o">=</span> <span class="mf">0.0001</span><span class="p">,</span>
                           <span class="n">verbose</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> 
                           <span class="n">warm_start</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>

<span class="c1"># Train the model</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
          intercept_scaling=1, max_iter=100, multi_class=&#39;ovr&#39;, n_jobs=1,
          penalty=&#39;l2&#39;, random_state=None, solver=&#39;liblinear&#39;, tol=0.0001,
          verbose=0, warm_start=False)
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Compute accuracy</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>1.0
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Equation intercept and coefficient</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Coefficient: </span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Intercept: </span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>Coefficient: 
 [[-0.43920419  0.62276186  0.8290359 ]]
Intercept: 
 [-0.00585817]
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Predict the output</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="n">y_pred</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>array([0, 0])
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Compute accuracy</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>0.5
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Print the metrics</span>
<span class="k">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">[[1 0]</span>
 <span class="k">[1 0]]</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>              precision    recall  f1-score   support

           0       0.50      1.00      0.67         1
           1       0.00      0.00      0.00         1

   micro avg       0.50      0.50      0.50         2
   macro avg       0.25      0.50      0.33         2
weighted avg       0.25      0.50      0.33         2



/home/ugo/miniconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  &#39;precision&#39;, &#39;predicted&#39;, average, warn_for)
</pre></div>
</td></tr></table>

<h3 id="decision-tree">Decision tree<a class="headerlink" href="#decision-tree" title="Permanent link">&para;</a></h3>
<p>It is a type of supervised learning algorithm that is mostly used for classification problems. Surprisingly, it works for both categorical and continuous dependent variables. In this algorithm, we split the population into two or more homogeneous sets. This is done based on most significant attributes/independent variables to make as distinct groups as possible.</p>
<p><a href="https://www.analyticsvidhya.com/blog/2016/04/complete-tutorial-tree-based-modeling-scratch-in-python/">Decision Tree Simplified</a>.</p>
<p>Note: we can work with strings in <code class="codehilite">Y</code>.</p>
<h4 id="the-r-code_1">The R Code<a class="headerlink" href="#the-r-code_1" title="Permanent link">&para;</a></h4>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="n">rpart</span><span class="p">)</span>

<span class="c1"># Load train and test datasets</span>
<span class="c1"># Identify the feature and response variable(s)</span>
<span class="c1"># Values must be numeric and numpy arrays</span>
<span class="n">x_train</span> <span class="o">&lt;-</span> <span class="n">input_variables_values_training_datasets</span>
<span class="n">y_train</span> <span class="o">&lt;-</span> <span class="n">target_variables_values_training_datasets</span>
<span class="n">x_test</span> <span class="o">&lt;-</span> <span class="n">input_variables_values_test_datasets</span>
<span class="n">x</span> <span class="o">&lt;-</span> <span class="nf">cbind</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Grow the tree </span>
<span class="n">fit</span> <span class="o">&lt;-</span> <span class="nf">rpart</span><span class="p">(</span><span class="n">y_train</span> <span class="o">~</span> <span class="n">.,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span> <span class="s">&quot;class&quot;</span><span class="p">)</span>
<span class="nf">summary</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>

<span class="c1"># Predict the output </span>
<span class="n">predicted</span> <span class="o">&lt;-</span> <span class="nf">predict</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span> <span class="n">x_test</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<h4 id="the-python-code_1">The Python Code<a class="headerlink" href="#the-python-code_1" title="Permanent link">&para;</a></h4>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Import the libraries</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">tree</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="c1"># Load the Train and Test Datasets</span>
<span class="c1"># Identify feature and response variable(s) and</span>
<span class="c1"># Values must be numeric and numpy arrays</span>
<span class="c1">#x_train = input_variables_values_training_datasets</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">X</span>
<span class="c1">#y_train = target_variables_values_training_datasets</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span>
<span class="c1">#x_test = input_variables_values_test_datasets</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">190</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="mi">43</span><span class="p">],</span> <span class="p">[</span><span class="mi">160</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">38</span><span class="p">]]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="c1"># y_true</span>

<span class="c1"># Assumed you have, X (predictor) and Y (target) for</span>
<span class="c1"># training data set and x_test(predictor) of</span>
<span class="c1"># test_dataset</span>
<span class="c1"># Create the tree object </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">criterion</span> <span class="o">=</span> <span class="s1">&#39;gini&#39;</span><span class="p">)</span>

<span class="c1"># For classification, we can change the algorithm</span>
<span class="c1"># as &#39;gini&#39; or &#39;entropy&#39; (information gain)</span>
<span class="c1"># by default it is &#39;gini&#39;</span>

<span class="c1"># For regression</span>
<span class="c1">#model = tree.DecisionTreeRegressor()</span>

<span class="c1"># Train the model</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>DecisionTreeClassifier(class_weight=None, criterion=&#39;gini&#39;, max_depth=None,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter=&#39;best&#39;)
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Compute accuracy</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>1.0
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Predict the output</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="n">y_pred</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>array([1, 0])
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Compute accuracy</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>1.0
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Print the metrics</span>
<span class="k">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">[[1 0]</span>
 <span class="k">[0 1]]</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7
8</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>              precision    recall  f1-score   support

           0       1.00      1.00      1.00         1
           1       1.00      1.00      1.00         1

   micro avg       1.00      1.00      1.00         2
   macro avg       1.00      1.00      1.00         2
weighted avg       1.00      1.00      1.00         2
</pre></div>
</td></tr></table>

<h3 id="random-forests">Random Forests<a class="headerlink" href="#random-forests" title="Permanent link">&para;</a></h3>
<p>Random Forest is a term for an ensemble of decision trees. In Random Forest, we have collection of decision trees (so known as “Forest”). To classify a new object based on attributes, each tree gives a classification and we say the tree “votes” for that class. The forest chooses the classification having the most votes (over all the trees in the forest).</p>
<p>Each tree is planted and grown as follows:</p>
<ol>
<li>If the number of cases in the training set is N, then a sample of N cases is taken at random but with replacement. This sample will be the training set for growing the tree.</li>
<li>If there are M input variables, a number m &lt; M is specified such that at each node, m variables are selected at random out of the M and the best split on these m is used to split the node. The value of m is held constant during the forest growing.</li>
<li>Each tree is grown to the largest extent possible. There is no pruning.</li>
</ol>
<p>For more:<br />
- <a href="https://www.analyticsvidhya.com/blog/2014/06/introduction-random-forest-simplified/">Introduction to Random forest – Simplified</a><br />
- <a href="https://www.analyticsvidhya.com/blog/2014/06/comparing-cart-random-forest-1/">Comparing a CART model to Random Forest (Part 1)</a><br />
- <a href="https://www.analyticsvidhya.com/blog/2014/06/comparing-random-forest-simple-cart-model/">Comparing a Random Forest to a CART model (Part 2)</a><br />
- <a href="https://www.analyticsvidhya.com/blog/2015/06/tuning-random-forest-model/">Tuning the parameters of your Random Forest model</a></p>
<p>Note: we can work with strings in <code class="codehilite">Y</code>.</p>
<h4 id="the-r-code_2">The R Code<a class="headerlink" href="#the-r-code_2" title="Permanent link">&para;</a></h4>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="n">randomForest</span><span class="p">)</span>

<span class="c1"># Load train and test datasets</span>
<span class="c1"># Identify the feature and response variable(s)</span>
<span class="c1"># Values must be numeric and numpy arrays</span>
<span class="n">x_train</span> <span class="o">&lt;-</span> <span class="n">input_variables_values_training_datasets</span>
<span class="n">y_train</span> <span class="o">&lt;-</span> <span class="n">target_variables_values_training_datasets</span>
<span class="n">x_test</span> <span class="o">&lt;-</span> <span class="n">input_variables_values_test_datasets</span>
<span class="n">x</span> <span class="o">&lt;-</span> <span class="nf">cbind</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Fitting the model</span>
<span class="n">fit</span> <span class="o">&lt;-</span> <span class="nf">randomForest</span><span class="p">(</span><span class="n">y_train</span> <span class="o">~</span> <span class="n">.,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">ntree</span> <span class="o">=</span> <span class="m">500</span><span class="p">)</span>
<span class="nf">summary</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>

<span class="c1"># Predict the output </span>
<span class="n">predicted</span> <span class="o">&lt;-</span> <span class="nf">predict</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span> <span class="n">x_test</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<h4 id="the-python-code_2">The Python Code<a class="headerlink" href="#the-python-code_2" title="Permanent link">&para;</a></h4>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Import the libraries</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="c1"># Load the Train and Test Datasets</span>
<span class="c1"># Identify feature and response variable(s) and</span>
<span class="c1"># Values must be numeric and numpy arrays</span>
<span class="c1">#x_train = input_variables_values_training_datasets</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">X</span>
<span class="c1">#y_train = target_variables_values_training_datasets</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span>
<span class="c1">#x_test = input_variables_values_test_datasets</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">190</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="mi">43</span><span class="p">],</span> <span class="p">[</span><span class="mi">160</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">38</span><span class="p">]]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="c1"># y_true</span>

<span class="c1"># Assume we have, X (predictor) and Y (target) for</span>
<span class="c1"># training data set and x_test(predictor) of</span>
<span class="c1"># test_dataset</span>
<span class="c1"># Create the Random Forest object</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">)</span>

<span class="c1"># Train the model</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
            max_depth=None, max_features=&#39;auto&#39;, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=None,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Compute accuracy</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>1.0
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Predict the output</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="n">y_pred</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>array([1, 0])
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Compute accuracy</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>1.0
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Print the metrics</span>
<span class="k">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">[[1 0]</span>
 <span class="k">[0 1]]</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7
8</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>              precision    recall  f1-score   support

           0       1.00      1.00      1.00         1
           1       1.00      1.00      1.00         1

   micro avg       1.00      1.00      1.00         2
   macro avg       1.00      1.00      1.00         2
weighted avg       1.00      1.00      1.00         2
</pre></div>
</td></tr></table>

<h3 id="k-nearest-neighbours">k-Nearest Neighbours<a class="headerlink" href="#k-nearest-neighbours" title="Permanent link">&para;</a></h3>
<p>kNN can be used for both classification and regression problems. However, it is more widely used in classification problems in the industry. k-NN is a simple algorithm that stores all available cases and classifies new cases by a majority vote of its k neighbors. The case being assigned to the class is most common amongst its kNN measured by a distance function.</p>
<p>These distance functions can be:</p>
<ul>
<li>Euclidean, </li>
<li>Manhattan, </li>
<li>Minkowski, and </li>
<li>Hamming. </li>
</ul>
<p>First three functions are used for continuous function and fourth one (Hamming) for categorical variables. If <code class="codehilite">k = 1</code>, then the case is simply assigned to the class of its nearest neighbor. At times, choosing k turns out to be a challenge while performing kNN modeling.</p>
<p>Things to consider before selecting kNN:</p>
<ul>
<li>kNN is computationally expensive;</li>
<li>Variables should be <strong>normalized</strong>/standardized/rescaled or else higher range variables can bias it;</li>
<li>Works on pre-processing stage more before going for kNN like outlier, noise removal.</li>
</ul>
<p>Note: we can work with strings in <code class="codehilite">Y</code>.</p>
<h4 id="the-r-code_3">The R Code<a class="headerlink" href="#the-r-code_3" title="Permanent link">&para;</a></h4>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="n">knn</span><span class="p">)</span>

<span class="c1"># Load train and test datasets</span>
<span class="c1"># Identify the feature and response variable(s)</span>
<span class="c1"># Values must be numeric and numpy arrays</span>
<span class="n">x_train</span> <span class="o">&lt;-</span> <span class="n">input_variables_values_training_datasets</span>
<span class="n">y_train</span> <span class="o">&lt;-</span> <span class="n">target_variables_values_training_datasets</span>
<span class="n">x_test</span> <span class="o">&lt;-</span> <span class="n">input_variables_values_test_datasets</span>
<span class="n">x</span> <span class="o">&lt;-</span> <span class="nf">cbind</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Fitting the model</span>
<span class="n">fit</span> <span class="o">&lt;-</span> <span class="nf">knn</span><span class="p">(</span><span class="n">y_train</span> <span class="o">~</span> <span class="n">.,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="m">5</span><span class="p">)</span>
<span class="nf">summary</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>

<span class="c1"># Predict the output </span>
<span class="n">predicted</span> <span class="o">&lt;-</span> <span class="nf">predict</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span> <span class="n">x_test</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<h4 id="rescaling">Rescaling<a class="headerlink" href="#rescaling" title="Permanent link">&para;</a></h4>
<p>Normalization: <span><span class="MathJax_Preview">x = \frac{ x - x_{min} }{ x_{max} - x_{min} }</span><script type="math/tex">x = \frac{ x - x_{min} }{ x_{max} - x_{min} }</script></span>, transforms features by scaling each feature to a given range.</p>
<p>Standardization: <span><span class="MathJax_Preview">x = \frac{x - \mu}{\sigma}</span><script type="math/tex">x = \frac{x - \mu}{\sigma}</script></span>, centers to the mean and component wise scale to unit variance.</p>
<p>Consult the documentation for more.</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Standardize</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">scale</span>

<span class="c1"># Scale the independent variables</span>
<span class="n">X_s</span> <span class="o">=</span> <span class="n">scale</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_s</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>


<span class="c1"># Normalize</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>

<span class="c1"># Scale the independent variables</span>
<span class="n">min_max_scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="n">X_s</span> <span class="o">=</span> <span class="n">min_max_scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">minmax_scale</span>
<span class="n">X_s</span> <span class="o">=</span> <span class="n">minmax_scale</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<h4 id="the-python-code_3">The Python Code<a class="headerlink" href="#the-python-code_3" title="Permanent link">&para;</a></h4>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Import the libraries</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="c1"># Load the Train and Test Datasets</span>
<span class="c1"># Identify feature and response variable(s) and</span>
<span class="c1"># Values must be numeric and numpy arrays</span>
<span class="c1">#x_train = input_variables_values_training_datasets</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">X</span>
<span class="c1">#y_train = target_variables_values_training_datasets</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span>
<span class="c1">#x_test = input_variables_values_test_datasets</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">190</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="mi">43</span><span class="p">],</span> <span class="p">[</span><span class="mi">160</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">38</span><span class="p">]]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="c1"># y_true</span>

<span class="c1"># Assume we have, X (predictor) and Y (target) for</span>
<span class="c1"># training data set and x_test(predictor) of</span>
<span class="c1"># test_dataset</span>
<span class="c1"># Create the KNeighbors classifier object model </span>
<span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="mi">6</span><span class="p">,</span>
                     <span class="n">algorithm</span> <span class="o">=</span> <span class="s1">&#39;auto&#39;</span><span class="p">,</span>
                     <span class="n">leaf_size</span> <span class="o">=</span> <span class="mi">30</span><span class="p">,</span>
                     <span class="n">metric</span> <span class="o">=</span> <span class="s1">&#39;minkowski&#39;</span><span class="p">,</span>
                     <span class="n">metric_params</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
                     <span class="n">n_jobs</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
                     <span class="n">p</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
                     <span class="n">weights</span> <span class="o">=</span> <span class="s1">&#39;uniform&#39;</span><span class="p">)</span> <span class="c1"># default value for n_neighbors is 5</span>

<span class="c1"># Train the model</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;,
            max_depth=None, max_features=&#39;auto&#39;, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=None,
            oob_score=False, random_state=None, verbose=0,
            warm_start=False)
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Compute accuracy</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>1.0
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Predict the output</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="n">y_pred</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>array([1, 0])
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Compute accuracy</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>1.0
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Print the metrics</span>
<span class="k">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">[[1 0]</span>
 <span class="k">[0 1]]</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7
8</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>              precision    recall  f1-score   support

           0       1.00      1.00      1.00         1
           1       1.00      1.00      1.00         1

   micro avg       1.00      1.00      1.00         2
   macro avg       1.00      1.00      1.00         2
weighted avg       1.00      1.00      1.00         2
</pre></div>
</td></tr></table>

<h3 id="naive-bayes">Naïve Bayes<a class="headerlink" href="#naive-bayes" title="Permanent link">&para;</a></h3>
<p>It is a classification technique based on Bayes’ theorem with an assumption of independence between predictors. In simple terms, a Naive Bayes classifier assumes that the presence of a particular feature in a class is unrelated to the presence of any other feature. For example, a fruit may be considered to be an apple if it is red, round, and about 3 inches in diameter. Even if these features depend on each other or upon the existence of the other features, a naive Bayes classifier would consider all of these properties to independently contribute to the probability that this fruit is an apple.</p>
<p>Naive Bayesian model is easy to build and particularly useful for very large data sets. Along with simplicity, Naive Bayes is known to outperform even highly sophisticated classification methods.</p>
<p><a href="https://scikit-learn.org/stable/modules/naive_bayes.html">Documentation</a>.</p>
<p>Note: we can work with strings in <code class="codehilite">Y</code>.</p>
<h4 id="the-r-code_4">The R Code<a class="headerlink" href="#the-r-code_4" title="Permanent link">&para;</a></h4>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="n">e1071</span><span class="p">)</span>

<span class="c1"># Load train and test datasets</span>
<span class="c1"># Identify the feature and response variable(s)</span>
<span class="c1"># Values must be numeric and numpy arrays</span>
<span class="n">x_train</span> <span class="o">&lt;-</span> <span class="n">input_variables_values_training_datasets</span>
<span class="n">y_train</span> <span class="o">&lt;-</span> <span class="n">target_variables_values_training_datasets</span>
<span class="n">x_test</span> <span class="o">&lt;-</span> <span class="n">input_variables_values_test_datasets</span>
<span class="n">x</span> <span class="o">&lt;-</span> <span class="nf">cbind</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Fitting the model</span>
<span class="n">fit</span> <span class="o">&lt;-</span> <span class="nf">naiveBayes</span><span class="p">(</span><span class="n">y_train</span> <span class="o">~</span> <span class="n">.,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">)</span>
<span class="nf">summary</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>

<span class="c1"># Predict the output </span>
<span class="n">predicted</span> <span class="o">&lt;-</span> <span class="nf">predict</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span> <span class="n">x_test</span><span class="p">)</span>
<span class="n">predicted</span>
</pre></div>
</td></tr></table>

<h4 id="the-python-code_4">The Python Code<a class="headerlink" href="#the-python-code_4" title="Permanent link">&para;</a></h4>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Import the libraries</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="c1"># Load the Train and Test Datasets</span>
<span class="c1"># Identify feature and response variable(s) and</span>
<span class="c1"># Values must be numeric and numpy arrays</span>
<span class="c1">#x_train = input_variables_values_training_datasets</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">X</span>
<span class="c1">#y_train = target_variables_values_training_datasets</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span>
<span class="c1">#x_test = input_variables_values_test_datasets</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">190</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="mi">43</span><span class="p">],</span> <span class="p">[</span><span class="mi">160</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">38</span><span class="p">]]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="c1"># y_true</span>

<span class="c1"># Assume you have, X (predictor) and Y (target) for</span>
<span class="c1"># training data set and x_test(predictor) of</span>
<span class="c1"># test_dataset</span>
<span class="c1"># Create SVM classification object</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span> 

<span class="c1"># There is other distribution for</span>
<span class="c1"># multinomial classes like Bernoulli Naive Bayes</span>

<span class="c1"># Train the model</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>GaussianNB(priors=None, var_smoothing=1e-09)
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Compute accuracy</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>0.8181818181818182
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Predict the output</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="n">y_pred</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>array([1, 0])
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Compute accuracy</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>1.0
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Print the metrics</span>
<span class="k">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">[[1 0]</span>
 <span class="k">[0 1]]</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7
8</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>              precision    recall  f1-score   support

           0       1.00      1.00      1.00         1
           1       1.00      1.00      1.00         1

   micro avg       1.00      1.00      1.00         2
   macro avg       1.00      1.00      1.00         2
weighted avg       1.00      1.00      1.00         2
</pre></div>
</td></tr></table>

<h3 id="support-vector-machine">Support Vector Machine<a class="headerlink" href="#support-vector-machine" title="Permanent link">&para;</a></h3>
<p>SVM is a classification method. In this algorithm, we plot each data item as a point in n-dimensional space (where n is number of features you have) with the value of each feature being the value of a particular coordinate.</p>
<p><a href="https://www.analyticsvidhya.com/blog/2014/10/support-vector-machine-simplified/">For more</a>.</p>
<p>Note: we can work with strings in <code class="codehilite">Y</code>.</p>
<h4 id="the-r-code_5">The R Code<a class="headerlink" href="#the-r-code_5" title="Permanent link">&para;</a></h4>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="n">e1071</span><span class="p">)</span>

<span class="c1"># Load train and test datasets</span>
<span class="c1"># Identify the feature and response variable(s)</span>
<span class="c1"># Values must be numeric and numpy arrays</span>
<span class="n">x_train</span> <span class="o">&lt;-</span> <span class="n">input_variables_values_training_datasets</span>
<span class="n">y_train</span> <span class="o">&lt;-</span> <span class="n">target_variables_values_training_datasets</span>
<span class="n">x_test</span> <span class="o">&lt;-</span> <span class="n">input_variables_values_test_datasets</span>
<span class="n">x</span> <span class="o">&lt;-</span> <span class="nf">cbind</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Fitting the model</span>
<span class="n">fit</span> <span class="o">&lt;-</span> <span class="nf">svm</span><span class="p">(</span><span class="n">y_train</span> <span class="o">~</span> <span class="n">.,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">)</span>
<span class="nf">summary</span><span class="p">(</span><span class="n">fit</span><span class="p">)</span>

<span class="c1"># Predict the output </span>
<span class="n">predicted</span> <span class="o">&lt;-</span> <span class="nf">predict</span><span class="p">(</span><span class="n">fit</span><span class="p">,</span> <span class="n">x_test</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<h4 id="the-python-code_5">The Python Code<a class="headerlink" href="#the-python-code_5" title="Permanent link">&para;</a></h4>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Import the libraries</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">svm</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="c1"># Load the Train and Test Datasets</span>
<span class="c1"># Identify feature and response variable(s) and</span>
<span class="c1"># Values must be numeric and numpy arrays</span>
<span class="c1">#x_train = input_variables_values_training_datasets</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">X</span>
<span class="c1">#y_train = target_variables_values_training_datasets</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y_train</span>
<span class="c1">#x_test = input_variables_values_test_datasets</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">190</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="mi">43</span><span class="p">],</span> <span class="p">[</span><span class="mi">160</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">38</span><span class="p">]]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="c1"># y_true</span>

<span class="c1"># Assume we have, X (predictor) and Y (target) for</span>
<span class="c1"># training data set and x_test(predictor) of</span>
<span class="c1"># test_dataset</span>
<span class="c1"># Create the SVM classification object </span>
<span class="n">model</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">gamma</span> <span class="o">=</span> <span class="s1">&#39;auto&#39;</span><span class="p">)</span> 

<span class="c1"># There is various option associated with it,</span>
<span class="c1"># this is simple for classification</span>

<span class="c1"># Train the model</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=&#39;ovr&#39;, degree=3, gamma=&#39;auto&#39;, kernel=&#39;rbf&#39;,
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Compute accuracy</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>1.0
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Predict the output</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="n">y_pred</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>array([1, 0])
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Compute accuracy</span>
<span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>1.0
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Print the metrics</span>
<span class="k">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">[[1 0]</span>
 <span class="k">[0 1]]</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7
8</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>              precision    recall  f1-score   support

           0       1.00      1.00      1.00         1
           1       1.00      1.00      1.00         1

   micro avg       1.00      1.00      1.00         2
   macro avg       1.00      1.00      1.00         2
weighted avg       1.00      1.00      1.00         2
</pre></div>
</td></tr></table>

<h2 id="split-a-dataset">Split a dataset<a class="headerlink" href="#split-a-dataset" title="Permanent link">&para;</a></h2>
<p>We can automate the split.</p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Import the libraries</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="c1"># Split the dataset</span>
<span class="c1"># 80% for training (train set)</span>
<span class="c1"># 20% for testing (test set)</span>
<span class="n">Xs_train</span><span class="p">,</span> <span class="n">Xs_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span>
                                                      <span class="n">Y</span><span class="p">,</span>
                                                      <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span>
                                                      <span class="n">random_state</span> <span class="o">=</span> <span class="mi">42</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<h2 id="intermediate-supervised-learning">Intermediate Supervised Learning<a class="headerlink" href="#intermediate-supervised-learning" title="Permanent link">&para;</a></h2>
<h3 id="logistic-regression_1">Logistic regression<a class="headerlink" href="#logistic-regression_1" title="Permanent link">&para;</a></h3>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Import the libraries</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>

<span class="c1"># Import the data</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/adults.txt&#39;</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;,&#39;</span><span class="p">)</span>

<span class="c1"># Convert the string labels to numeric labels</span>
<span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;race&#39;</span><span class="p">,</span> <span class="s1">&#39;occupation&#39;</span><span class="p">]:</span>
    <span class="n">data</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">label</span><span class="p">])</span>
<span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>workclass</th>
      <th>final_weight</th>
      <th>education</th>
      <th>education_num</th>
      <th>marital_status</th>
      <th>occupation</th>
      <th>relationship</th>
      <th>race</th>
      <th>sex</th>
      <th>capital_gain</th>
      <th>capital_loss</th>
      <th>hours_per_week</th>
      <th>native_country</th>
      <th>salary</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>39</td>
      <td>State-gov</td>
      <td>77516</td>
      <td>Bachelors</td>
      <td>13</td>
      <td>Never-married</td>
      <td>1</td>
      <td>Not-in-family</td>
      <td>4</td>
      <td>Male</td>
      <td>2174</td>
      <td>0</td>
      <td>40</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>1</th>
      <td>50</td>
      <td>Self-emp-not-inc</td>
      <td>83311</td>
      <td>Bachelors</td>
      <td>13</td>
      <td>Married-civ-spouse</td>
      <td>4</td>
      <td>Husband</td>
      <td>4</td>
      <td>Male</td>
      <td>0</td>
      <td>0</td>
      <td>13</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>2</th>
      <td>38</td>
      <td>Private</td>
      <td>215646</td>
      <td>HS-grad</td>
      <td>9</td>
      <td>Divorced</td>
      <td>6</td>
      <td>Not-in-family</td>
      <td>4</td>
      <td>Male</td>
      <td>0</td>
      <td>0</td>
      <td>40</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
  </tbody>
</table>
</div>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3
4
5
6</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Take the fields of interest and</span>
<span class="c1"># plug them into variable X</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="p">[[</span><span class="s1">&#39;race&#39;</span><span class="p">,</span> <span class="s1">&#39;hours_per_week&#39;</span><span class="p">,</span> <span class="s1">&#39;occupation&#39;</span><span class="p">]]</span>

<span class="c1"># Provide the corresponding values</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;sex&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3
4
5
6
7
8</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Import the libraries</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="c1"># Split the data into a test (30%) and train set (70%)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">Y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3
4
5
6
7
8
9</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Instantiate the classifier</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>

<span class="c1"># Train the model</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>

<span class="c1"># Compute accuracy</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Accuracy: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">accuracy</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>/home/ugo/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.
  FutureWarning)


Accuracy: 0.6801105537926093
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Predict the output</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">prediction</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">[&#39;Male&#39; &#39;Male&#39; &#39;Male&#39; ... &#39;Male&#39; &#39;Male&#39; &#39;Male&#39;]</span>





<span class="na">array([&#39;Male&#39;, &#39;Male&#39;, &#39;Male&#39;, ..., &#39;Male&#39;, &#39;Male&#39;, &#39;Male&#39;], dtype</span><span class="o">=</span><span class="s">&#39;&amp;lt;U6&#39;)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Print the confusion matrix and report</span>
<span class="k">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">[[ 498  446]</span>
 <span class="k">[2679 6146]]</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7
8</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>              precision    recall  f1-score   support

      Female       0.16      0.53      0.24       944
        Male       0.93      0.70      0.80      8825

   micro avg       0.68      0.68      0.68      9769
   macro avg       0.54      0.61      0.52      9769
weighted avg       0.86      0.68      0.74      9769
</pre></div>
</td></tr></table>

<h3 id="decision-tree_1">Decision tree<a class="headerlink" href="#decision-tree_1" title="Permanent link">&para;</a></h3>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Import the libraries</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">tree</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="c1"># Instantiate the classifier</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeClassifier</span><span class="p">()</span>

<span class="c1"># Train the model</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>

<span class="c1"># Compute accuracy</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Accuracy: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">accuracy</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">Accuracy</span><span class="o">:</span> <span class="mf">0.7340567100010237</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3
4
5
6</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Predict the output</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">prediction</span>

<span class="c1"># Print the confusion matrix and report</span>
<span class="k">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">[[1592 1013]</span>
 <span class="k">[1585 5579]]</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7
8</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>              precision    recall  f1-score   support

      Female       0.50      0.61      0.55      2603
        Male       0.85      0.78      0.81      7166

   micro avg       0.73      0.73      0.73      9769
   macro avg       0.67      0.69      0.68      9769
weighted avg       0.75      0.73      0.74      9769
</pre></div>
</td></tr></table>

<h3 id="random-forests_1">Random Forests<a class="headerlink" href="#random-forests_1" title="Permanent link">&para;</a></h3>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Import the libraries</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>


<span class="c1"># Instantiate the classifier</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">)</span>

<span class="c1"># Train the model</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>

<span class="c1"># Compute accuracy</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Accuracy: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">accuracy</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">Accuracy</span><span class="o">:</span> <span class="mf">0.73303306377316</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3
4
5
6</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Predict the output</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">prediction</span>

<span class="c1"># Print the confusion matrix and report</span>
<span class="k">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">[[1497  928]</span>
 <span class="k">[1680 5664]]</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7
8</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>              precision    recall  f1-score   support

      Female       0.47      0.62      0.53      2425
        Male       0.86      0.77      0.81      7344

   micro avg       0.73      0.73      0.73      9769
   macro avg       0.67      0.69      0.67      9769
weighted avg       0.76      0.73      0.74      9769
</pre></div>
</td></tr></table>

<h3 id="k-nearest-neighbours_1">k-Nearest Neighbours<a class="headerlink" href="#k-nearest-neighbours_1" title="Permanent link">&para;</a></h3>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Import the libraries</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="c1"># Instantiate the classifier</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span>

<span class="c1"># Train the model</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>

<span class="c1"># Compute accuracy</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Accuracy: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">accuracy</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">Accuracy</span><span class="o">:</span> <span class="mf">0.6849216910635685</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Predict the output</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">prediction</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>array([&#39;Female&#39;, &#39;Female&#39;, &#39;Male&#39;, ..., &#39;Female&#39;, &#39;Male&#39;, &#39;Male&#39;],
      dtype=&#39;&amp;lt;U6&#39;)
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Print the confusion matrix and report</span>
<span class="k">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">[[1745 1646]</span>
 <span class="k">[1432 4946]]</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7
8</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>              precision    recall  f1-score   support

      Female       0.55      0.51      0.53      3391
        Male       0.75      0.78      0.76      6378

   micro avg       0.68      0.68      0.68      9769
   macro avg       0.65      0.65      0.65      9769
weighted avg       0.68      0.68      0.68      9769
</pre></div>
</td></tr></table>

<h3 id="naive-bayes_1">Naïve Bayes<a class="headerlink" href="#naive-bayes_1" title="Permanent link">&para;</a></h3>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Import the libraries</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="c1"># Instantiate the classifier</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>

<span class="c1"># Train the model</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>

<span class="c1"># Compute accuracy</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Accuracy: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">accuracy</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">Accuracy</span><span class="o">:</span> <span class="mf">0.6708977377418365</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Predict the output</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">prediction</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>[&#39;Male&#39; &#39;Female&#39; &#39;Male&#39; ... &#39;Male&#39; &#39;Male&#39; &#39;Male&#39;]
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Print the confusion matrix and report</span>
<span class="k">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">[[ 636  674]</span>
 <span class="k">[2541 5918]]</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7
8</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>              precision    recall  f1-score   support

      Female       0.20      0.49      0.28      1310
        Male       0.90      0.70      0.79      8459

   micro avg       0.67      0.67      0.67      9769
   macro avg       0.55      0.59      0.53      9769
weighted avg       0.80      0.67      0.72      9769
</pre></div>
</td></tr></table>

<h3 id="support-vector-machine_1">Support Vector Machine<a class="headerlink" href="#support-vector-machine_1" title="Permanent link">&para;</a></h3>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Import the libraries</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">svm</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="c1"># Instantiate the classifier</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">gamma</span> <span class="o">=</span> <span class="s1">&#39;auto&#39;</span><span class="p">)</span>

<span class="c1"># Train the model</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>

<span class="c1"># Compute accuracy</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Accuracy: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">accuracy</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">Accuracy</span><span class="o">:</span> <span class="mf">0.7360016378339646</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Predict the output</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">prediction</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>[&#39;Male&#39; &#39;Female&#39; &#39;Female&#39; ... &#39;Female&#39; &#39;Male&#39; &#39;Male&#39;]
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Print the confusion matrix and report</span>
<span class="k">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">[[1519  921]</span>
 <span class="k">[1658 5671]]</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4
5
6
7
8</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>              precision    recall  f1-score   support

      Female       0.48      0.62      0.54      2440
        Male       0.86      0.77      0.81      7329

   micro avg       0.74      0.74      0.74      9769
   macro avg       0.67      0.70      0.68      9769
weighted avg       0.76      0.74      0.75      9769
</pre></div>
</td></tr></table>

<h2 id="unsupervised-learning_1">Unsupervised Learning<a class="headerlink" href="#unsupervised-learning_1" title="Permanent link">&para;</a></h2>
<h3 id="k-means">k-Means<a class="headerlink" href="#k-means" title="Permanent link">&para;</a></h3>
<p>It is an unsupervised algorithm which solves clustering problems. Assume k clusters, data points inside one cluster are homogeneous, but heterogeneous to peer groups.</p>
<p>In k-means, we have clusters and each cluster has its own centroid. Sum of square of difference between centroid and the data points within a cluster constitutes within sum of square value for that cluster. Also, when the sum of square values for all the clusters are added, it becomes total within sum of square value for the cluster solution.</p>
<p>We know that as the number of cluster increases, this value keeps on decreasing but if you plot the result you may see that the sum of squared distance decreases sharply up to some value of k, and then much more slowly after that. Here, we can find the optimum number of cluster.</p>
<h4 id="the-r-code_6">The R Code<a class="headerlink" href="#the-r-code_6" title="Permanent link">&para;</a></h4>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="n">cluster</span><span class="p">)</span>

<span class="c1"># Load train and test datasets</span>
<span class="c1"># Identify the feature and response variable(s)</span>
<span class="c1"># Values must be numeric and numpy arrays</span>
<span class="n">x_train</span> <span class="o">&lt;-</span> <span class="n">input_variables_values_training_datasets</span>
<span class="n">y_train</span> <span class="o">&lt;-</span> <span class="n">target_variables_values_training_datasets</span>
<span class="n">x_test</span> <span class="o">&lt;-</span> <span class="n">input_variables_values_test_datasets</span>
<span class="n">x</span> <span class="o">&lt;-</span> <span class="nf">cbind</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">fit</span> <span class="o">&lt;-</span> <span class="nf">kmeans</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="m">3</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<h4 id="the-python-code_6">The Python Code<a class="headerlink" href="#the-python-code_6" title="Permanent link">&para;</a></h4>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Import the Libraries</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="c1"># Instantiate the classifier</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>

<span class="c1"># Train the model</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="c1"># Compute accuracy</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Accuracy: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">accuracy</span><span class="p">))</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>Accuracy: -478732.018200623
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Extract the parameters</span>
<span class="n">clf</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>{&#39;algorithm&#39;: &#39;auto&#39;,
 &#39;copy_x&#39;: True,
 &#39;init&#39;: &#39;k-means++&#39;,
 &#39;max_iter&#39;: 300,
 &#39;n_clusters&#39;: 3,
 &#39;n_init&#39;: 10,
 &#39;n_jobs&#39;: None,
 &#39;precompute_distances&#39;: &#39;auto&#39;,
 &#39;random_state&#39;: 0,
 &#39;tol&#39;: 0.0001,
 &#39;verbose&#39;: 0}
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Predict the output</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">prediction</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>array([1, 0, 0, ..., 0, 0, 2], dtype=int32)
</pre></div>
</td></tr></table>

<h2 id="dimension-reduction">Dimension Reduction<a class="headerlink" href="#dimension-reduction" title="Permanent link">&para;</a></h2>
<h3 id="principal-component-analysis">Principal Component Analysis<a class="headerlink" href="#principal-component-analysis" title="Permanent link">&para;</a></h3>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3
4
5</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Import the Libraries</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;sex&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>0    Male
1    Male
2    Male
Name: sex, dtype: object
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># % Male</span>
<span class="nb">sum</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;sex&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;Male&#39;</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>0.6692054912318418
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3
4</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Convert the string labels to numeric labels</span>
<span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;race&#39;</span><span class="p">,</span> <span class="s1">&#39;occupation&#39;</span><span class="p">,</span> <span class="s1">&#39;sex&#39;</span><span class="p">]:</span>
    <span class="n">data</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">label</span><span class="p">])</span>
<span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>workclass</th>
      <th>final_weight</th>
      <th>education</th>
      <th>education_num</th>
      <th>marital_status</th>
      <th>occupation</th>
      <th>relationship</th>
      <th>race</th>
      <th>sex</th>
      <th>capital_gain</th>
      <th>capital_loss</th>
      <th>hours_per_week</th>
      <th>native_country</th>
      <th>salary</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>39</td>
      <td>State-gov</td>
      <td>77516</td>
      <td>Bachelors</td>
      <td>13</td>
      <td>Never-married</td>
      <td>1</td>
      <td>Not-in-family</td>
      <td>4</td>
      <td>1</td>
      <td>2174</td>
      <td>0</td>
      <td>40</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>1</th>
      <td>50</td>
      <td>Self-emp-not-inc</td>
      <td>83311</td>
      <td>Bachelors</td>
      <td>13</td>
      <td>Married-civ-spouse</td>
      <td>4</td>
      <td>Husband</td>
      <td>4</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>13</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>2</th>
      <td>38</td>
      <td>Private</td>
      <td>215646</td>
      <td>HS-grad</td>
      <td>9</td>
      <td>Divorced</td>
      <td>6</td>
      <td>Not-in-family</td>
      <td>4</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>40</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
  </tbody>
</table>
</div>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Take the fields of interest and</span>
<span class="c1"># plug them into variable X</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="p">[[</span><span class="s1">&#39;age&#39;</span><span class="p">,</span> <span class="s1">&#39;final_weight&#39;</span><span class="p">,</span> <span class="s1">&#39;education_num&#39;</span><span class="p">,</span> <span class="s1">&#39;occupation&#39;</span><span class="p">,</span> <span class="s1">&#39;race&#39;</span><span class="p">,</span> <span class="s1">&#39;capital_gain&#39;</span><span class="p">,</span> <span class="s1">&#39;hours_per_week&#39;</span><span class="p">]]</span>

<span class="c1"># Instantiate the PCA model</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span> <span class="c1"># default value of k = min(n_sample, n_features)</span>

<span class="c1"># For factor analysis</span>
<span class="c1">#fa = decomposition.FactorAnalysis()</span>

<span class="c1"># Transform the data</span>
<span class="n">reduced_data_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># Inspect the shape</span>
<span class="n">reduced_data_pca</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>(32561, 2)
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Print the transformed data</span>
<span class="n">reduced_data_pca</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>array([[-112262.33316765,    1099.76011639],
       [-106467.39923916,   -1074.41772634],
       [  25867.60075685,   -1078.43450794]])
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Plot the results</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">reduced_data_pca</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">reduced_data_pca</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;First Principal Component&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Second Principal Component&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;PCA Scatter Plot&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</td></tr></table>

<p><img alt="" src="../img/overview_of_scikit/output_100_0.png" /></p>
<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">male</span> <span class="o">=</span> <span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;sex&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span>
<span class="nb">type</span><span class="p">(</span><span class="n">male</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>list
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># Is Male?</span>
<span class="n">male</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>0    True
1    True
2    True
Name: sex, dtype: bool
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3
4</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">female</span> <span class="o">=</span> <span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;sex&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span>

<span class="c1"># Is Female?</span>
<span class="n">female</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">]</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2
3
4</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>0    False
1    False
2    False
Name: sex, dtype: bool
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2
3
4
5</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> 
          <span class="s1">&#39;red&#39;</span><span class="p">]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">colors</span><span class="p">)):</span>
    <span class="k">print</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span>0
1
</pre></div>
</td></tr></table>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span>1
2</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">sex</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">sex</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</td></tr></table>

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>age</th>
      <th>workclass</th>
      <th>final_weight</th>
      <th>education</th>
      <th>education_num</th>
      <th>marital_status</th>
      <th>occupation</th>
      <th>relationship</th>
      <th>race</th>
      <th>sex</th>
      <th>capital_gain</th>
      <th>capital_loss</th>
      <th>hours_per_week</th>
      <th>native_country</th>
      <th>salary</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>39</td>
      <td>State-gov</td>
      <td>77516</td>
      <td>Bachelors</td>
      <td>13</td>
      <td>Never-married</td>
      <td>1</td>
      <td>Not-in-family</td>
      <td>4</td>
      <td>1</td>
      <td>2174</td>
      <td>0</td>
      <td>40</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>1</th>
      <td>50</td>
      <td>Self-emp-not-inc</td>
      <td>83311</td>
      <td>Bachelors</td>
      <td>13</td>
      <td>Married-civ-spouse</td>
      <td>4</td>
      <td>Husband</td>
      <td>4</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>13</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
    <tr>
      <th>2</th>
      <td>38</td>
      <td>Private</td>
      <td>215646</td>
      <td>HS-grad</td>
      <td>9</td>
      <td>Divorced</td>
      <td>6</td>
      <td>Not-in-family</td>
      <td>4</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>40</td>
      <td>United-States</td>
      <td>&lt;=50K</td>
    </tr>
  </tbody>
</table>
</div>

<table class="codehilitetable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18</pre></div></td><td class="code"><div class="codehilite"><pre><span></span><span class="c1"># 0 Female, blue</span>
<span class="c1"># 1 Male, red</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">colors</span><span class="p">)):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">reduced_data_pca</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;sex&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">i</span><span class="p">]</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">reduced_data_pca</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;sex&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">i</span><span class="p">]</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span> 

<span class="c1"># 0 Female, 1 Male</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Female&#39;</span><span class="p">,</span><span class="s1">&#39;Male&#39;</span><span class="p">],</span> 
           <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">1.05</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> 
           <span class="n">loc</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
           <span class="n">borderaxespad</span><span class="o">=</span><span class="mf">0.</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;First Principal Component&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Second Principal Component&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;PCA Scatter Plot&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</td></tr></table>

<p><img alt="" src="../img/overview_of_scikit/output_106_0.png" /></p>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../intro_to_data_world_in_python/" title="Introduction to data.world" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Introduction to data.world
              </span>
            </div>
          </a>
        
        
          <a href="../python_and_excel/" title="Python and Excel" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Python and Excel
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
        
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/application.b41f3d20.js"></script>
      
      <script>app.initialize({version:"1.0.4",url:{base:".."}})</script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
    
    
      
        <script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-93008985-2","auto"),ga("set","anonymizeIp",!0),ga("send","pageview");var links=document.getElementsByTagName("a");if(Array.prototype.map.call(links,function(a){a.host!=document.location.host&&a.addEventListener("click",function(){var e=a.getAttribute("data-md-action")||"follow";ga("send","event","outbound",e,a.href)})}),document.forms.search){var query=document.forms.search.query;query.addEventListener("blur",function(){if(this.value){var e=document.location.pathname;ga("send","pageview",e+"?q="+this.value)}})}</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>
      
    
  </body>
</html>